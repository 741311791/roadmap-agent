# 任务阻塞根本原因分析

**日期**: 2026-01-03  
**问题**: 多个路线图生成任务无法同时运行  
**分析方法**: 第一性原理逐层分析

---

## 问题现象

用户提交多个路线图生成任务后，发现：
1. 部分任务显示 `pending` 状态且 `current_step=init`
2. 部分任务显示 `human_review_pending` 状态
3. 即使将 Worker 并发数从 2 增加到 6，问题仍然存在

---

## 第一性原理分析

### 1️⃣ 任务提交流程

```python
# backend/app/api/v1/endpoints/generation.py

@router.post("/generate")
async def generate_roadmap_async(request: UserRequest, repo_factory: RepositoryFactory):
    task_id = str(uuid.uuid4())
    
    # Step 1: 创建任务记录（FastAPI 进程的数据库连接）
    async with repo_factory.create_session() as session:
        task_repo = repo_factory.create_task_repo(session)
        await task_repo.create_task(
            task_id=task_id,
            user_id=request.user_id,
            user_request=request.model_dump(mode='json'),
        )
        await session.commit()  # ✅ 提交到数据库
    
    # Step 2: 提交 Celery 任务
    celery_task = generate_roadmap.delay(
        task_id=task_id,
        user_request=request.preferences.learning_goal,
        user_id=request.user_id,
        learning_preferences=request.preferences.model_dump(mode='json'),
    )
    
    return {"task_id": task_id, "status": "pending"}
```

### 2️⃣ Worker 执行流程

```python
# backend/app/tasks/roadmap_generation_tasks.py

@celery_app.task
def generate_roadmap(self, task_id, user_request, user_id, learning_preferences):
    # Step 3: Worker 使用独立的数据库连接（NullPool）
    result = run_async(
        _execute_roadmap_workflow(
            task_id=task_id,
            user_request=user_request,
            user_id=user_id,
            learning_preferences=learning_preferences,
        )
    )
    return result
```

### 3️⃣ 工作流执行

```python
async def _execute_roadmap_workflow(task_id, ...):
    # Step 4: 更新任务状态
    repo_factory = CeleryRepositoryFactory()
    async with repo_factory.create_session() as session:
        task_repo = repo_factory.create_task_repo(session)
        await task_repo.update_task_status(
            task_id=task_id,
            status="processing",
            current_step="queued",
        )
    
    # Step 5: 执行工作流
    executor = factory.create_workflow_executor()
    result = await executor.execute(user_request_obj, task_id)
    
    # Step 6: 保存 Intent Analysis 结果
    # ❌ 这里会尝试插入 intent_analysis_metadata
    # ❌ 外键约束：task_id 必须存在于 roadmap_tasks 表中
```

---

## 根本原因

### 问题：外键约束冲突

```sql
insert or update on table "intent_analysis_metadata" 
violates foreign key constraint "intent_analysis_metadata_task_id_fkey"

DETAIL: Key (task_id)=(9e8e98b3-c6cb-47d2-bfd6-4c8225f7e0f6) 
is not present in table "roadmap_tasks".
```

### 原因分析

**数据库连接隔离问题**：

1. **FastAPI 进程**：
   - 使用连接池（pool_size=2, max_overflow=3）
   - 提交任务记录到 `roadmap_tasks` 表
   - 连接 A 看到的数据：✅ task_id 存在

2. **Celery Worker 进程**：
   - 使用 NullPool（每次创建新连接）
   - 尝试插入 `intent_analysis_metadata`
   - 连接 B 看到的数据：❌ task_id 不存在

3. **问题核心**：
   - FastAPI 的 `commit()` 虽然提交了事务
   - 但由于 PostgreSQL 的 **MVCC（多版本并发控制）** 机制
   - Celery Worker 的新连接可能看到的是**旧快照**
   - 或者 FastAPI 的连接还在连接池中缓存，未真正释放

### 时序问题

```
时间线：
T1: FastAPI 创建 RoadmapTask 记录
T2: FastAPI commit() 
T3: FastAPI 提交 Celery 任务
T4: Celery Worker 接收任务（几乎立即，< 10ms）
T5: Worker 创建新数据库连接
T6: Worker 尝试读取 RoadmapTask（❌ 可能看不到）
T7: Worker 尝试插入 intent_analysis_metadata（❌ 外键约束失败）
```

**问题**：T4-T6 之间的时间窗口太短，Worker 的新连接可能还没看到 FastAPI 提交的数据。

---

## 为什么增加并发数没用？

**误判**：用户以为是并发数不足导致任务排队。

**真相**：
- 任务确实被提交到 Celery
- Worker 也确实执行了任务
- 但任务执行时**立即失败**（外键约束错误）
- 失败信息存储在 Redis 中，但**没有同步回数据库**
- 数据库中的任务仍然显示 `status=pending`

---

## 解决方案

### 方案 1：添加延迟（临时方案）

在提交 Celery 任务前添加短暂延迟，确保数据库事务完全提交：

```python
@router.post("/generate")
async def generate_roadmap_async(request: UserRequest, repo_factory: RepositoryFactory):
    task_id = str(uuid.uuid4())
    
    # 创建任务记录
    async with repo_factory.create_session() as session:
        task_repo = repo_factory.create_task_repo(session)
        await task_repo.create_task(...)
        await session.commit()
    
    # ✅ 添加短暂延迟，确保数据库事务完全提交
    await asyncio.sleep(0.1)  # 100ms
    
    # 提交 Celery 任务
    celery_task = generate_roadmap.delay(...)
    
    return {"task_id": task_id, "status": "pending"}
```

**优点**：简单，立即生效  
**缺点**：不优雅，治标不治本

### 方案 2：在 Worker 中验证任务存在（推荐）

在 Worker 执行前先验证任务记录是否存在，如果不存在则重试：

```python
async def _execute_roadmap_workflow(task_id, ...):
    repo_factory = CeleryRepositoryFactory()
    
    # ✅ Step 1: 验证任务记录是否存在
    max_retries = 5
    for attempt in range(max_retries):
        async with repo_factory.create_session() as session:
            task_repo = repo_factory.create_task_repo(session)
            task = await task_repo.get_by_task_id(task_id)
            
            if task:
                break  # 任务存在，继续执行
            
            if attempt < max_retries - 1:
                logger.warning(
                    "task_not_found_retrying",
                    task_id=task_id,
                    attempt=attempt + 1,
                )
                await asyncio.sleep(0.1 * (attempt + 1))  # 指数退避
            else:
                raise ValueError(f"Task {task_id} not found after {max_retries} retries")
    
    # Step 2: 更新任务状态
    async with repo_factory.create_session() as session:
        task_repo = repo_factory.create_task_repo(session)
        await task_repo.update_task_status(
            task_id=task_id,
            status="processing",
            current_step="queued",
        )
    
    # Step 3: 执行工作流
    ...
```

**优点**：
- 可靠，处理了时序问题
- 不影响 API 响应时间
- 有重试机制，容错性强

**缺点**：
- 增加了 Worker 的启动时间（最多 500ms）

### 方案 3：使用数据库通知机制（最优）

使用 PostgreSQL 的 `LISTEN/NOTIFY` 机制，确保 Worker 在任务记录提交后才开始执行：

```python
# 1. FastAPI 提交任务后发送通知
async with repo_factory.create_session() as session:
    task_repo = repo_factory.create_task_repo(session)
    await task_repo.create_task(...)
    await session.commit()
    
    # 发送 PostgreSQL 通知
    await session.execute(text(f"NOTIFY task_created, '{task_id}'"))

# 2. Celery Worker 等待通知
async def _execute_roadmap_workflow(task_id, ...):
    # 订阅通知
    async with repo_factory.create_session() as session:
        await session.execute(text("LISTEN task_created"))
        
        # 等待通知或超时
        timeout = 5.0
        start_time = time.time()
        while time.time() - start_time < timeout:
            # 检查任务是否存在
            task = await task_repo.get_by_task_id(task_id)
            if task:
                break
            await asyncio.sleep(0.05)
```

**优点**：
- 最优雅，利用数据库原生机制
- 无需轮询，性能最好

**缺点**：
- 实现复杂度较高
- 需要额外的数据库连接管理

---

## 推荐方案

**立即实施：方案 2（在 Worker 中验证任务存在）**

**长期优化：方案 3（数据库通知机制）**

---

## 验证方法

修复后，运行以下脚本验证：

```bash
# 1. 检查 Redis 队列
uv run python scripts/diagnose_task_blocking.py

# 2. 检查数据库任务状态
uv run python scripts/check_db_tasks.py

# 3. 提交测试任务
curl -X POST http://localhost:8000/api/v1/roadmaps/generate \
  -H "Content-Type: application/json" \
  -d '{"preferences": {"learning_goal": "测试任务"}}'

# 4. 观察 Worker 日志
# 应该看到：
# - task_not_found_retrying (如果需要重试)
# - celery_task_started
# - workflow_execution_starting
```

---

## 总结

**问题本质**：数据库事务提交与 Celery 任务执行之间的**时序竞争**（Race Condition）

**根本原因**：FastAPI 和 Celery Worker 使用不同的数据库连接，Worker 可能看不到 FastAPI 刚提交的数据

**解决方案**：在 Worker 中添加任务存在性验证和重试机制

**教训**：
1. 分布式系统中，不同进程/连接之间的数据可见性需要特别注意
2. 外键约束错误需要同步回数据库，避免状态不一致
3. 第一性原理分析：从现象 → 日志 → 数据库 → 代码 → 时序，逐层深入

