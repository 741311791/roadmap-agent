# å†…å®¹ç”Ÿæˆè¿æ¥æ± è€—å°½ä¿®å¤

**å®æ–½æ—¥æœŸ**: 2026-01-04  
**é—®é¢˜ç±»å‹**: æ•°æ®åº“è¿æ¥æ± è€—å°½ï¼ˆTimeoutErrorï¼‰  
**å½±å“èŒƒå›´**: å†…å®¹ç”Ÿæˆä»»åŠ¡ï¼ˆContent Generationï¼‰

---

## é—®é¢˜æè¿°

### é”™è¯¯æ—¥å¿—

```
[2026-01-04 22:27:30,796: WARNING/ForkPoolWorker-2] 2026-01-04 22:27:30 [error] tavily_get_best_key_failed     
error='QueuePool limit of size 5 overflow 5 reached, connection timed out, timeout 60.00' 
error_type=TimeoutError

[2026-01-04 22:30:57,436: WARNING/ForkPoolWorker-2] 2026-01-04 22:30:57 [warning] web_search_router_tavily_check_failed 
error='QueuePool limit of size 5 overflow 5 reached...'
```

### ç”¨æˆ·é…ç½®

```bash
# .env é…ç½®
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=5
# æ€»è¿æ¥æ•° = 5 + 5 = 10 ä¸ª/è¿›ç¨‹

# Celery é…ç½®ï¼ˆæ¨æµ‹ï¼‰
CELERY_CONTENT_CONCURRENCY=6  # 6 ä¸ªè·¯çº¿å›¾å¹¶å‘
```

---

## æ ¹å› åˆ†æ

### 1. ä¸¤å±‚å¹¶å‘æ¶æ„

ç³»ç»Ÿé‡‡ç”¨**åŒå±‚å¹¶å‘**ï¼š
- **Celery å±‚**: 6 ä¸ªè·¯çº¿å›¾ä»»åŠ¡å¹¶å‘
- **AsyncIO å±‚**: æ¯ä¸ªè·¯çº¿å›¾å†…éƒ¨æ‰€æœ‰ Concept **æ— é™åˆ¶å¹¶å‘**ï¼ˆä¾‹å¦‚ 30 ä¸ªï¼‰

**ç†è®ºæœ€å¤§å¹¶å‘**ï¼š
```
6 ä¸ªè·¯çº¿å›¾ Ã— 30 ä¸ª Concept = 180 ä¸ª Concept åŒæ—¶ç”Ÿæˆ
```

### 2. è¿æ¥æ± é…ç½®ä¸è¶³

```
å½“å‰é…ç½®ï¼šDB_POOL_SIZE=5, DB_MAX_OVERFLOW=5
æ¯ä¸ªè¿›ç¨‹æœ€å¤§è¿æ¥æ•° = 5 + 5 = 10 ä¸ª
Celery Content Worker è¿›ç¨‹æ•° = 1 ä¸»è¿›ç¨‹ + 6 å·¥ä½œè¿›ç¨‹ = 7 ä¸ªè¿›ç¨‹
æ€»è¿æ¥æ•° = 7 Ã— 10 = 70 ä¸ªï¼ˆç†è®ºå€¼ï¼‰
```

ä½†åœ¨å®é™…è¿è¡Œä¸­ï¼Œ180 ä¸ª Concept å¯èƒ½åŒæ—¶è¯·æ±‚æ•°æ®åº“è¿æ¥ï¼Œ10 ä¸ªè¿æ¥è¿œè¿œä¸å¤Ÿï¼

### 3. å›é€€æœºåˆ¶è§¦å‘æ•°æ®åº“æŸ¥è¯¢é£æš´

è™½ç„¶ç³»ç»Ÿå®ç°äº† **Tavily Key é¢„åˆ†é…æœºåˆ¶**ï¼ˆ2025-01-01ï¼‰ï¼Œä½†æ˜¯ï¼š

1. **é¢„åˆ†é… Key å¯èƒ½è€—å°½æˆ–å¤±è´¥**
2. ç³»ç»Ÿå›é€€åˆ°**æ¨¡å¼ 2**ï¼ˆä»æ•°æ®åº“æŸ¥è¯¢ Keyï¼‰
3. `WebSearchRouter._has_valid_tavily_keys()` åœ¨æ¯æ¬¡æœç´¢å‰æŸ¥è¯¢æ•°æ®åº“
4. é«˜å¹¶å‘åœºæ™¯ä¸‹ï¼Œæ­¤æ–¹æ³•è¢«å¤§é‡è°ƒç”¨ï¼Œå¯¼è‡´è¿æ¥æ± è€—å°½

**ä»£ç è·¯å¾„**ï¼š
```python
# backend/app/tools/search/web_search_router.py

async def _has_valid_tavily_keys(self, db_session: AsyncSession) -> bool:
    """æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰å¯ç”¨çš„ Tavily API Key"""
    repo = TavilyKeyRepository(db_session)
    key_record = await repo.get_best_key()  # ğŸ”´ é«˜å¹¶å‘æ—¶è¿æ¥æ± è€—å°½
    return key_record is not None
```

---

## è§£å†³æ–¹æ¡ˆ

### ğŸ”¥ ç«‹å³ä¿®å¤ï¼šä¼˜åŒ– Tavily Key å¯ç”¨æ€§æ£€æŸ¥

#### ä¿®æ”¹æ–‡ä»¶
`backend/app/tools/search/web_search_router.py`

#### ä¼˜åŒ–å†…å®¹

1. **æ·»åŠ è¶…æ—¶ä¿æŠ¤**ï¼ˆ5ç§’ï¼‰
   - é¿å…åœ¨è¿æ¥æ± è€—å°½æ—¶é•¿æ—¶é—´é˜»å¡
   - è¶…æ—¶åå¿«é€Ÿå¤±è´¥ï¼Œå›é€€åˆ° DuckDuckGo

2. **è¿æ¥æ± é”™è¯¯å¿«é€Ÿè¯†åˆ«**
   - æ•è· `TimeoutError` å’ŒåŒ…å« "pool" å…³é”®å­—çš„é”™è¯¯
   - è®°å½•ä¸“é—¨çš„è­¦å‘Šæ—¥å¿—ï¼Œä¾¿äºç›‘æ§

3. **é”™è¯¯æ—¥å¿—ä¼˜åŒ–**
   - åŒºåˆ†è¿æ¥æ± è€—å°½ vs å…¶ä»–é”™è¯¯
   - æˆªæ–­é”™è¯¯ä¿¡æ¯ï¼ˆæœ€å¤š 200 å­—ç¬¦ï¼‰ï¼Œé¿å…æ—¥å¿—çˆ†ç‚¸

**ä¼˜åŒ–åçš„ä»£ç **ï¼š
```python
async def _has_valid_tavily_keys(self, db_session: AsyncSession) -> bool:
    try:
        import asyncio
        from app.db.repositories.tavily_key_repo import TavilyKeyRepository
        
        repo = TavilyKeyRepository(db_session)
        
        # ğŸ›¡ï¸ è¶…æ—¶ä¿æŠ¤ï¼š5ç§’å†…å¿…é¡»å®ŒæˆæŸ¥è¯¢
        key_record = await asyncio.wait_for(
            repo.get_best_key(),
            timeout=5.0
        )
        return key_record is not None
        
    except asyncio.TimeoutError:
        # è¿æ¥æ± è€—å°½æˆ–æ•°æ®åº“å“åº”æ…¢ï¼Œå¿«é€Ÿå¤±è´¥
        logger.warning(
            "web_search_router_tavily_check_timeout",
            message="Tavily Key æŸ¥è¯¢è¶…æ—¶ï¼ˆå¯èƒ½æ˜¯è¿æ¥æ± è€—å°½ï¼‰ï¼Œå›é€€åˆ° DuckDuckGo"
        )
        return False
    except Exception as e:
        # å…¶ä»–é”™è¯¯ï¼ˆåŒ…æ‹¬è¿æ¥æ±  TimeoutErrorï¼‰
        error_msg = str(e).lower()
        if "pool" in error_msg or "timeout" in error_msg:
            logger.warning(
                "web_search_router_tavily_check_pool_exhausted",
                error=str(e)[:200],
                message="è¿æ¥æ± è€—å°½ï¼Œè·³è¿‡ Tavily æ£€æŸ¥"
            )
        else:
            logger.warning(
                "web_search_router_tavily_check_failed",
                error=str(e)[:200]
            )
        return False
```

---

### ğŸ› ï¸ æ¨èé…ç½®ï¼šè°ƒæ•´è¿æ¥æ± å’Œå¹¶å‘

#### æ–¹æ¡ˆ Aï¼šæå‡è¿æ¥æ± å¤§å°ï¼ˆçŸ­æœŸï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šPostgreSQL è‡ªå»ºæ•°æ®åº“ï¼ˆmax_connections >= 100ï¼‰

```bash
# .env é…ç½®
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=10
# æ€»è¿æ¥æ•° = 10 + 10 = 20 ä¸ª/è¿›ç¨‹
# 7 ä¸ªè¿›ç¨‹ Ã— 20 = 140 ä¸ªè¿æ¥ï¼ˆéœ€è¦æ•°æ®åº“æ”¯æŒï¼‰
```

#### æ–¹æ¡ˆ Bï¼šé™ä½å¹¶å‘æ•°ï¼ˆæ¨èï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šSupabase å…è´¹ç‰ˆï¼ˆ60 è¿æ¥é™åˆ¶ï¼‰

```bash
# .env é…ç½®
DB_POOL_SIZE=3
DB_MAX_OVERFLOW=2
CELERY_CONTENT_CONCURRENCY=4  # ä» 6 é™åˆ° 4
# æ€»è¿æ¥æ•° = (3 + 2) Ã— 5 è¿›ç¨‹ = 25 ä¸ªè¿æ¥ < 60 âœ…
```

**è¿æ¥æ•°è®¡ç®—**ï¼š
```
Celery Content Worker è¿›ç¨‹æ•° = 1 ä¸»è¿›ç¨‹ + 4 å·¥ä½œè¿›ç¨‹ = 5 ä¸ª
æ¯è¿›ç¨‹è¿æ¥æ•° = 3 + 2 = 5 ä¸ª
æ€»è¿æ¥æ•° = 5 Ã— 5 = 25 ä¸ª < 60ï¼ˆå®‰å…¨ï¼‰
```

#### æ–¹æ¡ˆ Cï¼šæ··åˆä¼˜åŒ–ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

```bash
# .env é…ç½®
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=3
CELERY_CONTENT_CONCURRENCY=4

# æ€»è¿æ¥æ•° = (5 + 3) Ã— 5 = 40 ä¸ª
# é¢„ç•™ 20 ä¸ªç»™ FastAPI å’Œå…¶ä»–æœåŠ¡
```

---

## æ•ˆæœéªŒè¯

### é¢„æœŸç»“æœ

1. **é”™è¯¯æ—¥å¿—å‡å°‘**
   - `tavily_get_best_key_failed` ä¸å†é¢‘ç¹å‡ºç°
   - è¿æ¥æ± è€—å°½é”™è¯¯æ¶ˆå¤±

2. **DuckDuckGo å›é€€æ›´å¿«**
   - ä» 60 ç§’è¶…æ—¶é™è‡³ 5 ç§’å¿«é€Ÿå¤±è´¥
   - ç”¨æˆ·ä½“éªŒæå‡ï¼ˆæœç´¢ç»“æœæ›´å¿«è¿”å›ï¼‰

3. **è¿æ¥æ± ä½¿ç”¨ç‡ä¸‹é™**
   - Prometheus æŒ‡æ ‡ `db_pool_connections_in_use` < 80%
   - é«˜å³°æœŸä¸å†è§¦å‘ `db_pool_critical_usage` è­¦å‘Š

### ç›‘æ§æŒ‡æ ‡

```promql
# è¿æ¥æ± ä½¿ç”¨ç‡
(db_pool_connections_in_use / db_pool_size) > 0.8

# è¿æ¥æ± è¶…æ—¶æ¬¡æ•°
rate(db_pool_connection_timeouts_total[5m]) > 0
```

---

## é•¿æœŸä¼˜åŒ–å»ºè®®

### 1. å®Œå…¨ç§»é™¤æ¨¡å¼ 2ï¼ˆæ•°æ®åº“æŸ¥è¯¢æ¨¡å¼ï¼‰

**åŸå› **ï¼š
- é¢„åˆ†é…æœºåˆ¶å·²ç»å®ç°ï¼Œæ¨¡å¼ 2 æ˜¯å†—ä½™çš„
- åœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹ï¼Œæ¨¡å¼ 2 ä¼šå¯¼è‡´è¿æ¥æ± è€—å°½

**å®æ–½æ­¥éª¤**ï¼š
1. ç¡®ä¿ Tavily Key é¢„åˆ†é…æœºåˆ¶ 100% è¦†ç›–
2. ç§»é™¤ `_has_valid_tavily_keys()` æ–¹æ³•
3. å¼ºåˆ¶æ‰€æœ‰æœç´¢ä½¿ç”¨é¢„åˆ†é… Key æˆ–ç›´æ¥å›é€€åˆ° DuckDuckGo

### 2. æ·»åŠ  Concept çº§åˆ«å¹¶å‘æ§åˆ¶

**å½“å‰é—®é¢˜**ï¼š
- å•ä¸ªè·¯çº¿å›¾çš„ 30 ä¸ª Concept æ— é™åˆ¶å¹¶å‘
- å¯èƒ½å¯¼è‡´æ•°æ®åº“è¿æ¥ã€HTTP è¿æ¥ã€LLM è°ƒç”¨å…¨éƒ¨è€—å°½

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# backend/app/tasks/content_generation_tasks.py

# æ·»åŠ  Concept çº§åˆ«çš„å¹¶å‘é™åˆ¶
CONCEPT_CONCURRENCY_LIMIT = 10  # æœ€å¤š 10 ä¸ª Concept åŒæ—¶ç”Ÿæˆ

async def _generate_content_parallel(...):
    concept_semaphore = asyncio.Semaphore(CONCEPT_CONCURRENCY_LIMIT)
    
    async def generate_with_limit(concept):
        async with concept_semaphore:
            return await generate_single_concept(concept)
    
    tasks = [generate_with_limit(c) for c in concepts]
    results = await asyncio.gather(*tasks)
```

### 3. Redis ç¼“å­˜ Tavily Key å¯ç”¨æ€§

**å®æ–½æ–¹æ¡ˆ**ï¼š
```python
# backend/app/tools/search/web_search_router.py

async def _has_valid_tavily_keys(self, db_session: AsyncSession) -> bool:
    # å°è¯•ä» Redis è¯»å–ç¼“å­˜
    cache_key = "tavily:keys:available"
    cached_value = await redis_client.get(cache_key)
    
    if cached_value is not None:
        return bool(int(cached_value))
    
    # ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
    repo = TavilyKeyRepository(db_session)
    key_record = await repo.get_best_key()
    available = key_record is not None
    
    # ç¼“å­˜ç»“æœï¼ˆTTL 30 ç§’ï¼‰
    await redis_client.setex(cache_key, 30, int(available))
    
    return available
```

---

## å®æ–½æ£€æŸ¥æ¸…å•

- [x] ä¼˜åŒ– `_has_valid_tavily_keys()` æ–¹æ³•ï¼ˆæ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼‰
- [ ] è°ƒæ•´ `.env` é…ç½®ï¼ˆDB_POOL_SIZEã€CELERY_CONTENT_CONCURRENCYï¼‰
- [ ] é‡å¯ Celery Content Worker
- [ ] ç›‘æ§æ—¥å¿—ï¼Œç¡®è®¤ `tavily_get_best_key_failed` ä¸å†é¢‘ç¹å‡ºç°
- [ ] éªŒè¯ DuckDuckGo å›é€€æœºåˆ¶æ­£å¸¸å·¥ä½œ
- [ ] ç›‘æ§ Prometheus æŒ‡æ ‡ï¼Œç¡®è®¤è¿æ¥æ± ä½¿ç”¨ç‡ < 80%
- [ ] é•¿æœŸä¼˜åŒ–ï¼šæ·»åŠ  Concept çº§åˆ«å¹¶å‘æ§åˆ¶
- [ ] é•¿æœŸä¼˜åŒ–ï¼šç§»é™¤æ¨¡å¼ 2ï¼Œå¼ºåˆ¶ä½¿ç”¨é¢„åˆ†é…æœºåˆ¶

---

## ç›¸å…³æ–‡æ¡£

- [20250101_Tavily_Keyé¢„åˆ†é…ä¼˜åŒ–.md](./20250101_Tavily_Keyé¢„åˆ†é…ä¼˜åŒ–.md) - Tavily Key é¢„åˆ†é…æœºåˆ¶å®æ–½
- [20251231_å¹¶å‘æ§åˆ¶æœºåˆ¶åˆ†æ.md](./20251231_å¹¶å‘æ§åˆ¶æœºåˆ¶åˆ†æ.md) - ä¸¤å±‚å¹¶å‘æ¶æ„åˆ†æ
- [20250101_è¿æ¥æ± è€—å°½ä¿®å¤å†å².md](./20250101_è¿æ¥æ± è€—å°½ä¿®å¤å†å².md) - å†å²è¿æ¥æ± é—®é¢˜ä¿®å¤
- [20251231_Railwayè¿æ¥æ± è€—å°½ä¿®å¤.md](./20251231_Railwayè¿æ¥æ± è€—å°½ä¿®å¤.md) - Railway éƒ¨ç½²è¿æ¥æ± é…ç½®

---

## é™„å½•ï¼šQueuePool é…ç½®ä½ç½®

### ä¸»æ•°æ®åº“è¿æ¥æ± 

**é…ç½®æ–‡ä»¶**ï¼š`backend/app/db/session.py`

```python
new_engine = create_async_engine(
    settings.DATABASE_URL,
    pool_size=settings.DB_POOL_SIZE,      # ä»ç¯å¢ƒå˜é‡è¯»å–
    max_overflow=settings.DB_MAX_OVERFLOW, # ä»ç¯å¢ƒå˜é‡è¯»å–
    pool_pre_ping=True,
    pool_recycle=300,
    pool_timeout=60,
)
```

**ç¯å¢ƒå˜é‡**ï¼š`backend/app/config/settings.py`

```python
DB_POOL_SIZE: int = Field(2, description="æ•°æ®åº“è¿æ¥æ± åŸºç¡€å¤§å°")
DB_MAX_OVERFLOW: int = Field(2, description="æ•°æ®åº“è¿æ¥æ± æœ€å¤§æº¢å‡ºæ•°")
```

### LangGraph Checkpointer è¿æ¥æ± 

**é…ç½®æ–‡ä»¶**ï¼š`backend/app/core/orchestrator_factory.py`

```python
cls._connection_pool = AsyncConnectionPool(
    conninfo=settings.CHECKPOINTER_DATABASE_URL,
    min_size=2,
    max_size=20,  # ç‹¬ç«‹é…ç½®ï¼Œä¸å— DB_POOL_SIZE å½±å“
    timeout=60,
)
```

**æ³¨æ„**ï¼š
- ä¸»æ•°æ®åº“è¿æ¥æ± å’Œ LangGraph è¿æ¥æ± æ˜¯**ç‹¬ç«‹çš„**
- æœ¬æ¬¡é—®é¢˜æ¶‰åŠçš„æ˜¯**ä¸»æ•°æ®åº“è¿æ¥æ± **
- LangGraph è¿æ¥æ± ä½¿ç”¨ psycopg `AsyncConnectionPool`ï¼Œä¸æ˜¯ SQLAlchemy QueuePool

