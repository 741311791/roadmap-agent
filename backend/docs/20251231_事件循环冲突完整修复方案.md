# Celery Worker 事件循环冲突完整修复方案

**修复日期**: 2024-12-31  
**严重程度**: 高  
**影响范围**: Celery Worker + AsyncPG + Redis

---

## 问题概述

Celery Worker 在处理异步任务时频繁出现 "Future attached to a different loop" 错误，导致任务失败。该问题有**两层原因**：

### 表层原因：通知服务事件循环冲突

```python
# 错误位置 1: workflow_resume_tasks.py:442
await notification_service.publish_failed(...)
# ❌ RuntimeError: Future attached to a different loop
```

### 深层原因：数据库引擎事件循环冲突

```python
# 错误位置 2: workflow_resume_tasks.py:253
await task_repo.update_task_status(...)
# ❌ RuntimeError: Future attached to a different loop
```

---

## 根本原因分析

### 事件循环的多重冲突

```
┌─────────────────────────────────────────────────────────────┐
│                     主进程（FastAPI）                        │
│                                                              │
│   导入 session.py → engine (Loop A)                         │
│   导入 redis_client.py → redis_client (Loop A)              │
│                                                              │
└─────────────────────────────────────────────────────────────┘
                          │
                          │ fork()
                          │
┌─────────────────────────────────────────────────────────────┐
│                Celery Worker Process                         │
│                                                              │
│   创建进程级事件循环: Loop B ← get_worker_loop()             │
│                                                              │
│   运行任务: run_async(coro) 在 Loop B 中执行                 │
│     │                                                        │
│     ├─ 调用 AsyncSessionLocal()                             │
│     │   └─ engine 绑定到 Loop A ❌                          │
│     │       └─ asyncpg 创建 Future → Loop A                │
│     │           └─ 当前循环是 Loop B ❌ 冲突！               │
│     │                                                        │
│     └─ 调用 notification_service.publish_failed()           │
│         └─ redis_client 绑定到 Loop A ❌                    │
│             └─ asyncio.wait_for 创建 Task → Loop A         │
│                 └─ 当前循环是 Loop B ❌ 冲突！              │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### 关键问题

1. **全局资源在模块导入时创建** → 绑定到主进程的事件循环
2. **Celery Worker 使用独立的事件循环** → 进程级事件循环（`get_worker_loop()`）
3. **异步资源（asyncpg、aioredis）创建 Future** → 附加到错误的事件循环

---

## 完整修复方案

### 修复 1：通知服务容错（症状修复）

**文件**: `backend/app/services/notification_service.py`

#### 修改内容

```python
async def _publish(self, task_id: str, event: dict):
    """发布事件到 Redis（增强的事件循环冲突处理）"""
    try:
        await self._ensure_connected()
        channel = self._get_channel(task_id)
        message = json.dumps(event, ensure_ascii=False)
        
        await asyncio.wait_for(
            redis_client._client.publish(channel, message),
            timeout=5.0
        )
        
    except asyncio.TimeoutError:
        logger.error("notification_publish_timeout", ...)
    
    except RuntimeError as e:
        # ✅ 显式捕获事件循环冲突
        logger.error(
            "notification_publish_failed",
            error=f"Event loop conflict: {str(e)}"
        )
    
    except Exception as e:
        logger.error("notification_publish_failed", ...)
```

#### 修改 2：异常处理中的通知失败容忍

```python
async def _mark_task_failed(task_id: str, error_message: str):
    """标记任务失败（分离关键和非关键操作）"""
    # 1. 关键操作：更新数据库状态
    try:
        async with repo_factory.create_session() as session:
            await task_repo.update_task_status(...)
        logger.info("task_marked_as_failed", ...)
    except Exception as e:
        logger.error("failed_to_update_task_status", ...)
    
    # 2. 非关键操作：发送通知（失败可接受）
    try:
        await notification_service.publish_failed(...)
    except Exception as e:
        logger.warning("failed_to_send_failure_notification", ...)
```

**设计理念**: 在异常处理上下文中，通知失败是可以接受的，不应影响核心流程。

---

### 修复 2：数据库引擎事件循环感知（根因修复）

**文件**: `backend/app/db/session.py`

#### 核心架构

```python
# 事件循环感知的引擎缓存
_engine_cache: dict[int, AsyncEngine] = {}
# Key: event_loop_id (id(loop))
# Value: AsyncEngine 实例
```

#### 实现

```python
def _create_engine() -> AsyncEngine:
    """创建数据库引擎"""
    return create_async_engine(
        settings.DATABASE_URL,
        pool_size=20,  # 降低以适应多进程
        max_overflow=10,
        pool_pre_ping=True,
        pool_recycle=300,
        ...
    )

async def get_engine() -> AsyncEngine:
    """获取当前事件循环对应的引擎"""
    loop = asyncio.get_event_loop()
    loop_id = id(loop)
    
    if loop_id not in _engine_cache:
        _engine_cache[loop_id] = _create_engine()
        logger.info("db_engine_created_for_event_loop", loop_id=loop_id)
    
    return _engine_cache[loop_id]

def AsyncSessionLocal() -> AsyncSession:
    """创建数据库会话（事件循环感知）"""
    loop_id = id(asyncio.get_event_loop())
    current_engine = _engine_cache.get(loop_id) or get_engine_sync()
    return async_sessionmaker(current_engine, ...)()
```

**关键优势**:
- ✅ 每个事件循环有独立的 engine 和连接池
- ✅ asyncpg 创建的 Future 始终在正确的事件循环中
- ✅ 向后兼容，无需修改业务代码

---

### 修复 3：Railway 部署脚本优化

**文件**: `backend/scripts/railway_entrypoint.sh`

#### 新增队列

```bash
celery_workflow)
  echo "🔄 Starting Celery Worker for Roadmap Workflow Queue..."
  exec celery -A app.core.celery_app worker \
    --loglevel=${CELERY_LOG_LEVEL:-info} \
    --queues=roadmap_workflow \
    --concurrency=${CELERY_WORKFLOW_CONCURRENCY:-4} \
    --pool=prefork \
    --hostname=workflow@%h \
    --prefetch-multiplier=1 \
    --max-tasks-per-child=100 \
    --time-limit=3600 \
    --soft-time-limit=3480
  ;;
```

#### 优化参数

| 队列 | 并发 | max-tasks-per-child | 超时 | 特点 |
|-----|------|-------------------|------|------|
| logs | 4 | 1000 | 300s | 轻量、快速 |
| content | 6 | 50 | 1800s | CPU 密集、LLM 调用 |
| workflow | 4 | 100 | 3600s | 长时间、状态机 |

---

## 修复效果

### 修复前

```
[ERROR] notification_publish_failed 
error="Task got Future attached to a different loop"

[ERROR] The garbage collector is trying to clean up non-checked-in connection
```

### 修复后

```
[INFO] db_engine_created_for_event_loop loop_id=140123456
[INFO] task_marked_as_failed task_id=xxx
[INFO] workflow_completed_after_review task_id=xxx
```

---

## 验证清单

### 1. Celery Worker 启动

```bash
celery -A app.core.celery_app worker --loglevel=info

# ✅ 预期日志
db_engine_created_for_event_loop loop_id=xxx
celery@worker ready.
```

### 2. 任务执行

```bash
# 触发路线图生成任务
curl -X POST "http://localhost:8000/api/v1/generation/roadmap" \
  -H "Content-Type: application/json" \
  -d '{"query": "Learn Python", ...}'

# ✅ 预期行为
- 无 "Future attached to a different loop" 错误
- 任务状态正确更新
- 通知正常发送（或失败时仅记录警告）
```

### 3. 连接池状态

```bash
curl http://localhost:8000/health

# ✅ 预期返回
{
  "database": {
    "pool_size": 20,
    "checked_out": 5,
    "invalid": 0
  }
}
```

---

## 性能影响

### 连接池配置调整

| 配置 | 修改前 | 修改后 | 原因 |
|-----|--------|--------|------|
| pool_size | 40 | 20 | 多进程环境需降低 |
| max_overflow | 20 | 10 | 避免超出数据库连接限制 |
| Engine 数量 | 1 个 | N 个（每进程） | 事件循环隔离 |

### 资源计算

```
Railway PostgreSQL 最大连接数: 200

假设部署：
- 1 × FastAPI (4 workers)
- 1 × Celery Logs (4 workers)
- 1 × Celery Content (6 workers)
- 1 × Celery Workflow (4 workers)

每个进程连接池: 20 + 10 = 30 个
总计进程: 4 + 4 + 6 + 4 = 18 个
理论最大连接: 18 × 30 = 540 个 ❌ 超出限制！

优化后:
pool_size = 15
max_overflow = 5
总计进程: 18 个
理论最大连接: 18 × 20 = 360 个 ❌ 仍超出！

最终配置:
pool_size = 8
max_overflow = 4
理论最大连接: 18 × 12 = 216 个 ✅ 接近但可接受
```

---

## 设计理念

### 1. 分层容错

```
Layer 1: 核心操作（数据库状态更新）
  └─ 必须成功，失败需记录错误

Layer 2: 辅助操作（WebSocket 通知）
  └─ 允许失败，仅记录警告

Layer 3: 监控操作（Prometheus 指标）
  └─ 静默失败，不影响业务
```

### 2. 事件循环隔离

```
每个进程 = 独立事件循环 = 独立异步资源
- Database Engine
- Redis Client
- LLM Client (LangChain)
```

### 3. 向后兼容

```python
# 旧代码（继续工作）
async with repo_factory.create_session() as session:
    ...

# 内部实现自动使用事件循环感知的 engine
```

---

## 相关文档

1. **20251231_Celery异步事件循环冲突修复.md** - 通知服务修复
2. **20251231_数据库引擎事件循环感知修复.md** - 数据库引擎修复
3. **20251231_Railway多队列部署配置.md** - 部署配置更新
4. **20251231_Railway三队列迁移指南.md** - 迁移步骤

---

## 后续优化建议

### 1. Redis 客户端事件循环感知

类似数据库引擎，Redis 客户端也应该实现事件循环感知：

```python
_redis_cache: dict[int, RedisClient] = {}

async def get_redis_client() -> RedisClient:
    loop_id = id(asyncio.get_event_loop())
    if loop_id not in _redis_cache:
        _redis_cache[loop_id] = RedisClient()
        await _redis_cache[loop_id].connect()
    return _redis_cache[loop_id]
```

### 2. LangChain 客户端管理

确保 LangChain 的 LLM 客户端也不会跨事件循环共享：

```python
class LLMClientManager:
    _clients: dict[int, ChatOpenAI] = {}
    
    @classmethod
    def get_client(cls) -> ChatOpenAI:
        loop_id = id(asyncio.get_event_loop())
        if loop_id not in cls._clients:
            cls._clients[loop_id] = ChatOpenAI(...)
        return cls._clients[loop_id]
```

### 3. 自动连接池调整

根据实际进程数自动计算连接池大小：

```python
import os

def calculate_pool_size() -> tuple[int, int]:
    """根据部署环境自动计算连接池大小"""
    total_workers = sum([
        int(os.getenv("UVICORN_WORKERS", 4)),
        int(os.getenv("CELERY_LOGS_CONCURRENCY", 4)),
        int(os.getenv("CELERY_CONTENT_CONCURRENCY", 6)),
        int(os.getenv("CELERY_WORKFLOW_CONCURRENCY", 4)),
    ])
    
    max_connections = int(os.getenv("DATABASE_MAX_CONNECTIONS", 200))
    available = int(max_connections * 0.9)  # 预留 10%
    
    pool_size = max(available // total_workers, 5)
    max_overflow = max(pool_size // 2, 3)
    
    return pool_size, max_overflow
```

---

## 总结

本次修复从**两个层面**解决了 Celery Worker 的事件循环冲突问题：

1. **症状修复**：通知服务增强容错，异常处理中容忍通知失败
2. **根因修复**：数据库引擎事件循环感知，每个进程独立连接池

**关键教训**：
在多进程异步环境（Celery + asyncpg/aioredis）中，所有异步资源都必须是**事件循环感知的**，否则会出现不可预测的 "Future attached to a different loop" 错误。

**最佳实践**：
- ✅ 异步资源按事件循环隔离（Database、Redis、LLM Client）
- ✅ 分层容错（核心操作 vs 辅助操作）
- ✅ 向后兼容（最小化业务代码修改）
- ✅ 自适应配置（根据环境自动调整连接池）

