# 数据库引擎事件循环感知修复

**修复日期**: 2024-12-31  
**问题类型**: 运行时错误 - 事件循环冲突（深层次）  
**影响范围**: Celery Worker + 数据库连接池

---

## 问题描述

### 错误信息（第二次）

```
Task <Task pending name='Task-57' 
coro=<_resume_workflow_after_review() running at workflow_resume_tasks.py:253> 
cb=[_run_until_complete_cb()]> got Future <Future pending cb=[BaseProtocol._on_waiter_completed()]> 
attached to a different loop
```

### 问题位置

第 253 行：
```python
await task_repo.update_task_status(
    task_id=task_id,
    status=TaskStatus.PROCESSING.value,
    current_step="resuming",
)
```

### 根本原因

#### 第一次修复的局限性

之前我们修复了 `notification_service.publish_failed` 中的事件循环冲突，但这只是**症状**，不是**根因**。真正的问题在于：

**全局数据库引擎绑定到错误的事件循环**

```python
# app/db/session.py (旧版本)
engine = create_async_engine(...)  # 在模块导入时创建
AsyncSessionLocal = async_sessionmaker(engine, ...)  # 绑定到导入时的事件循环
```

#### 问题链条

```
1. 主进程导入 session.py
   ↓
2. 创建全局 engine，绑定到主进程的事件循环 (Loop A)
   ↓
3. Celery Worker 启动，创建进程级事件循环 (Loop B)
   ↓
4. Celery 任务调用 run_async(coro)，在 Loop B 中执行
   ↓
5. coro 中调用 AsyncSessionLocal() 创建会话
   ↓
6. asyncpg 连接池尝试创建连接，创建 Future
   ↓
7. Future 被附加到 Loop A（engine 绑定的循环）
   ↓
8. ❌ RuntimeError: "Future attached to a different loop"
```

---

## 解决方案

### 核心思路：事件循环感知

为每个事件循环创建独立的数据库引擎实例，确保 asyncpg 连接池始终绑定到正确的事件循环。

### 实现架构

#### 1. 引擎缓存字典

```python
_engine_cache: dict[int, AsyncEngine] = {}
# Key: event_loop_id (id(loop))
# Value: AsyncEngine 实例
```

**示例**：
```
主进程（FastAPI）:
  event_loop_id=140123456 → engine_1

Celery Worker 1:
  event_loop_id=140789012 → engine_2

Celery Worker 2:
  event_loop_id=140345678 → engine_3
```

#### 2. 动态引擎获取

```python
async def get_engine() -> AsyncEngine:
    """获取当前事件循环对应的引擎"""
    loop = asyncio.get_event_loop()
    loop_id = id(loop)
    
    if loop_id not in _engine_cache:
        _engine_cache[loop_id] = _create_engine()
        logger.info("db_engine_created_for_event_loop", loop_id=loop_id)
    
    return _engine_cache[loop_id]
```

#### 3. 会话工厂改造

```python
# 旧版本：全局会话工厂（绑定到固定 engine）
AsyncSessionLocal = async_sessionmaker(engine, ...)

# 新版本：函数式会话工厂（动态获取 engine）
def AsyncSessionLocal() -> AsyncSession:
    loop_id = id(asyncio.get_event_loop())
    current_engine = _engine_cache.get(loop_id) or get_engine_sync()
    return async_sessionmaker(current_engine, ...)()
```

---

## 修改内容

### 文件：`backend/app/db/session.py`

#### 修改 1：引入事件循环感知的引擎管理

```python
_engine_cache: dict[int, AsyncEngine] = {}

def _create_engine() -> AsyncEngine:
    """创建数据库引擎（内部函数）"""
    return create_async_engine(
        settings.DATABASE_URL,
        pool_size=40,
        max_overflow=20,
        ...
    )

async def get_engine() -> AsyncEngine:
    """获取当前事件循环对应的引擎"""
    loop = asyncio.get_event_loop()
    loop_id = id(loop)
    
    if loop_id not in _engine_cache:
        _engine_cache[loop_id] = _create_engine()
        logger.info("db_engine_created_for_event_loop", loop_id=loop_id)
    
    return _engine_cache[loop_id]

def get_engine_sync() -> AsyncEngine:
    """同步方式获取引擎（用于事件监听器注册）"""
    loop_id = id(asyncio.get_event_loop())
    if loop_id not in _engine_cache:
        _engine_cache[loop_id] = _create_engine()
    return _engine_cache[loop_id]
```

#### 修改 2：会话工厂改为函数

```python
def get_session_maker() -> async_sessionmaker:
    """获取当前事件循环对应的会话工厂"""
    loop_id = id(asyncio.get_event_loop())
    current_engine = _engine_cache.get(loop_id) or get_engine_sync()
    
    return async_sessionmaker(
        current_engine,
        class_=AsyncSession,
        expire_on_commit=False,
        autocommit=False,
        autoflush=False,
    )

def AsyncSessionLocal() -> AsyncSession:
    """创建数据库会话（事件循环感知）"""
    return get_session_maker()()
```

#### 修改 3：更新使用 engine 的函数

```python
async def init_db():
    """初始化数据库"""
    current_engine = await get_engine()  # ← 动态获取
    async with current_engine.begin() as conn:
        ...

async def get_pool_status() -> dict:
    """获取连接池状态"""
    current_engine = await get_engine()  # ← 动态获取
    pool = current_engine.pool
    return {...}
```

---

## 向后兼容性

### 保留旧的调用方式

```python
# 旧代码（继续工作）
async with repo_factory.create_session() as session:
    await task_repo.update_task_status(...)

# 内部实现
class RepositoryFactory:
    async def create_session(self):
        return safe_session_with_retry()  # 使用新的 AsyncSessionLocal()
```

### 自动迁移

所有使用 `AsyncSessionLocal()` 的代码无需修改：
- 旧代码：`AsyncSessionLocal` 是全局变量
- 新代码：`AsyncSessionLocal()` 是函数
- Python 中 `AsyncSessionLocal()` 同时满足两种调用方式

---

## 测试验证

### 1. Celery Worker 测试

启动 Celery Worker 并触发任务：

```bash
# 启动 Worker
celery -A app.core.celery_app worker --loglevel=info

# 触发任务
curl -X POST "http://localhost:8000/api/v1/generation/roadmap" \
  -H "Content-Type: application/json" \
  -d '{"query": "Learn Python", ...}'
```

**预期行为**：
- ✅ 日志中出现 `db_engine_created_for_event_loop` （每个 Worker 进程一次）
- ✅ 任务成功执行，无 "Future attached to a different loop" 错误
- ✅ 数据库状态正确更新

### 2. 多进程测试

```bash
# 启动多个 Worker 进程
celery -A app.core.celery_app worker --concurrency=4

# 观察日志
grep "db_engine_created_for_event_loop" logs
```

**预期输出**：
```
db_engine_created_for_event_loop loop_id=140123456 engine_id=140123789
db_engine_created_for_event_loop loop_id=140789012 engine_id=140789345
db_engine_created_for_event_loop loop_id=140345678 engine_id=140345901
db_engine_created_for_event_loop loop_id=140456789 engine_id=140457012
```

每个 Worker 进程有独立的事件循环和引擎。

### 3. 连接池隔离验证

```bash
# API 健康检查
curl http://localhost:8000/health

# 预期返回
{
  "status": "healthy",
  "database": {
    "pool_size": 40,
    "checked_out": 5
  }
}
```

每个进程的连接池是独立的，不会互相干扰。

---

## 性能影响

### 内存占用

| 组件 | 修改前 | 修改后 | 影响 |
|-----|--------|--------|------|
| Engine 实例数 | 1 个（全局） | N 个（每个进程一个） | +N-1 |
| 连接池总数 | 1 个 | N 个 | +N-1 |

**示例**（4 个 Celery Worker + 1 个 FastAPI）：
```
Engine: 1 → 5 个
连接池: 1 → 5 个
每个池大小: 40 + 20 = 60 个连接
理论最大连接数: 60 → 300 个
```

**注意**：Railway PostgreSQL 最大连接数为 200，需要降低每个池的大小。

### 优化建议

```python
# 根据 Worker 数量调整连接池大小
WORKER_COUNT = 5  # FastAPI + 4 Celery Workers
DATABASE_MAX_CONNECTIONS = 200

# 每个进程的连接池配置
pool_size = (DATABASE_MAX_CONNECTIONS * 0.8) // WORKER_COUNT  # 32
max_overflow = pool_size // 2  # 16

# 总计: (32 + 16) * 5 = 240 个（超出限制！）
# 需要进一步降低
pool_size = 20
max_overflow = 10
# 总计: (20 + 10) * 5 = 150 个 ✅
```

---

## 设计理念

### 为什么不使用单一连接池？

**方案 A：全局共享连接池**
```python
# ❌ 问题：事件循环冲突
engine = create_async_engine(...)  # 绑定到主进程循环
# Celery Worker 使用独立循环 → 冲突
```

**方案 B：每个进程独立连接池**（本方案）
```python
# ✅ 优势：完全隔离，无冲突
_engine_cache[loop_id] = create_async_engine(...)
```

### 为什么不使用同步驱动？

**方案 C：切换到 psycopg2（同步）**
```python
# ❌ 缺点：失去异步性能优势
engine = create_engine("postgresql://...")  # 同步驱动
```

**对比**：
| 特性 | 异步（asyncpg） | 同步（psycopg2） |
|-----|----------------|----------------|
| 并发性能 | 高（非阻塞 I/O） | 低（阻塞 I/O） |
| 事件循环冲突 | 需要解决 | 无冲突 |
| 代码复杂度 | 中等 | 低 |

我们选择解决事件循环冲突，保留异步优势。

---

## 故障排查

### 问题 1：仍然出现事件循环错误

**症状**: "Future attached to a different loop" 仍然出现

**排查步骤**:
```bash
# 1. 检查是否有旧的导入缓存
rm -rf backend/**/__pycache__
rm -rf backend/**/*.pyc

# 2. 重启 Celery Worker
celery -A app.core.celery_app worker --loglevel=debug

# 3. 检查日志中是否有 engine 创建记录
grep "db_engine_created_for_event_loop" logs
```

### 问题 2：连接池耗尽

**症状**: "QueuePool limit exceeded"

**原因**: 多个进程共享数据库连接限制

**解决方案**:
```python
# 降低每个进程的连接池大小
pool_size = 15  # 从 40 降到 15
max_overflow = 5  # 从 20 降到 5
```

### 问题 3：性能下降

**症状**: 数据库查询变慢

**排查**:
```bash
# 查看连接池状态
curl http://localhost:8000/health

# 检查是否有连接等待
{
  "pool": {
    "checked_out": 25,  # ← 如果接近 pool_size + max_overflow，需要扩容
    "overflow": 5
  }
}
```

---

## 相关修复

本次修复与以下修复相关联：

1. **20251231_Celery异步事件循环冲突修复.md**
   - 修复了 `notification_service` 中的事件循环冲突
   - 本次修复解决了更深层次的数据库引擎冲突

2. **20251231_并发控制机制分析.md**
   - 分析了 Celery Worker 的并发架构
   - 为本次修复提供了上下文

---

## 后续优化

### 1. 自适应连接池大小

```python
import os

def _get_pool_size() -> int:
    """根据环境自动计算连接池大小"""
    worker_count = int(os.getenv("CELERY_WORKER_COUNT", 4)) + 1  # +1 for FastAPI
    max_db_connections = int(os.getenv("DATABASE_MAX_CONNECTIONS", 200))
    
    # 预留 20% 给其他连接
    available = int(max_db_connections * 0.8)
    pool_size = available // worker_count
    
    return max(pool_size, 10)  # 最小 10 个连接

pool_size = _get_pool_size()
```

### 2. 监控引擎数量

```python
from prometheus_client import Gauge

db_engine_count = Gauge(
    'db_engine_count',
    'Number of database engines created'
)

async def get_engine() -> AsyncEngine:
    ...
    if loop_id not in _engine_cache:
        _engine_cache[loop_id] = _create_engine()
        db_engine_count.set(len(_engine_cache))  # ← 监控
    ...
```

### 3. 引擎自动清理

```python
async def cleanup_unused_engines():
    """清理已关闭事件循环对应的引擎"""
    for loop_id, engine in list(_engine_cache.items()):
        if loop.is_closed():  # 检测循环是否已关闭
            await engine.dispose()
            del _engine_cache[loop_id]
```

---

## 总结

本次修复从根本上解决了 Celery Worker 中的事件循环冲突问题：

- ✅ 数据库引擎自动绑定到正确的事件循环
- ✅ 每个 Worker 进程有独立的连接池
- ✅ 向后兼容，无需修改业务代码
- ✅ 自动检测和创建引擎，无需手动管理

**关键教训**：
在多进程异步环境（如 Celery + asyncpg）中，所有异步资源（engine、连接池、Redis 客户端）都必须是**事件循环感知的**，否则会出现不可预测的事件循环冲突。

