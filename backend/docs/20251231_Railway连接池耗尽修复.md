# Railway 数据库连接池耗尽修复方案

## 问题症状

```
[2025-12-31 08:33:57,850: WARNING/ForkPoolWorker-3] 
tutorial_save_failed concept_id=agent-performance-optimization-x5y9z2q8:c-2-2-1 
error='QueuePool limit of size 40 overflow 20 reached, connection timed out, timeout 60.00'
```

## 第一性原理分析

### 问题本质

**连接池 = 有限共享资源**
- 健康状态：借出速度 ≈ 归还速度
- 问题状态：借出速度 >> 归还速度

### 根本原因

不是连接泄漏，而是**架构设计导致的连接需求超出数据库容量**。

#### 数学推导

```
# Railway部署架构
API Worker:          4 进程
Celery Logs:         4 进程
Celery Content:      6 进程  ← 错误发生在这里
Celery Workflow:     4 进程
─────────────────────────────
总计:               18 进程

# 原配置（硬编码）
pool_size = 40
max_overflow = 20
每进程连接数 = 60

# 总连接需求
总需求 = 18 × 60 = 1,080 个连接

# Railway PostgreSQL 实际容量
max_connections ≈ 200 个

# 结果
1,080 > 200  →  连接池耗尽 ❌
```

#### 事件循环隔离加剧问题

由于之前修复的"事件循环冲突"（详见 `20251231_数据库引擎事件循环感知修复.md`），系统采用了**每进程独立engine**策略：

```python
# session.py
_engine_cache: dict[int, AsyncEngine] = {}

async def get_engine() -> AsyncEngine:
    loop = asyncio.get_running_loop()
    loop_id = id(loop)
    
    if loop_id not in _engine_cache:
        _engine_cache[loop_id] = _create_engine()  # 每个进程独立创建
```

**后果：** 连接池配置会被**乘以进程数**，导致总连接需求爆炸式增长。

## 解决方案

### 核心策略

通过**环境变量动态配置连接池大小**，适配不同部署环境：
- 本地开发：保持较大值（单进程，无压力）
- Railway生产：使用较小值（多进程，需严格控制）

### 代码修改

#### 1. Settings 配置（`app/config/settings.py`）

```python
# 连接池配置（针对多进程部署优化）
DB_POOL_SIZE: int = Field(
    40, 
    description="数据库连接池基础大小（本地开发默认40，Railway生产环境建议5）"
)
DB_MAX_OVERFLOW: int = Field(
    20, 
    description="数据库连接池最大溢出数（本地开发默认20，Railway生产环境建议3）"
)
```

#### 2. Engine 创建（`app/db/session.py`）

```python
def _create_engine() -> AsyncEngine:
    return create_async_engine(
        settings.DATABASE_URL,
        pool_size=settings.DB_POOL_SIZE,      # 从环境变量读取
        max_overflow=settings.DB_MAX_OVERFLOW, # 从环境变量读取
        # ... 其他配置
    )
```

### Railway 环境变量配置

在所有服务中添加以下环境变量：

```bash
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=3
```

#### 验证计算

```
每进程连接数 = 5 + 3 = 8
总连接需求 = 18 × 8 = 144 个
Railway容量 = 200 个

144 < 200  →  安全 ✅
剩余余量 = 200 - 144 = 56 个（28%）
```

## 性能影响评估

### 疑问：降低连接池会影响性能吗？

**答案：不会，因为内容生成任务的瓶颈不在数据库。**

#### 任务执行流程分析

```python
async def generate_concept_content(concept_id):
    # 1. 从数据库读取概念信息（<100ms）
    concept = await db.get(concept_id)
    
    # 2. 调用 LLM 生成内容（5-30秒）← 真正的瓶颈
    content = await llm.generate(concept.description)
    
    # 3. 保存到数据库（<200ms）
    await db.save(concept_id, content)
```

**时间占比：**
- 数据库操作：~300ms（<2%）
- LLM API调用：~20秒（>98%）

**结论：** 即使连接池从60降到8，也只会增加数据库等待时间（如果真的有并发），但LLM API才是真正的瓶颈。

### 实际并发度

```python
# Content Worker 配置
concurrency=6  # 6个进程

# 但每个进程内部是串行处理任务的（一次一个任务）
# 因此真实并发 = 6 个任务
# 每个任务需要的数据库连接 ≈ 1-2 个

# 实际需要的连接池 = 6 × 2 = 12 个
# 配置的连接池 = 6 × 8 = 48 个（充足）
```

## 部署步骤

### 1. 提交代码

```bash
cd backend
git add app/config/settings.py app/db/session.py
git commit -m "fix: 通过环境变量动态配置数据库连接池"
git push
```

### 2. 配置 Railway 环境变量

在Railway项目中，为**所有4个服务**添加环境变量：

| 服务 | 添加环境变量 |
|------|-------------|
| `roadmap-agent-api` | `DB_POOL_SIZE=5`<br>`DB_MAX_OVERFLOW=3` |
| `celery-logs` | `DB_POOL_SIZE=5`<br>`DB_MAX_OVERFLOW=3` |
| `celery-content` | `DB_POOL_SIZE=5`<br>`DB_MAX_OVERFLOW=3` |
| `celery-workflow` | `DB_POOL_SIZE=5`<br>`DB_MAX_OVERFLOW=3` |

### 3. 重新部署

Railway 会自动检测到环境变量变化并重新部署所有服务。

### 4. 验证修复

```bash
# 1. 创建新的路线图生成任务
# 2. 观察日志，确认不再出现 "QueuePool limit" 错误
# 3. 检查内容生成阶段能否正常完成
```

## 监控指标

修复后，可通过以下指标验证健康状态：

```python
# 访问健康检查端点
GET http://your-api.railway.app/health

# 关注以下指标
{
  "database": {
    "pool_size": 5,
    "max_overflow": 3,
    "checked_out": 2,        # 当前使用中的连接（应该 << 8）
    "overflow": 0,           # 溢出连接数（应该 = 0 或很小）
    "pool_total": 5          # 池中总连接数
  }
}
```

**健康标准：**
- `checked_out < pool_size`：大部分时间成立
- `overflow = 0`：大部分时间成立
- 如果频繁出现 `overflow > 0`，说明连接池不足，可适当增加

## 未来优化方向

### 方案 A：差异化配置

不同服务使用不同的连接池大小：

```bash
# API服务（高频短连接）
DB_POOL_SIZE=8
DB_MAX_OVERFLOW=4

# Content Worker（低频长连接）
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=3

# Logs Worker（批量写入）
DB_POOL_SIZE=3
DB_MAX_OVERFLOW=2
```

### 方案 B：动态计算

根据数据库实际容量和进程数自动计算：

```python
def calculate_pool_size() -> tuple[int, int]:
    max_connections = get_db_max_connections()  # 通过 SQL 查询
    total_processes = detect_total_processes()  # 环境变量
    
    available = int(max_connections * 0.8)  # 预留20%
    per_process = available // total_processes
    
    pool_size = max(per_process // 2, 3)
    max_overflow = max(per_process // 4, 2)
    
    return pool_size, max_overflow
```

### 方案 C：使用 PgBouncer

在PostgreSQL前面加一层连接池代理：
- 应用侧可以使用较大的连接池
- PgBouncer 负责实际的连接复用
- Railway 暂不支持，需自行部署

## 总结

| 维度 | 原因 | 修复 |
|------|------|------|
| **问题本质** | 架构设计缺陷（多进程 × 大连接池） | 动态配置连接池 |
| **触发条件** | Railway多进程部署 + 数据库连接限制 | 根据环境调整 |
| **影响范围** | 所有Celery Worker | 所有服务统一配置 |
| **性能影响** | 无（瓶颈在LLM API） | 可忽略 |
| **修复成本** | 低（仅环境变量） | 无需改代码逻辑 |

**关键教训：** 在设计多进程架构时，必须考虑**每进程独立资源 × 进程数**的乘数效应。

