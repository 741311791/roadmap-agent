# 任务重试逻辑修复 - 主应用与Worker检测不一致

## 问题现象

```bash
# 主应用日志
found_missing_concepts_in_database missing_count=21

# Worker日志
no_failed_items_to_retry

# 结果
retried_count=0  # 没有重试任何项目
```

## 第一性原理分析

### 现象拆解

1. **主应用：** 检测到21个missing concepts（数据库中不存在）
2. **主应用：** 构造`items_to_retry`列表，包含这21个concept
3. **主应用：** 调用Celery Worker进行重试
4. **Worker：** 报告"no_failed_items_to_retry"
5. **结果：** 任务成功完成，但retried_count=0（什么都没做）

### 核心矛盾

**主应用认为有21个项目需要重试，Worker认为没有**

这说明双方对"需要重试"的判断标准不一致。

### 根本原因

#### 主应用逻辑（retry.py）

```python
# 查询数据库中已完成的教程
completed_tutorials = await roadmap_repo.get_tutorials_by_roadmap(
    roadmap_id=roadmap_id,
    latest_only=True,
)
completed_concept_ids = {
    tutorial.concept_id 
    for tutorial in completed_tutorials 
    if tutorial.content_status == "completed"
}

# 找出缺失的概念（数据库中不存在）
missing_concept_ids = set(all_concept_ids) - completed_concept_ids
```

**判断标准：数据库中没有记录 = 需要重试**

#### Worker逻辑（content_generation_tasks.py）

```python
# 从 framework_data 中查询失败项目
failed_items = get_failed_content_items(roadmap_metadata.framework_data)

# utils.py
def get_failed_content_items(framework_data: dict):
    if concept_data.get("content_status") == "failed":
        failed_items["tutorial"].append(...)
```

**判断标准：framework_data 中 status == "failed" = 需要重试**

#### 逻辑不一致

```
主应用：检查数据库缺失 (missing from DB)
  ↓
构造 items_to_retry 列表
  ↓
调用 Worker（但没有传递这个列表！）
  ↓
Worker：重新查询 framework_data 中的 status 字段
  ↓
找到 0 个 status="failed" 的项目
```

**关键问题：主应用构造的列表没有传递给Worker！**

### 连接池耗尽的连锁反应

当连接池耗尽导致教程保存失败时：

```
1. 教程生成成功（LLM调用完成）
   ↓
2. 尝试保存到数据库
   ↓
3. 连接池耗尽 → 抛出异常
   ↓
4. 数据库中没有创建记录（missing）
   ↓
5. framework_data 中的 concept.content_status 未更新
   ↓
6. status 可能是：
   - null（初始值）
   - "processing"（开始时设置）
   - 但不是 "failed"（异常发生时没有更新）
```

**结果：**
- 主应用检测到：数据库中没有这个教程 → missing ✅
- Worker检测：framework_data 中 status != "failed" → 找不到 ❌

## 修复方案

### 核心思路

**主应用已经检测了需要重试的项目，直接传递给Worker，避免重复查询和逻辑不一致。**

### 代码修改

#### 1. Worker函数添加可选参数

```python
# backend/app/tasks/content_generation_tasks.py

def retry_failed_content_task(
    self,
    roadmap_id: str,
    task_id: str,
    user_id: str,
    preferences: dict,
    content_types: list[str],
    items_to_retry: dict | None = None,  # 新增参数
):
    """
    重试失败内容的生成（Celery 任务入口）
    
    Args:
        items_to_retry: 要重试的具体项目列表（可选，如果提供则直接使用）
    """
    
    # 如果没有提供items_to_retry，则查询（向后兼容）
    if items_to_retry is None:
        items_to_retry = run_async(_get_failed_items())
    else:
        # 使用提供的列表，但仍需要筛选content_types
        filtered_items = {}
        for content_type in content_types:
            if content_type in items_to_retry and items_to_retry[content_type]:
                filtered_items[content_type] = items_to_retry[content_type]
        items_to_retry = filtered_items
```

#### 2. API调用传递列表

```python
# backend/app/api/v1/endpoints/retry.py

# 分发 Celery 任务进行内容重试
celery_task = retry_failed_content_task.delay(
    roadmap_id=roadmap_id,
    task_id=task_id,
    user_id=user_id,
    preferences=preferences.model_dump(mode='json'),
    content_types=content_types,
    items_to_retry=items_to_retry,  # 传递主应用构造的列表
)
```

### 修复效果

#### 修复前

```
主应用：检测到21个missing concepts
  ↓
调用Worker（不传递列表）
  ↓
Worker：重新查询status="failed"
  ↓
找到0个 → 返回"没有需要重试的项目"
```

#### 修复后

```
主应用：检测到21个missing concepts
  ↓
构造items_to_retry列表（包含21个项目）
  ↓
调用Worker并传递列表
  ↓
Worker：直接使用传入的列表
  ↓
重试21个项目 ✅
```

## 设计优势

### 1. 单一数据源

**修复前：** 主应用和Worker各自查询，可能得到不同结果

**修复后：** 主应用查询一次，Worker直接使用，保证一致性

### 2. 减少数据库查询

Worker不再需要重复查询roadmap_metadata和framework_data

### 3. 向后兼容

```python
items_to_retry: dict | None = None
```

- 如果传递了列表：直接使用（新逻辑）
- 如果未传递：自动查询（旧逻辑，兼容其他调用点）

### 4. 逻辑清晰

**主应用职责：**
- 检测需要重试的项目
- 构造完整的context信息
- 分发任务

**Worker职责：**
- 接收任务参数
- 执行内容生成
- 保存结果

各司其职，不重复。

## 适用场景

### 场景1：连接池耗尽导致保存失败

```
教程生成成功 → 保存失败 → 数据库missing但status不是"failed"
```

修复后：主应用检测到missing，直接传递给Worker重试 ✅

### 场景2：正常失败（status已标记为failed）

```
教程生成失败 → status更新为"failed" → 数据库有记录但标记失败
```

修复后：主应用可以同时检测到missing和failed，统一处理 ✅

### 场景3：部分成功，部分失败

```
21个concept：
- 10个成功保存
- 5个保存失败（missing）
- 6个生成失败（status="failed"）
```

修复后：主应用可以同时检测missing和failed，构造完整的重试列表 ✅

## 验证方法

### 1. 查看日志

```bash
# Railway日志
railway logs --service celery-content

# 应该看到：
celery_retry_task_started items_provided=True
```

### 2. 检查重试结果

```json
{
  "success": true,
  "retried_count": 21,  // 不再是0
  "message": "成功重试 21 个内容项目"
}
```

### 3. 验证数据库

```sql
-- 检查教程是否创建成功
SELECT concept_id, content_status 
FROM tutorials 
WHERE roadmap_id = 'agent-performance-optimization-x5y9z2q8';

-- 应该有21条新记录
```

## 相关修复

本修复与以下问题相关：

1. **连接池耗尽** (`20251231_Railway连接池耗尽修复.md`)
   - 根本原因：连接池配置过大
   - 症状之一：教程保存失败但status未标记

2. **事件循环冲突** (`20251231_数据库引擎事件循环感知修复.md`)
   - 多进程架构导致的资源隔离
   - 每个进程独立的连接池

## 总结

| 维度 | 问题 | 修复 |
|------|------|------|
| **根本原因** | 主应用和Worker使用不同的检测逻辑 | 主应用传递检测结果给Worker |
| **触发条件** | 连接池耗尽导致保存失败但status未更新 | 不依赖status字段 |
| **影响范围** | 所有重试场景 | 统一处理missing和failed |
| **兼容性** | 无 | 向后兼容（可选参数） |
| **性能** | Worker重复查询 | 减少数据库查询 |

**核心教训：** 
当系统有多个组件需要做相同判断时，应该由一个组件负责判断，并将结果传递给其他组件，而不是让每个组件独立判断。这样可以保证一致性，避免逻辑分歧。

