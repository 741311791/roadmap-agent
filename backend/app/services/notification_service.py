"""
é€šçŸ¥æœåŠ¡ï¼ˆåŸºäº Redis Pub/Subï¼‰

ç”¨äºåœ¨å·¥ä½œæµå…³é”®èŠ‚ç‚¹å‘å¸ƒäº‹ä»¶ï¼ŒWebSocket ç«¯ç‚¹è®¢é˜…å¹¶æ¨é€ç»™å®¢æˆ·ç«¯ã€‚

äº‹ä»¶ç±»å‹ï¼š
- progress: ä»»åŠ¡è¿›åº¦æ›´æ–°
- human_review_required: äººå·¥å®¡æ ¸è¯·æ±‚
- completed: ä»»åŠ¡å®Œæˆ
- failed: ä»»åŠ¡å¤±è´¥

Concept çº§åˆ«äº‹ä»¶ï¼š
- concept_start: æ¦‚å¿µå†…å®¹ç”Ÿæˆå¼€å§‹
- concept_complete: æ¦‚å¿µå†…å®¹ç”Ÿæˆå®Œæˆ
- concept_failed: æ¦‚å¿µå†…å®¹ç”Ÿæˆå¤±è´¥
- batch_start: æ‰¹æ¬¡å¤„ç†å¼€å§‹
- batch_complete: æ‰¹æ¬¡å¤„ç†å®Œæˆ
"""
from typing import AsyncIterator, Optional
from datetime import datetime
import json
import asyncio
import structlog

from app.db.redis_client import redis_client
from app.models.database import beijing_now

logger = structlog.get_logger()


# Redis é¢‘é“å‰ç¼€
CHANNEL_PREFIX = "roadmap:task:"


class TaskEvent:
    """ä»»åŠ¡äº‹ä»¶ç±»å‹å¸¸é‡"""
    # é˜¶æ®µçº§åˆ«äº‹ä»¶
    PROGRESS = "progress"
    HUMAN_REVIEW_REQUIRED = "human_review_required"
    COMPLETED = "completed"
    FAILED = "failed"
    
    # Concept çº§åˆ«äº‹ä»¶
    CONCEPT_START = "concept_start"
    CONCEPT_COMPLETE = "concept_complete"
    CONCEPT_FAILED = "concept_failed"
    CONCEPT_ALL_CONTENT_COMPLETE = "concept_all_content_complete"  # ğŸ†• ä¸‰é¡¹å†…å®¹å…¨éƒ¨å®Œæˆ
    BATCH_START = "batch_start"
    BATCH_COMPLETE = "batch_complete"
    
    # é‡è¯•ä»»åŠ¡äº‹ä»¶
    RETRY_STARTED = "retry_started"
    RETRY_ITEM_COMPLETE = "retry_item_complete"
    RETRY_COMPLETED = "retry_completed"
    
    # ä»»åŠ¡æ¢å¤äº‹ä»¶
    TASK_RECOVERING = "task_recovering"


class StepName:
    """æ­¥éª¤åç§°å¸¸é‡"""
    QUEUED = "queued"
    INTENT_ANALYSIS = "intent_analysis"
    CURRICULUM_DESIGN = "curriculum_design"
    STRUCTURE_VALIDATION = "structure_validation"
    HUMAN_REVIEW = "human_review"
    ROADMAP_EDIT = "roadmap_edit"
    CONTENT_GENERATION = "content_generation"
    COMPLETED = "completed"
    FAILED = "failed"


class HumanReviewSubStatus:
    """äººå·¥å®¡æ ¸å­çŠ¶æ€å¸¸é‡"""
    WAITING = "waiting"
    EDITING = "editing"


class NotificationService:
    """
    é€šçŸ¥æœåŠ¡
    
    ä½¿ç”¨ Redis Pub/Sub å®ç°ä»»åŠ¡è¿›åº¦çš„å®æ—¶æ¨é€ã€‚
    
    å‘å¸ƒç«¯ï¼šå·¥ä½œæµ Orchestrator åœ¨å…³é”®èŠ‚ç‚¹è°ƒç”¨ publish_* æ–¹æ³•
    è®¢é˜…ç«¯ï¼šWebSocket ç«¯ç‚¹è°ƒç”¨ subscribe æ–¹æ³•è·å–äº‹ä»¶æµ
    """
    
    def __init__(self):
        self._subscriptions: dict[str, asyncio.Task] = {}
    
    def _get_channel(self, task_id: str) -> str:
        """è·å–ä»»åŠ¡å¯¹åº”çš„ Redis é¢‘é“å"""
        return f"{CHANNEL_PREFIX}{task_id}"
    
    async def _ensure_connected(self):
        """ç¡®ä¿ Redis è¿æ¥"""
        await redis_client.connect()
    
    async def publish_progress(
        self,
        task_id: str,
        step: str,
        status: str = "processing",
        message: Optional[str] = None,
        extra_data: Optional[dict] = None,
        sub_status: Optional[str] = None,
    ):
        """
        å‘å¸ƒè¿›åº¦æ›´æ–°äº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            step: å½“å‰æ­¥éª¤ï¼ˆå¦‚ intent_analysis, curriculum_designï¼‰
            status: çŠ¶æ€ï¼ˆprocessing, completed ç­‰ï¼‰
            message: å¯é€‰çš„æ¶ˆæ¯æ–‡æœ¬
            extra_data: é¢å¤–æ•°æ®
            sub_status: å­çŠ¶æ€ï¼ˆç”¨äº human_review æ­¥éª¤ï¼šwaiting/editingï¼‰
        """
        event = {
            "type": TaskEvent.PROGRESS,
            "task_id": task_id,
            "step": step,
            "status": status,
            "timestamp": beijing_now().isoformat(),
        }
        
        if message:
            event["message"] = message
        if extra_data:
            event["data"] = extra_data
        if sub_status:
            event["sub_status"] = sub_status
        
        await self._publish(task_id, event)
    
    async def publish_human_review_required(
        self,
        task_id: str,
        roadmap_id: str,
        roadmap_title: str,
        stages_count: int,
    ):
        """
        å‘å¸ƒäººå·¥å®¡æ ¸è¯·æ±‚äº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            roadmap_id: è·¯çº¿å›¾ ID
            roadmap_title: è·¯çº¿å›¾æ ‡é¢˜
            stages_count: é˜¶æ®µæ•°é‡
        """
        event = {
            "type": TaskEvent.HUMAN_REVIEW_REQUIRED,
            "task_id": task_id,
            "roadmap_id": roadmap_id,
            "roadmap_title": roadmap_title,
            "stages_count": stages_count,
            "timestamp": beijing_now().isoformat(),
            "message": "è·¯çº¿å›¾æ¡†æ¶å·²ç”Ÿæˆï¼Œè¯·å®¡æ ¸",
        }
        
        await self._publish(task_id, event)
    
    async def publish_completed(
        self,
        task_id: str,
        roadmap_id: str,
        tutorials_count: Optional[int] = None,
        failed_count: Optional[int] = None,
    ):
        """
        å‘å¸ƒä»»åŠ¡å®Œæˆäº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            roadmap_id: è·¯çº¿å›¾ ID
            tutorials_count: ç”Ÿæˆçš„æ•™ç¨‹æ•°é‡
            failed_count: å¤±è´¥çš„æ•™ç¨‹æ•°é‡
        """
        event = {
            "type": TaskEvent.COMPLETED,
            "task_id": task_id,
            "roadmap_id": roadmap_id,
            "timestamp": beijing_now().isoformat(),
            "message": "è·¯çº¿å›¾ç”Ÿæˆå®Œæˆ",
        }
        
        if tutorials_count is not None:
            event["tutorials_count"] = tutorials_count
        if failed_count is not None:
            event["failed_count"] = failed_count
        
        await self._publish(task_id, event)
        
        # è®°å½•ä»»åŠ¡å®Œæˆçš„è¯¦ç»†æ—¥å¿—ï¼ˆæ–°å¢ - ç”¨äºå‰ç«¯å±•ç¤ºï¼‰
        from app.services.execution_logger import execution_logger, LogCategory
        
        # æ³¨æ„ï¼šè¿™é‡Œæ— æ³•è·å–å®Œæ•´çš„frameworkä¿¡æ¯ï¼Œæ‰€ä»¥åªè®°å½•åŸºæœ¬ç»Ÿè®¡
        # å‰ç«¯å¯ä»¥é€šè¿‡roadmap_idè·å–å®Œæ•´ä¿¡æ¯
        await execution_logger.info(
            task_id=task_id,
            category=LogCategory.WORKFLOW,
            step="completed",
            roadmap_id=roadmap_id,
            message="ğŸ‰ Roadmap generation completed successfully!",
            details={
                "log_type": "task_completed",
                "roadmap_id": roadmap_id,
                "roadmap_url": f"/roadmap/{roadmap_id}",
                "statistics": {
                    "tutorials_generated": tutorials_count if tutorials_count else 0,
                    "failed_concepts": failed_count if failed_count else 0,
                },
                "next_actions": [
                    {
                        "action": "view_roadmap",
                        "label": "View Roadmap",
                        "url": f"/roadmap/{roadmap_id}",
                        "primary": True,
                    },
                ],
            },
        )
    
    async def publish_failed(
        self,
        task_id: str,
        error: str,
        step: Optional[str] = None,
    ):
        """
        å‘å¸ƒä»»åŠ¡å¤±è´¥äº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            error: é”™è¯¯ä¿¡æ¯
            step: å¤±è´¥çš„æ­¥éª¤
        """
        event = {
            "type": TaskEvent.FAILED,
            "task_id": task_id,
            "error": error,
            "timestamp": beijing_now().isoformat(),
            "message": f"ä»»åŠ¡å¤±è´¥: {error[:100]}",
        }
        
        if step:
            event["step"] = step
        
        await self._publish(task_id, event)
    
    async def notify_task_recovering(
        self,
        task_id: str,
        roadmap_id: Optional[str] = None,
        current_step: Optional[str] = None,
    ):
        """
        å‘å¸ƒä»»åŠ¡æ¢å¤äº‹ä»¶
        
        å½“æœåŠ¡å™¨é‡å¯åè‡ªåŠ¨æ¢å¤è¢«ä¸­æ–­çš„ä»»åŠ¡æ—¶å‘é€æ­¤äº‹ä»¶ã€‚
        
        Args:
            task_id: ä»»åŠ¡ ID
            roadmap_id: è·¯çº¿å›¾ IDï¼ˆå¯é€‰ï¼‰
            current_step: æ¢å¤æ—¶çš„æ­¥éª¤ï¼ˆä» checkpoint è·å–ï¼‰
        """
        event = {
            "type": TaskEvent.TASK_RECOVERING,
            "task_id": task_id,
            "timestamp": beijing_now().isoformat(),
            "message": "ä»»åŠ¡æ­£åœ¨ä»æœåŠ¡å™¨é‡å¯ä¸­æ¢å¤æ‰§è¡Œ",
        }
        
        if roadmap_id:
            event["roadmap_id"] = roadmap_id
        if current_step:
            event["current_step"] = current_step
        
        await self._publish(task_id, event)
        
        logger.info(
            "task_recovering_notification_sent",
            task_id=task_id,
            roadmap_id=roadmap_id,
            current_step=current_step,
        )
    
    # ============================================================
    # Concept çº§åˆ«äº‹ä»¶å‘å¸ƒæ–¹æ³•
    # ============================================================
    
    async def publish_concept_start(
        self,
        task_id: str,
        concept_id: str,
        concept_name: str,
        current: int,
        total: int,
        content_type: str = "tutorial",
    ):
        """
        å‘å¸ƒæ¦‚å¿µå†…å®¹ç”Ÿæˆå¼€å§‹äº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            concept_id: æ¦‚å¿µ ID
            concept_name: æ¦‚å¿µåç§°
            current: å½“å‰è¿›åº¦ï¼ˆç¬¬å‡ ä¸ªï¼‰
            total: æ€»æ•°
            content_type: å†…å®¹ç±»å‹ (tutorial/resources/quiz)
        """
        percentage = round(current / total * 100, 1) if total > 0 else 0
        
        event = {
            "type": TaskEvent.CONCEPT_START,
            "task_id": task_id,
            "concept_id": concept_id,
            "concept_name": concept_name,
            "content_type": content_type,
            "progress": {
                "current": current,
                "total": total,
                "percentage": percentage,
            },
            "timestamp": beijing_now().isoformat(),
            "message": f"å¼€å§‹ç”Ÿæˆå†…å®¹: {concept_name}",
        }
        
        await self._publish(task_id, event)
    
    async def publish_concept_complete(
        self,
        task_id: str,
        concept_id: str,
        concept_name: str,
        data: Optional[dict] = None,
        content_type: str = "tutorial",
    ):
        """
        å‘å¸ƒæ¦‚å¿µå†…å®¹ç”Ÿæˆå®Œæˆäº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            concept_id: æ¦‚å¿µ ID
            concept_name: æ¦‚å¿µåç§°
            data: ç”Ÿæˆçš„å†…å®¹æ•°æ®ï¼ˆå¦‚ tutorial_id, content_url ç­‰ï¼‰
            content_type: å†…å®¹ç±»å‹ (tutorial/resources/quiz)
        """
        event = {
            "type": TaskEvent.CONCEPT_COMPLETE,
            "task_id": task_id,
            "concept_id": concept_id,
            "concept_name": concept_name,
            "content_type": content_type,
            "timestamp": beijing_now().isoformat(),
            "message": f"å†…å®¹ç”Ÿæˆå®Œæˆ: {concept_name}",
        }
        
        if data:
            event["data"] = data
        
        await self._publish(task_id, event)
    
    async def publish_concept_failed(
        self,
        task_id: str,
        concept_id: str,
        concept_name: str,
        error: str,
        content_type: str = "tutorial",
    ):
        """
        å‘å¸ƒæ¦‚å¿µå†…å®¹ç”Ÿæˆå¤±è´¥äº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            concept_id: æ¦‚å¿µ ID
            concept_name: æ¦‚å¿µåç§°
            content_type: å†…å®¹ç±»å‹ (tutorial/resources/quiz)
            error: é”™è¯¯ä¿¡æ¯
        """
        event = {
            "type": TaskEvent.CONCEPT_FAILED,
            "task_id": task_id,
            "concept_id": concept_id,
            "concept_name": concept_name,
            "content_type": content_type,
            "error": error[:200],  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
            "timestamp": beijing_now().isoformat(),
            "message": f"å†…å®¹ç”Ÿæˆå¤±è´¥: {concept_name}",
        }
        
        await self._publish(task_id, event)
    
    async def publish_concept_all_content_complete(
        self,
        task_id: str,
        concept_id: str,
        concept_name: str,
        data: Optional[dict] = None,
    ):
        """
        å‘å¸ƒ Concept å…¨éƒ¨å†…å®¹å®Œæˆäº‹ä»¶ï¼ˆTutorial + Resource + Quizï¼‰
        
        ä¸ publish_concept_complete çš„åŒºåˆ«ï¼š
        - concept_complete: å•é¡¹å†…å®¹å®Œæˆæ—¶å‘é€ï¼ˆå¦‚ Tutorial å®Œæˆï¼‰
        - concept_all_content_complete: ä¸‰é¡¹å†…å®¹å…¨éƒ¨å®Œæˆæ—¶å‘é€ï¼ˆç”¨äºå‰ç«¯æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ï¼‰
        
        Args:
            task_id: ä»»åŠ¡ ID
            concept_id: æ¦‚å¿µ ID
            concept_name: æ¦‚å¿µåç§°
            data: ç”Ÿæˆçš„å†…å®¹æ•°æ®ï¼ˆåŒ…å« tutorial_id, resources_id, quiz_idï¼‰
        """
        event = {
            "type": TaskEvent.CONCEPT_ALL_CONTENT_COMPLETE,
            "task_id": task_id,
            "concept_id": concept_id,
            "concept_name": concept_name,
            "timestamp": beijing_now().isoformat(),
            "message": f"âœ… Concept å®Œæ•´å†…å®¹å·²ç”Ÿæˆ: {concept_name}",
        }
        
        if data:
            event["data"] = data
        
        await self._publish(task_id, event)
    
    async def publish_batch_start(
        self,
        task_id: str,
        batch_index: int,
        batch_size: int,
        total_batches: int,
        concept_ids: list[str],
    ):
        """
        å‘å¸ƒæ‰¹æ¬¡å¤„ç†å¼€å§‹äº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            batch_index: å½“å‰æ‰¹æ¬¡ç´¢å¼•ï¼ˆä» 1 å¼€å§‹ï¼‰
            batch_size: å½“å‰æ‰¹æ¬¡å¤§å°
            total_batches: æ€»æ‰¹æ¬¡æ•°
            concept_ids: æœ¬æ‰¹æ¬¡åŒ…å«çš„æ¦‚å¿µ ID åˆ—è¡¨
        """
        event = {
            "type": TaskEvent.BATCH_START,
            "task_id": task_id,
            "batch_index": batch_index,
            "batch_size": batch_size,
            "total_batches": total_batches,
            "concept_ids": concept_ids,
            "timestamp": beijing_now().isoformat(),
            "message": f"å¼€å§‹å¤„ç†æ‰¹æ¬¡ {batch_index}/{total_batches}",
        }
        
        await self._publish(task_id, event)
    
    async def publish_batch_complete(
        self,
        task_id: str,
        batch_index: int,
        total_batches: int,
        completed: int,
        failed: int,
        total: int,
    ):
        """
        å‘å¸ƒæ‰¹æ¬¡å¤„ç†å®Œæˆäº‹ä»¶
        
        Args:
            task_id: ä»»åŠ¡ ID
            batch_index: å½“å‰æ‰¹æ¬¡ç´¢å¼•ï¼ˆä» 1 å¼€å§‹ï¼‰
            total_batches: æ€»æ‰¹æ¬¡æ•°
            completed: å·²å®Œæˆæ•°é‡
            failed: å·²å¤±è´¥æ•°é‡
            total: æ€»æ•°é‡
        """
        percentage = round((completed + failed) / total * 100, 1) if total > 0 else 0
        
        event = {
            "type": TaskEvent.BATCH_COMPLETE,
            "task_id": task_id,
            "batch_index": batch_index,
            "total_batches": total_batches,
            "progress": {
                "completed": completed,
                "failed": failed,
                "total": total,
                "percentage": percentage,
            },
            "timestamp": beijing_now().isoformat(),
            "message": f"æ‰¹æ¬¡ {batch_index}/{total_batches} å¤„ç†å®Œæˆ",
        }
        
        await self._publish(task_id, event)
    
    async def _publish(self, task_id: str, event: dict):
        """
        å‘å¸ƒäº‹ä»¶åˆ° Redis é¢‘é“
        
        å¦‚æœ Redis è¿æ¥å¤±è´¥æˆ–è¶…æ—¶ï¼Œä¼šè®°å½•é”™è¯¯ä½†ä¸ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œ
        ç¡®ä¿å·¥ä½œæµä¸ä¼šå› ä¸ºé€šçŸ¥å¤±è´¥è€Œä¸­æ–­ã€‚
        
        åœ¨å¼‚å¸¸å¤„ç†ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨æ—¶ï¼Œèƒ½å¤Ÿä¼˜é›…å¤„ç†äº‹ä»¶å¾ªç¯å†²çªã€‚
        
        Args:
            task_id: ä»»åŠ¡ ID
            event: äº‹ä»¶æ•°æ®
        """
        try:
            await self._ensure_connected()
            channel = self._get_channel(task_id)
            
            message = json.dumps(event, ensure_ascii=False)
            
            # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼š5ç§’è¶…æ—¶
            # æ³¨æ„ï¼šåœ¨å¼‚å¸¸å¤„ç†ä¸Šä¸‹æ–‡ä¸­ï¼Œasyncio.wait_for å¯èƒ½è§¦å‘äº‹ä»¶å¾ªç¯å†²çª
            # å› æ­¤éœ€è¦æ•è· RuntimeError
            await asyncio.wait_for(
                redis_client._client.publish(channel, message),
                timeout=5.0
            )
            
            logger.debug(
                "notification_published",
                task_id=task_id,
                event_type=event.get("type"),
                channel=channel,
            )
            
        except asyncio.TimeoutError:
            logger.error(
                "notification_publish_timeout",
                task_id=task_id,
                event_type=event.get("type"),
                timeout_seconds=5,
            )
        except RuntimeError as e:
            # äº‹ä»¶å¾ªç¯å†²çªï¼ˆå¦‚ "Future attached to a different loop"ï¼‰
            logger.error(
                "notification_publish_failed",
                task_id=task_id,
                event_type=event.get("type"),
                error=f"Event loop conflict: {str(e)}",
            )
        except Exception as e:
            logger.error(
                "notification_publish_failed",
                task_id=task_id,
                event_type=event.get("type"),
                error=str(e),
            )
    
    async def subscribe(self, task_id: str) -> AsyncIterator[dict]:
        """
        è®¢é˜…ä»»åŠ¡äº‹ä»¶æµ
        
        Args:
            task_id: ä»»åŠ¡ ID
            
        Yields:
            äº‹ä»¶å­—å…¸
            
        Example:
            ```python
            async for event in notification_service.subscribe("task-123"):
                print(event)
                if event["type"] == "completed":
                    break
            ```
        """
        await self._ensure_connected()
        channel = self._get_channel(task_id)
        
        # åˆ›å»º Pub/Sub è®¢é˜…
        pubsub = redis_client._client.pubsub()
        
        try:
            await pubsub.subscribe(channel)
            
            logger.info(
                "notification_subscribed",
                task_id=task_id,
                channel=channel,
            )
            
            # æŒç»­ç›‘å¬æ¶ˆæ¯
            async for message in pubsub.listen():
                if message["type"] == "message":
                    try:
                        data = message["data"]
                        # Redis è¿”å›çš„å¯èƒ½æ˜¯ bytes æˆ– str
                        if isinstance(data, bytes):
                            data = data.decode("utf-8")
                        
                        event = json.loads(data)
                        yield event
                        
                        # å¦‚æœæ˜¯ç»ˆæ­¢äº‹ä»¶ï¼Œç»“æŸè®¢é˜…
                        if event.get("type") in (TaskEvent.COMPLETED, TaskEvent.FAILED):
                            logger.info(
                                "notification_subscription_ended",
                                task_id=task_id,
                                reason=event.get("type"),
                            )
                            break
                            
                    except json.JSONDecodeError as e:
                        logger.warning(
                            "notification_message_decode_error",
                            task_id=task_id,
                            error=str(e),
                        )
                        continue
        
        except asyncio.CancelledError:
            logger.info(
                "notification_subscription_cancelled",
                task_id=task_id,
            )
            raise
        
        except Exception as e:
            logger.error(
                "notification_subscription_error",
                task_id=task_id,
                error=str(e),
            )
            raise
        
        finally:
            # æ¸…ç†è®¢é˜…
            await pubsub.unsubscribe(channel)
            await pubsub.close()
            
            logger.debug(
                "notification_subscription_cleanup",
                task_id=task_id,
            )
    
    async def subscribe_with_timeout(
        self,
        task_id: str,
        timeout_seconds: int = 3600,  # é»˜è®¤ 1 å°æ—¶è¶…æ—¶
    ) -> AsyncIterator[dict]:
        """
        å¸¦è¶…æ—¶çš„è®¢é˜…
        
        Args:
            task_id: ä»»åŠ¡ ID
            timeout_seconds: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Yields:
            äº‹ä»¶å­—å…¸
        """
        try:
            async with asyncio.timeout(timeout_seconds):
                async for event in self.subscribe(task_id):
                    yield event
        except asyncio.TimeoutError:
            logger.warning(
                "notification_subscription_timeout",
                task_id=task_id,
                timeout_seconds=timeout_seconds,
            )
            yield {
                "type": "timeout",
                "task_id": task_id,
                "message": f"è®¢é˜…è¶…æ—¶ï¼ˆ{timeout_seconds}ç§’ï¼‰",
                "timestamp": beijing_now().isoformat(),
            }


# å…¨å±€å•ä¾‹
notification_service = NotificationService()

