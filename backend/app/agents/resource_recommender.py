"""
Resource Recommender Agentï¼ˆèµ„æºæ¨èå¸ˆï¼‰
"""
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional
from app.agents.base import BaseAgent
from app.models.domain import (
    Concept,
    LearningPreferences,
    ResourceRecommendationInput,
    ResourceRecommendationOutput,
    Resource,
    SearchQuery,
)
from app.core.tool_registry import tool_registry
from app.config.settings import settings
import structlog
import httpx
import asyncio

logger = structlog.get_logger()


class ResourceRecommenderAgent(BaseAgent):
    """
    èµ„æºæ¨èå¸ˆ Agent
    
    é…ç½®ä»ç¯å¢ƒå˜é‡åŠ è½½ï¼š
    - RECOMMENDER_PROVIDER: æ¨¡å‹æä¾›å•†ï¼ˆé»˜è®¤: openaiï¼‰
    - RECOMMENDER_MODEL: æ¨¡å‹åç§°ï¼ˆé»˜è®¤: gpt-4o-miniï¼‰
    - RECOMMENDER_BASE_URL: è‡ªå®šä¹‰ API ç«¯ç‚¹ï¼ˆå¯é€‰ï¼‰
    - RECOMMENDER_API_KEY: API å¯†é’¥ï¼ˆå¿…éœ€ï¼‰
    """
    
    def __init__(
        self,
        agent_id: str = "resource_recommender",
        model_provider: str | None = None,
        model_name: str | None = None,
        base_url: str | None = None,
        api_key: str | None = None,
    ):
        super().__init__(
            agent_id=agent_id,
            model_provider=model_provider or settings.RECOMMENDER_PROVIDER,
            model_name=model_name or settings.RECOMMENDER_MODEL,
            base_url=base_url or settings.RECOMMENDER_BASE_URL,
            api_key=api_key or settings.RECOMMENDER_API_KEY,
            temperature=0.5,
            max_tokens=4096,
        )
    
    def _get_tools_definition(self) -> List[Dict[str, Any]]:
        """
        è·å–å·¥å…·å®šä¹‰ï¼ˆç¬¦åˆ OpenAI Function Calling æ ¼å¼ï¼‰
        
        è¿”å› web_search å·¥å…·ï¼ˆé€šè¿‡ WebSearchRouter è‡ªåŠ¨è·¯ç”±åˆ° Tavily API æˆ– DuckDuckGoï¼‰
        
        Returns:
            å·¥å…·å®šä¹‰åˆ—è¡¨
        """
        tools = [
            # æ™®é€šæœç´¢å·¥å…·ï¼ˆé€šè¿‡ WebSearchRouter è·¯ç”±ï¼‰
            {
                "type": "function",
                "function": {
                    "name": "web_search",
                    "description": (
                        "æ‰§è¡Œç½‘ç»œæœç´¢ä»¥è·å–å­¦ä¹ èµ„æºã€å®˜æ–¹æ–‡æ¡£ã€æ•™ç¨‹å’Œè¯¾ç¨‹ã€‚"
                        "æ”¯æŒæ—¶é—´ç­›é€‰ï¼ˆæœ€è¿‘ä¸€å¹´/æœˆ/å‘¨ï¼‰ã€åŸŸåç­›é€‰ï¼ˆä¼˜å…ˆæœç´¢æƒå¨ç½‘ç«™ï¼‰ç­‰é«˜çº§åŠŸèƒ½ã€‚"
                        "ä¼˜å…ˆçº§ï¼šTavily API â†’ DuckDuckGoã€‚"
                    ),
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ï¼š'React Hooks å®˜æ–¹æ–‡æ¡£'ã€'Python æœºå™¨å­¦ä¹ æ•™ç¨‹'",
                            },
                            "max_results": {
                                "type": "integer",
                                "description": "æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤5ï¼ŒèŒƒå›´1-20",
                                "default": 5,
                            },
                            "time_range": {
                                "type": "string",
                                "enum": ["day", "week", "month", "year"],
                                "description": (
                                    "æ—¶é—´ç­›é€‰ï¼ˆæ¨èä½¿ç”¨ï¼Œç¡®ä¿èµ„æºæ—¶æ•ˆæ€§ï¼‰ï¼š"
                                    "'year'=æœ€è¿‘ä¸€å¹´ï¼ˆæ¨èï¼Œé€‚åˆæŠ€æœ¯æ•™ç¨‹ï¼‰ã€"
                                    "'month'=æœ€è¿‘ä¸€æœˆï¼ˆæœ€æ–°èµ„è®¯ï¼‰ã€"
                                    "'week'=æœ€è¿‘ä¸€å‘¨ã€'day'=æœ€è¿‘ä¸€å¤©"
                                ),
                            },
                            "search_depth": {
                                "type": "string",
                                "enum": ["basic", "advanced"],
                                "description": "æœç´¢æ·±åº¦ï¼š'advanced'ï¼ˆé«˜è´¨é‡ï¼Œæ¨èï¼‰æˆ– 'basic'ï¼ˆå¿«é€Ÿï¼‰",
                                "default": "advanced",
                            },
                            "include_domains": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": (
                                    "ä¼˜å…ˆæœç´¢çš„æƒå¨åŸŸååˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š['github.com', 'stackoverflow.com', 'docs.python.org']"
                                ),
                            },
                            "exclude_domains": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "æ’é™¤çš„åŸŸååˆ—è¡¨ï¼Œä¾‹å¦‚ï¼š['medium.com']ï¼ˆé¿å…ä½è´¨é‡å†…å®¹ï¼‰",
                            },
                        },
                        "required": ["query"],
                    },
                },
            }
        ]
        
        return tools
    
    async def _handle_tool_calls(
        self, 
        tool_calls: List[Any],
        user_preferences: LearningPreferences | None = None
    ) -> tuple[List[Dict[str, Any]], List[str]]:
        """
        å¤„ç† LLM è¿”å›çš„å·¥å…·è°ƒç”¨è¯·æ±‚
        
        Args:
            tool_calls: å·¥å…·è°ƒç”¨åˆ—è¡¨
            user_preferences: ç”¨æˆ·åå¥½ï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæä¾›åˆ™ä»å®ä¾‹å˜é‡è·å–ï¼‰
            
        Returns:
            (å·¥å…·è°ƒç”¨ç»“æœåˆ—è¡¨, ä½¿ç”¨çš„æœç´¢æŸ¥è¯¢åˆ—è¡¨)
        """
        tool_messages = []
        search_queries_used = []
        
        # è·å–ç”¨æˆ·åå¥½ï¼ˆä¼˜å…ˆä½¿ç”¨å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨å®ä¾‹å˜é‡ï¼‰
        prefs = user_preferences or getattr(self, '_current_user_preferences', None)
        
        for tool_call in tool_calls:
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)
            tool_call_id = tool_call.id
            
            logger.info(
                "resource_recommender_tool_call",
                tool_name=tool_name,
                tool_args=tool_args,
                tool_call_id=tool_call_id,
            )
            
            # å¤„ç† web_search å·¥å…·è°ƒç”¨
            if tool_name == "web_search":
                try:
                    # è®°å½•æœç´¢æŸ¥è¯¢
                    search_queries_used.append(tool_args["query"])
                    
                    # ä½¿ç”¨ WebSearchRouterï¼ˆä¼šæŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨é€‰æ‹©ï¼šTavily API â†’ DuckDuckGoï¼‰
                    search_tool = tool_registry.get("web_search_v1")
                    if not search_tool:
                        raise RuntimeError("Web Search Router æœªæ³¨å†Œ")
                    
                    # æ„å»ºæœç´¢æŸ¥è¯¢ï¼ˆåŒ…å«è¯­è¨€å’Œå†…å®¹ç±»å‹ä¿¡æ¯ï¼‰
                    # ä» user_preferences æå–è¯­è¨€ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    language = None
                    if prefs and prefs.preferred_language:
                        language = prefs.preferred_language
                    
                    # ä»æŸ¥è¯¢ä¸­æ¨æ–­å†…å®¹ç±»å‹ï¼ˆå¦‚æœå¯èƒ½ï¼‰
                    content_type = None
                    query_lower = tool_args["query"].lower()
                    if any(keyword in query_lower for keyword in ["video", "tutorial", "course", "youtube", "bilibili"]):
                        content_type = "video"
                    elif any(keyword in query_lower for keyword in ["documentation", "docs", "api"]):
                        content_type = "documentation"
                    elif any(keyword in query_lower for keyword in ["article", "blog", "post"]):
                        content_type = "article"
                    
                    # æ„å»º SearchQueryï¼ˆæ”¯æŒ Tavily é«˜çº§å‚æ•°ï¼‰
                    search_query = SearchQuery(
                        query=tool_args["query"],
                        max_results=tool_args.get("max_results", 5),
                        language=language,
                        content_type=content_type,
                        # Tavily é«˜çº§å‚æ•°
                        search_depth=tool_args.get("search_depth", "advanced"),
                        time_range=tool_args.get("time_range"),
                        include_domains=tool_args.get("include_domains"),
                        exclude_domains=tool_args.get("exclude_domains"),
                    )
                    
                    # æ‰§è¡Œæœç´¢
                    search_result = await search_tool.execute(search_query)
                    
                    # æ ¼å¼åŒ–æœç´¢ç»“æœ
                    formatted_results = []
                    for idx, result in enumerate(search_result.results[:5], 1):
                        formatted_results.append(
                            f"{idx}. {result['title']}\n"
                            f"   URL: {result['url']}\n"
                            f"   æ‘˜è¦: {result['snippet']}\n"
                        )
                    
                    result_text = "\n".join(formatted_results) if formatted_results else "æœªæ‰¾åˆ°ç›¸å…³ç»“æœ"
                    
                    logger.info(
                        "resource_recommender_tool_success",
                        tool_name=tool_name,
                        results_count=len(search_result.results),
                    )
                    
                    # æ„å»ºå·¥å…·å“åº”æ¶ˆæ¯
                    tool_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call_id,
                        "content": result_text,
                    })
                    
                except Exception as e:
                    logger.error(
                        "resource_recommender_tool_failed",
                        tool_name=tool_name,
                        error=str(e),
                    )
                    tool_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call_id,
                        "content": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}",
                    })
            else:
                logger.warning("resource_recommender_unknown_tool", tool_name=tool_name)
                tool_messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call_id,
                    "content": f"æœªçŸ¥å·¥å…·: {tool_name}",
                })
        
        return tool_messages, search_queries_used
    
    async def _verify_urls(
        self, 
        resources: List[Resource]
    ) -> List[Resource]:
        """
        æ‰¹é‡éªŒè¯èµ„æºURLçš„æœ‰æ•ˆæ€§
        
        ç­–ç•¥:
        - ä½¿ç”¨ HEAD è¯·æ±‚æ£€æŸ¥é“¾æ¥ï¼ˆæ›´å¿«ï¼‰
        - æ¨¡æ‹Ÿæµè§ˆå™¨ User-Agentï¼ˆé¿å…403ï¼‰
        - å¹¶å‘éªŒè¯æå‡é€Ÿåº¦
        - ä¿ç•™200å’Œ403/412çŠ¶æ€ç çš„èµ„æºï¼ˆ403/412å¯èƒ½éœ€è¦æµè§ˆå™¨è®¿é—®ä½†èµ„æºå­˜åœ¨ï¼‰
        - è¿‡æ»¤404å’Œ500+é”™è¯¯çš„èµ„æº
        
        Args:
            resources: å¾…éªŒè¯çš„èµ„æºåˆ—è¡¨
            
        Returns:
            éªŒè¯åçš„èµ„æºåˆ—è¡¨ï¼ˆå·²è¿‡æ»¤æ— æ•ˆé“¾æ¥ï¼‰
        """
        verified_resources = []
        
        # æ¨¡æ‹Ÿæµè§ˆå™¨ User-Agent
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                         "AppleWebKit/537.36 (KHTML, like Gecko) "
                         "Chrome/120.0.0.0 Safari/537.36"
        }
        
        async def verify_single(resource: Resource) -> Optional[Resource]:
            """éªŒè¯å•ä¸ªURL"""
            try:
                async with httpx.AsyncClient(
                    timeout=10.0, 
                    follow_redirects=True
                ) as client:
                    response = await client.head(resource.url, headers=headers)
                    
                    # 200: å®Œå…¨æœ‰æ•ˆ
                    if response.status_code == 200:
                        # æ›´æ–°ä¸ºæœ€ç»ˆURLï¼ˆå¤„ç†é‡å®šå‘ï¼‰
                        resource.url = str(response.url)
                        logger.info(
                            "url_verified_success",
                            url=resource.url,
                            status=200,
                            title=resource.title[:50]
                        )
                        return resource
                    
                    # 403/412: å¯èƒ½éœ€è¦æµè§ˆå™¨è®¿é—®ï¼Œä½†èµ„æºå¯èƒ½å­˜åœ¨ï¼Œä¿ç•™
                    elif response.status_code in [403, 412]:
                        logger.info(
                            "url_possibly_valid",
                            url=resource.url,
                            status=response.status_code,
                            title=resource.title[:50],
                            reason="éœ€è¦æµè§ˆå™¨è®¿é—®æˆ–Cookie"
                        )
                        return resource  # ä¿ç•™è¿™äº›èµ„æº
                    
                    # 404: ç¡®è®¤æ— æ•ˆ
                    elif response.status_code == 404:
                        logger.warning(
                            "url_not_found",
                            url=resource.url,
                            status=404,
                            title=resource.title[:50]
                        )
                        return None  # è¿‡æ»¤æ‰
                    
                    # 500+: æœåŠ¡å™¨é”™è¯¯
                    elif response.status_code >= 500:
                        logger.warning(
                            "url_server_error",
                            url=resource.url,
                            status=response.status_code,
                            title=resource.title[:50]
                        )
                        return None  # è¿‡æ»¤æ‰
                    
                    # å…¶ä»–çŠ¶æ€ç ï¼šä¿å®ˆå¤„ç†ï¼Œä¿ç•™
                    else:
                        logger.info(
                            "url_unknown_status",
                            url=resource.url,
                            status=response.status_code,
                            title=resource.title[:50]
                        )
                        return resource
                        
            except httpx.TimeoutException:
                logger.warning(
                    "url_verification_timeout",
                    url=resource.url,
                    title=resource.title[:50]
                )
                # è¶…æ—¶çš„é“¾æ¥ä¿ç•™ï¼ˆå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜ï¼‰
                return resource
                
            except Exception as e:
                logger.warning(
                    "url_verification_failed",
                    url=resource.url,
                    error=str(e)[:100],
                    title=resource.title[:50]
                )
                # éªŒè¯å¤±è´¥çš„é“¾æ¥ä¿ç•™ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
                return resource
        
        # å¹¶å‘éªŒè¯æ‰€æœ‰URL
        logger.info(
            "url_verification_start",
            total_resources=len(resources)
        )
        
        tasks = [verify_single(r) for r in resources]
        results = await asyncio.gather(*tasks)
        
        verified_resources = [r for r in results if r is not None]
        
        filtered_count = len(resources) - len(verified_resources)
        
        logger.info(
            "url_verification_complete",
            total=len(resources),
            verified=len(verified_resources),
            filtered=filtered_count,
            success_rate=f"{len(verified_resources)/len(resources)*100:.1f}%" if resources else "0%"
        )
        
        return verified_resources
    
    async def recommend(
        self,
        concept: Concept,
        context: dict,
        user_preferences: LearningPreferences,
    ) -> ResourceRecommendationOutput:
        """
        ä¸ºç»™å®šçš„ Concept æ¨èå­¦ä¹ èµ„æº
        
        æ”¯æŒåŒè¯­èµ„æºæ¨èï¼š
        - å¦‚æœç”¨æˆ·è®¾ç½®äº†ä¸åŒçš„ä¸»è¯­è¨€å’Œæ¬¡è¯­è¨€ï¼ŒæŒ‰ 60%/40% æ¯”ä¾‹åˆ†é…èµ„æº
        - å¦‚æœåªæœ‰ä¸»è¯­è¨€ï¼Œåˆ™ 100% ä½¿ç”¨ä¸»è¯­è¨€èµ„æº
        
        Args:
            concept: è¦æ¨èèµ„æºçš„æ¦‚å¿µ
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆæ‰€å±é˜¶æ®µã€æ¨¡å—ç­‰ï¼‰
            user_preferences: ç”¨æˆ·åå¥½
            
        Returns:
            èµ„æºæ¨èç»“æœ
        """
        # ä¿å­˜ç”¨æˆ·åå¥½åˆ°å®ä¾‹å˜é‡ï¼Œä¾›å·¥å…·è°ƒç”¨æ—¶ä½¿ç”¨
        self._current_user_preferences = user_preferences
        
        # è·å–è¯­è¨€åå¥½å’Œèµ„æºåˆ†é…æ¯”ä¾‹
        language_prefs = user_preferences.get_language_preferences()
        resource_ratio = language_prefs.get_effective_ratio()
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦åŒè¯­æœç´¢
        has_bilingual = (
            language_prefs.secondary_language and 
            language_prefs.secondary_language != language_prefs.primary_language and
            resource_ratio["secondary"] > 0
        )
        
        logger.info(
            "resource_recommender_language_config",
            concept_id=concept.concept_id,
            primary_language=language_prefs.primary_language,
            secondary_language=language_prefs.secondary_language,
            resource_ratio=resource_ratio,
            has_bilingual=has_bilingual,
        )
        
        # åŠ è½½ System Promptï¼ˆåŒ…å«è¯­è¨€åå¥½ä¿¡æ¯ï¼‰
        system_prompt = self._load_system_prompt(
            "resource_recommender.j2",
            agent_name="Resource Recommender",
            role_description="èµ„æ·±å­¦ä¹ èµ„æºä¸“å®¶ï¼Œæ“…é•¿ä¸ºå­¦ä¹ è€…æœç´¢å¹¶æ¨èé«˜è´¨é‡çš„å­¦ä¹ èµ„æºï¼ŒåŒ…æ‹¬å®˜æ–¹æ–‡æ¡£ã€æ•™ç¨‹ã€è§†é¢‘è¯¾ç¨‹ã€ä¹¦ç±å’Œå·¥å…·ã€‚",
            concept=concept,
            context=context,
            user_preferences=user_preferences,
            language_preferences=language_prefs.model_dump(),
            resource_ratio=resource_ratio,
        )
        
        # æ ¹æ®å†…å®¹åå¥½æ„å»ºæœç´¢å»ºè®®
        content_pref_map = {
            "visual": "è§†é¢‘æ•™ç¨‹ã€å›¾è§£ã€æ¼”ç¤º",
            "text": "æ–‡æ¡£ã€æ–‡ç« ã€ä¹¦ç±",
            "audio": "æ’­å®¢ã€æœ‰å£°å†…å®¹",
            "hands_on": "äº’åŠ¨ç»ƒä¹ ã€é¡¹ç›®å®æˆ˜",
        }
        content_pref_desc = ", ".join([
            content_pref_map.get(pref, pref) 
            for pref in user_preferences.content_preference
        ])
        
        # æ„å»ºè¯­è¨€åˆ†é…æŒ‡ä»¤
        if has_bilingual:
            primary_count = int(10 * resource_ratio["primary"])  # å‡è®¾æ¨è10ä¸ªèµ„æº
            secondary_count = 10 - primary_count
            language_instruction = f"""
**è¯­è¨€åˆ†é…è¦æ±‚**ï¼ˆé‡è¦ï¼‰:
- ä¸»è¦è¯­è¨€ï¼ˆ{language_prefs.primary_language}ï¼‰èµ„æº: çº¦ {int(resource_ratio['primary'] * 100)}%ï¼ˆçº¦ {primary_count} ä¸ªï¼‰
- æ¬¡è¦è¯­è¨€ï¼ˆ{language_prefs.secondary_language}ï¼‰èµ„æº: çº¦ {int(resource_ratio['secondary'] * 100)}%ï¼ˆçº¦ {secondary_count} ä¸ªï¼‰
- æ¯ä¸ªèµ„æºéœ€è¦åœ¨ JSON è¾“å‡ºä¸­æ ‡æ³¨å…¶è¯­è¨€ï¼ˆlanguage å­—æ®µï¼‰
- æœç´¢æ—¶éœ€è¦åˆ†åˆ«ä½¿ç”¨ä¸»è¯­è¨€å’Œæ¬¡è¯­è¨€çš„æœç´¢æŸ¥è¯¢
"""
        else:
            language_instruction = f"""
**è¯­è¨€è¦æ±‚**:
- ä¸»è¦ä½¿ç”¨ {language_prefs.primary_language} è¯­è¨€çš„èµ„æº
- æ¯ä¸ªèµ„æºéœ€è¦åœ¨ JSON è¾“å‡ºä¸­æ ‡æ³¨å…¶è¯­è¨€ï¼ˆlanguage å­—æ®µï¼‰
"""
        
        user_message = f"""
è¯·ä¸ºä»¥ä¸‹æ¦‚å¿µæ¨èé«˜è´¨é‡çš„å­¦ä¹ èµ„æºï¼š

**æ¦‚å¿µä¿¡æ¯**:
- åç§°: {concept.name}
- æè¿°: {concept.description}
- éš¾åº¦: {concept.difficulty}
- å…³é”®è¯: {", ".join(concept.keywords) if concept.keywords else "æ— "}

**ä¸Šä¸‹æ–‡ä¿¡æ¯**:
- æ‰€å±é˜¶æ®µ: {context.get("stage_name", "æœªçŸ¥")}
- æ‰€å±æ¨¡å—: {context.get("module_name", "æœªçŸ¥")}

**ç”¨æˆ·åå¥½**:
- å†…å®¹åå¥½: {content_pref_desc}
- å½“å‰æ°´å¹³: {user_preferences.current_level}
{language_instruction}
è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
1. æ ¹æ®ç”¨æˆ·çš„å†…å®¹åå¥½ï¼ˆ{", ".join(user_preferences.content_preference)}ï¼‰å’Œè¯­è¨€åˆ†é…è¦æ±‚ï¼Œæ„å»ºé’ˆå¯¹æ€§çš„æœç´¢æŸ¥è¯¢
2. ä½¿ç”¨ web_search å·¥å…·æœç´¢ä¸æ¦‚å¿µç›¸å…³çš„å®˜æ–¹æ–‡æ¡£ã€æ•™ç¨‹ã€è¯¾ç¨‹ç­‰èµ„æº
   - ä¼˜å…ˆæœç´¢ç”¨æˆ·åå¥½çš„å†…å®¹ç±»å‹ï¼ˆå¦‚åå¥½ visualï¼Œä¼˜å…ˆæœç´¢è§†é¢‘æ•™ç¨‹ï¼‰
   - **æŒ‰è¯­è¨€åˆ†é…æ¯”ä¾‹åˆ†åˆ«æœç´¢ä¸åŒè¯­è¨€çš„èµ„æº**
3. åŸºäºæœç´¢ç»“æœå’Œä½ çš„çŸ¥è¯†ï¼Œç­›é€‰ 8-10 ä¸ªé«˜è´¨é‡èµ„æºï¼ˆæŒ‰è¯­è¨€æ¯”ä¾‹åˆ†é…ï¼‰
4. æŒ‰ç›¸å…³æ€§è¯„åˆ†æ’åºï¼Œè¾“å‡º JSON æ ¼å¼çš„æ¨èç»“æœï¼ˆæ¯ä¸ªèµ„æºåŒ…å« language å­—æ®µï¼‰
"""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ]
        
        # è·å–å·¥å…·å®šä¹‰
        tools = self._get_tools_definition()
        
        # æ”¶é›†æ‰€æœ‰ä½¿ç”¨çš„æœç´¢æŸ¥è¯¢
        all_search_queries = []
        
        # è°ƒç”¨ LLMï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
        max_iterations = 5
        iteration = 0
        content = None  # åˆå§‹åŒ– content å˜é‡ï¼Œé¿å… UnboundLocalError
        
        while iteration < max_iterations:
            logger.info(
                "resource_recommender_llm_call",
                concept_id=concept.concept_id,
                iteration=iteration,
            )
            
            response = await self._call_llm(messages, tools=tools)
            message = response.choices[0].message
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if hasattr(message, 'tool_calls') and message.tool_calls:
                logger.info(
                    "resource_recommender_tool_calls_detected",
                    concept_id=concept.concept_id,
                    tool_calls_count=len(message.tool_calls),
                )
                
                # å°† assistant çš„æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": message.content or "",
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments,
                            }
                        }
                        for tc in message.tool_calls
                    ]
                })
                
                # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆä¼ é€’ç”¨æˆ·åå¥½ï¼‰
                tool_messages, search_queries = await self._handle_tool_calls(
                    message.tool_calls,
                    user_preferences=user_preferences
                )
                messages.extend(tool_messages)
                all_search_queries.extend(search_queries)
                
                iteration += 1
                continue
            
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè·å–æœ€ç»ˆå†…å®¹
            content = message.content
            break
        
        if iteration >= max_iterations:
            logger.error(
                "resource_recommender_max_iterations_reached",
                concept_id=concept.concept_id,
            )
            raise ValueError(
                f"èµ„æºæ¨èå¤±è´¥ï¼šå·¥å…·è°ƒç”¨å¾ªç¯è¾¾åˆ°æœ€å¤§æ¬¡æ•°ï¼ˆ{max_iterations}ï¼‰ä»æœªè·å¾—æœ€ç»ˆå†…å®¹ã€‚"
                "å¯èƒ½åŸå› ï¼šLLM æŒç»­è¿›è¡Œå·¥å…·è°ƒç”¨è€Œæœªè¾“å‡ºæœ€ç»ˆç»“æœã€‚"
            )
        
        # è§£æè¾“å‡º
        if not content:
            raise ValueError("LLM æœªè¿”å›ä»»ä½•å†…å®¹")
        
        try:
            # æå– JSON å†…å®¹
            json_content = content.strip()
            
            # å¦‚æœåŒ…å« ```json ä»£ç å—ï¼Œæå–å…¶ä¸­çš„å†…å®¹
            if "```json" in json_content:
                json_start = json_content.find("```json") + 7
                json_end = json_content.find("```", json_start)
                if json_end > json_start:
                    json_content = json_content[json_start:json_end].strip()
            elif json_content.startswith("```") and "```" in json_content[3:]:
                json_start = 3
                json_end = json_content.find("```", json_start)
                if json_end > json_start:
                    json_content = json_content[json_start:json_end].strip()
            
            # è§£æ JSON
            data = json.loads(json_content)
            
            # æ„å»º Resource åˆ—è¡¨
            resources = []
            for r in data.get("resources", []):
                try:
                    resource = Resource(
                        title=r.get("title", ""),
                        url=r.get("url", ""),
                        type=r.get("type", "article"),
                        description=r.get("description", ""),
                        relevance_score=float(r.get("relevance_score", 0.5)),
                        # ğŸ†• æ”¯æŒæ–°å­—æ®µ
                        confidence_score=float(r.get("confidence_score")) if r.get("confidence_score") is not None else None,
                        published_date=r.get("published_date"),
                        language=r.get("language"),
                    )
                    resources.append(resource)
                except Exception as e:
                    logger.warning(
                        "resource_recommender_parse_resource_failed",
                        error=str(e),
                        resource_data=r,
                    )
            
            logger.info(
                "resource_recommender_parsed_resources",
                concept_id=concept.concept_id,
                resources_count=len(resources)
            )
            
            # ğŸ†• éªŒè¯URLæœ‰æ•ˆæ€§ï¼ˆè¿‡æ»¤404é“¾æ¥ï¼‰
            if resources:
                logger.info(
                    "resource_recommender_verifying_urls",
                    concept_id=concept.concept_id,
                    resources_count=len(resources)
                )
                
                resources = await self._verify_urls(resources)
                
                # ç¡®ä¿è‡³å°‘æœ‰3ä¸ªèµ„æº
                if len(resources) < 3:
                    logger.warning(
                        "resource_recommender_insufficient_resources",
                        concept_id=concept.concept_id,
                        resources_count=len(resources),
                        message="URLéªŒè¯åèµ„æºæ•°é‡ä¸è¶³ï¼Œä½†å°†ç»§ç»­è¿”å›"
                    )
            
            # åˆå¹¶æœç´¢æŸ¥è¯¢ï¼ˆä» JSON å’Œå®é™…è°ƒç”¨ä¸­ï¼‰
            json_queries = data.get("search_queries_used", [])
            combined_queries = list(set(all_search_queries + json_queries))
            
            # ç”Ÿæˆå”¯ä¸€ IDï¼ˆç”¨äºå…³è” resource_recommendation_metadata è¡¨ï¼‰
            resource_id = str(uuid.uuid4())
            
            # æ„å»ºè¾“å‡º
            result = ResourceRecommendationOutput(
                id=resource_id,
                concept_id=concept.concept_id,
                resources=resources,
                search_queries_used=combined_queries,
                generated_at=datetime.now(),
            )
            
            logger.info(
                "resource_recommender_success",
                concept_id=concept.concept_id,
                resources_count=len(resources),
                search_queries_count=len(combined_queries),
            )
            return result
            
        except json.JSONDecodeError as e:
            logger.error(
                "resource_recommender_json_parse_error",
                error=str(e),
                content=content[:500],
            )
            raise ValueError(f"LLM è¾“å‡ºä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼: {e}")
        except Exception as e:
            logger.error(
                "resource_recommender_failed",
                concept_id=concept.concept_id,
                error=str(e),
            )
            raise ValueError(f"èµ„æºæ¨èå¤±è´¥: {e}")
    
    async def execute(self, input_data: ResourceRecommendationInput) -> ResourceRecommendationOutput:
        """å®ç°åŸºç±»çš„æŠ½è±¡æ–¹æ³•"""
        return await self.recommend(
            concept=input_data.concept,
            context=input_data.context,
            user_preferences=input_data.user_preferences,
        )

