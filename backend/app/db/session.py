"""
æ•°æ®åº“ä¼šè¯ç®¡ç†ï¼ˆSQLModel + AsyncPGï¼‰

ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–é…ç½®ï¼š
- è¿æ¥æ± å¤§å°å’Œæº¢å‡ºç­–ç•¥
- è¿æ¥å¥åº·æ£€æŸ¥ï¼ˆpool_pre_pingï¼‰
- è¿æ¥å›æ”¶ç­–ç•¥é˜²æ­¢åƒµæ­»è¿æ¥
- è¯¦ç»†çš„è¿æ¥æ± çŠ¶æ€ç›‘æ§
- Prometheus æŒ‡æ ‡æš´éœ²
- æ…¢æŸ¥è¯¢è¿½è¸ª
- äº‹ä»¶å¾ªç¯æ„ŸçŸ¥ï¼ˆCelery Worker å…¼å®¹ï¼‰
"""
from typing import AsyncGenerator, Optional
from sqlalchemy.ext.asyncio import AsyncSession, AsyncEngine, create_async_engine, async_sessionmaker
from sqlalchemy import event, text
from sqlalchemy.exc import IllegalStateChangeError
from sqlmodel import SQLModel
import structlog
import time
import asyncio

from app.config.settings import settings

logger = structlog.get_logger()

# ============================================================
# Prometheus æŒ‡æ ‡å®šä¹‰
# ============================================================
try:
    from prometheus_client import Histogram, Gauge, Counter
    
    # è¿æ¥æŒæœ‰æ—¶é—´ç›´æ–¹å›¾
    db_connection_hold_time = Histogram(
        'db_connection_hold_seconds',
        'Duration a connection is held before return to pool',
        buckets=[0.1, 0.5, 1, 2, 5, 10, 30, 60, 120]
    )
    
    # è¿æ¥æ± ä½¿ç”¨ä¸­çš„è¿æ¥æ•°
    db_pool_connections_in_use = Gauge(
        'db_pool_connections_in_use',
        'Number of database connections currently checked out'
    )
    
    # è¿æ¥æ± å¤§å°
    db_pool_size_gauge = Gauge(
        'db_pool_size',
        'Current size of the connection pool'
    )
    
    # è¿æ¥æ± è¶…æ—¶æ¬¡æ•°
    db_pool_connection_timeouts = Counter(
        'db_pool_connection_timeouts_total',
        'Number of connection pool timeout errors'
    )
    
    # æŸ¥è¯¢æ‰§è¡Œæ—¶é—´ç›´æ–¹å›¾
    db_query_duration = Histogram(
        'db_query_duration_seconds',
        'Database query execution time',
        labelnames=['operation'],
        buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]
    )
    
    # æ…¢æŸ¥è¯¢è®¡æ•°å™¨
    db_slow_query_count = Counter(
        'db_slow_query_total',
        'Number of slow queries detected',
        labelnames=['operation']
    )
    
    PROMETHEUS_ENABLED = True
except ImportError:
    logger.warning("prometheus_client_not_installed", message="Prometheus æŒ‡æ ‡å°†è¢«ç¦ç”¨")
    PROMETHEUS_ENABLED = False

# ============================================================
# äº‹ä»¶å¾ªç¯æ„ŸçŸ¥çš„å¼•æ“ç®¡ç†ï¼ˆCelery Worker å…¼å®¹ï¼‰
# ============================================================
#
# é—®é¢˜èƒŒæ™¯ï¼š
# - å…¨å±€ engine åœ¨å¯¼å…¥æ—¶åˆ›å»ºï¼Œç»‘å®šåˆ°ä¸»è¿›ç¨‹çš„äº‹ä»¶å¾ªç¯
# - Celery Worker ä½¿ç”¨ç‹¬ç«‹çš„è¿›ç¨‹çº§äº‹ä»¶å¾ªç¯ï¼ˆget_worker_loopï¼‰
# - asyncpg è¿æ¥æ± åˆ›å»ºçš„ Future ç»‘å®šåˆ°æ—§äº‹ä»¶å¾ªç¯ï¼Œå¯¼è‡´ï¼š
#   "Task got Future attached to a different loop" é”™è¯¯
#
# è§£å†³æ–¹æ¡ˆï¼š
# - ä¸ºæ¯ä¸ªäº‹ä»¶å¾ªç¯åˆ›å»ºç‹¬ç«‹çš„ engine å®ä¾‹
# - ä½¿ç”¨å­—å…¸ç¼“å­˜ï¼ševent_loop_id -> engine
# - è‡ªåŠ¨æ£€æµ‹å½“å‰äº‹ä»¶å¾ªç¯ï¼Œè¿”å›å¯¹åº”çš„ engine
#
_engine_cache: dict[int, AsyncEngine] = {}
_engine_lock = asyncio.Lock()


def _register_engine_events(engine_instance: AsyncEngine) -> None:
    """
    ä¸º engine æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨
    
    âš ï¸ å…³é”®ï¼šæ¯ä¸ªæ–°åˆ›å»ºçš„ engine å®ä¾‹éƒ½å¿…é¡»æ³¨å†Œè¿™äº›äº‹ä»¶
    ç¡®ä¿è·¨äº‹ä»¶å¾ªç¯çš„ engine éƒ½èƒ½æ­£ç¡®æ¸…ç†é¢„ç¼–è¯‘è¯­å¥
    """
    sync_engine = engine_instance.sync_engine
    
    # ============================================================
    # checkout äº‹ä»¶ï¼šè¿æ¥å–å‡ºæ—¶æ¸…ç†é¢„ç¼–è¯‘è¯­å¥
    # ============================================================
    @event.listens_for(sync_engine, "checkout")
    def on_checkout_handler(dbapi_connection, connection_record, connection_proxy):
        """
        ä»è¿æ¥æ± è·å–è¿æ¥æ—¶è§¦å‘
        
        âš ï¸ å…³é”®ä¿®å¤ï¼šåœ¨è¿æ¥å–å‡ºæ—¶æ¸…ç†é¢„ç¼–è¯‘è¯­å¥
        - Supabase pgbouncer äº‹åŠ¡æ¨¡å¼ä¸æ”¯æŒè·¨äº‹åŠ¡çš„é¢„ç¼–è¯‘è¯­å¥
        - å³ä½¿é…ç½®äº† statement_cache_size=0ï¼Œè¿æ¥æ± ä¸­çš„æ—§è¿æ¥ä»å¯èƒ½æºå¸¦é¢„ç¼–è¯‘è¯­å¥
        - å¿…é¡»åœ¨è¿æ¥å–å‡ºæ—¶ä¸»åŠ¨æ¸…ç†ï¼Œè€Œä¸æ˜¯å½’è¿˜æ—¶æ¸…ç†
        """
        connection_record.info["checkout_time"] = time.time()
        
        # æ¸…ç†é¢„ç¼–è¯‘è¯­å¥
        try:
            if hasattr(dbapi_connection, "_connection"):
                raw_connection = dbapi_connection._connection
                if hasattr(raw_connection, "execute"):
                    from sqlalchemy.util._concurrency_py3k import await_only
                    try:
                        await_only(raw_connection.execute("DEALLOCATE ALL"))
                        logger.debug(
                            "db_prepared_statements_cleared_on_checkout",
                            connection_id=id(dbapi_connection),
                        )
                    except Exception as e:
                        logger.debug(
                            "db_prepared_statements_clear_on_checkout_failed",
                            error=str(e),
                            error_type=type(e).__name__,
                        )
        except Exception as e:
            logger.debug(
                "db_checkout_cleanup_error",
                error=str(e),
                error_type=type(e).__name__,
            )
        
        # Prometheus æŒ‡æ ‡
        if PROMETHEUS_ENABLED:
            db_pool_connections_in_use.inc()
            try:
                pool = engine_instance.pool
                db_pool_size_gauge.set(pool.size())
                checked_out = pool.checkedout()
                max_connections = pool.size() + pool._max_overflow
                usage_ratio = checked_out / max_connections if max_connections > 0 else 0
                if usage_ratio > 0.9:
                    logger.error(
                        "db_pool_critical_usage",
                        checked_out=checked_out,
                        max_connections=max_connections,
                        usage_ratio=round(usage_ratio * 100, 1),
                        message=f"ğŸš¨ è¿æ¥æ± ä½¿ç”¨ç‡è¿‡é«˜ ({round(usage_ratio * 100, 1)}%)ï¼Œå³å°†è€—å°½",
                    )
            except Exception:
                pass
    
    # ============================================================
    # checkin äº‹ä»¶ï¼šè¿æ¥å½’è¿˜æ—¶æ¸…ç†é¢„ç¼–è¯‘è¯­å¥ï¼ˆåŒé‡ä¿é™©ï¼‰
    # ============================================================
    @event.listens_for(sync_engine, "checkin")
    def on_checkin_handler(dbapi_connection, connection_record):
        """è¿æ¥å½’è¿˜è¿æ¥æ± æ—¶è§¦å‘"""
        checkout_time = connection_record.info.get("checkout_time")
        if checkout_time:
            duration = time.time() - checkout_time
            if PROMETHEUS_ENABLED:
                db_connection_hold_time.observe(duration)
                db_pool_connections_in_use.dec()
            if duration > 5:
                logger.warning(
                    "db_connection_long_hold",
                    duration_seconds=round(duration, 2),
                    connection_id=id(dbapi_connection),
                )
            if duration > 10:
                logger.error(
                    "db_connection_held_too_long",
                    duration_seconds=round(duration, 2),
                    threshold_seconds=10,
                    connection_id=id(dbapi_connection),
                )
        
        # æ¸…ç†é¢„ç¼–è¯‘è¯­å¥ï¼ˆåŒé‡ä¿é™©ï¼‰
        try:
            if hasattr(dbapi_connection, "_connection"):
                raw_connection = dbapi_connection._connection
                if hasattr(raw_connection, "execute"):
                    from sqlalchemy.util._concurrency_py3k import await_only
                    try:
                        await_only(raw_connection.execute("DEALLOCATE ALL"))
                        logger.debug(
                            "db_prepared_statements_cleared",
                            connection_id=id(dbapi_connection),
                        )
                    except Exception as e:
                        logger.debug(
                            "db_prepared_statements_clear_failed",
                            error=str(e),
                            error_type=type(e).__name__,
                        )
        except Exception as e:
            logger.debug(
                "db_checkin_cleanup_error",
                error=str(e),
                error_type=type(e).__name__,
            )
    
    # ============================================================
    # å…¶ä»–äº‹ä»¶
    # ============================================================
    @event.listens_for(sync_engine, "connect")
    def on_connect_handler(dbapi_connection, connection_record):
        """æ–°è¿æ¥åˆ›å»ºæ—¶è§¦å‘"""
        logger.debug(
            "db_pool_new_connection",
            connection_id=id(dbapi_connection),
        )
    
    @event.listens_for(sync_engine, "invalidate")
    def on_invalidate_handler(dbapi_connection, connection_record, exception):
        """è¿æ¥è¢«æ ‡è®°ä¸ºæ— æ•ˆæ—¶è§¦å‘"""
        logger.warning(
            "db_connection_invalidated",
            connection_id=id(dbapi_connection),
            exception=str(exception),
        )


def _create_engine() -> AsyncEngine:
    """
    åˆ›å»ºæ•°æ®åº“å¼•æ“ï¼ˆSupabase äº‹åŠ¡æ± åŒ–æ¨¡å¼ä¼˜åŒ–ï¼‰
    
    Supabase Transaction Pooling å…³é”®é…ç½®ï¼š
    âš ï¸ å…³é”®ï¼šasyncpg é»˜è®¤ä¼šè‡ªåŠ¨åˆ›å»ºé¢„ç¼–è¯‘è¯­å¥ï¼ˆprepared statementsï¼‰ï¼Œ
    ä½† pgbouncer çš„äº‹åŠ¡æ¨¡å¼ä¸æ”¯æŒè·¨äº‹åŠ¡çš„é¢„ç¼–è¯‘è¯­å¥ã€‚
    
    è§£å†³æ–¹æ¡ˆï¼š
    1. statement_cache_size=0: ç¦ç”¨ asyncpg å®¢æˆ·ç«¯ç¼“å­˜
    2. ç›‘å¬ checkout/checkin äº‹ä»¶ï¼Œä¸»åŠ¨æ‰§è¡Œ DEALLOCATE ALL æ¸…ç†é¢„ç¼–è¯‘è¯­å¥
    3. pool_pre_ping=False: é¿å…å¥åº·æ£€æŸ¥è§¦å‘é¢„ç¼–è¯‘è¯­å¥åˆ›å»º
    4. pool_recycle=300: å®šæœŸå›æ”¶è¿æ¥
    
    è¿æ¥æ± é…ç½®ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡åŠ¨æ€è°ƒæ•´ï¼‰ï¼š
    - pool_size: ç”± DB_POOL_SIZE ç¯å¢ƒå˜é‡æ§åˆ¶
    - max_overflow: ç”± DB_MAX_OVERFLOW ç¯å¢ƒå˜é‡æ§åˆ¶
    
    æ³¨æ„ï¼šå¤šè¿›ç¨‹éƒ¨ç½²æ—¶ï¼Œæ¯ä¸ªè¿›ç¨‹åˆ›å»ºç‹¬ç«‹çš„è¿æ¥æ± 
    æ€»åº”ç”¨è¿æ¥æ•° = (pool_size + max_overflow) Ã— è¿›ç¨‹æ•°
    """
    new_engine = create_async_engine(
        settings.DATABASE_URL,
        echo=False,
        pool_size=settings.DB_POOL_SIZE,
        max_overflow=settings.DB_MAX_OVERFLOW,
        pool_pre_ping=False,  # ç¦ç”¨å¥åº·æ£€æŸ¥
        pool_recycle=300,  # 5åˆ†é’Ÿå›æ”¶è¿æ¥
        pool_timeout=60,
        pool_use_lifo=True,
        connect_args={
            # Supabase Transaction Mode å¿…é¡»é…ç½®
            # âš ï¸ å…³é”®ä¿®å¤ï¼šåŒæ—¶è®¾ç½®ä¸¤ä¸ªå‚æ•°ç¦ç”¨é¢„ç¼–è¯‘è¯­å¥
            "statement_cache_size": 0,  # ç¦ç”¨ SQLAlchemy å±‚é¢çš„è¯­å¥ç¼“å­˜
            "prepared_statement_cache_size": 0,  # ç¦ç”¨ asyncpg é©±åŠ¨å±‚é¢çš„ç¼“å­˜
            
            # åº”ç”¨çº§é…ç½®
            "server_settings": {
                "application_name": "roadmap_agent",
                "jit": "off",
            },
            "command_timeout": 120,
            "timeout": 30,
        },
    )
    
    # âš ï¸ å…³é”®ï¼šä¸ºæ–°åˆ›å»ºçš„ engine æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨
    _register_engine_events(new_engine)
    
    return new_engine


async def get_engine() -> AsyncEngine:
    """
    è·å–å½“å‰äº‹ä»¶å¾ªç¯å¯¹åº”çš„æ•°æ®åº“å¼•æ“
    
    è‡ªåŠ¨æ£€æµ‹å½“å‰äº‹ä»¶å¾ªç¯ï¼Œå¦‚æœæ˜¯æ–°å¾ªç¯åˆ™åˆ›å»ºæ–° engineã€‚
    ç¡®ä¿ Celery Workerã€FastAPIã€æµ‹è¯•ç­‰ä¸åŒç¯å¢ƒéƒ½ä½¿ç”¨æ­£ç¡®çš„ engineã€‚
    
    Returns:
        AsyncEngine: ç»‘å®šåˆ°å½“å‰äº‹ä»¶å¾ªç¯çš„æ•°æ®åº“å¼•æ“
    """
    loop = asyncio.get_event_loop()
    loop_id = id(loop)
    
    if loop_id not in _engine_cache:
        # åˆ›å»ºæ–° engineï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œä¸ä½¿ç”¨ lockï¼Œå› ä¸ºå¤šæ¬¡åˆ›å»º engine ä¹Ÿæ˜¯å®‰å…¨çš„
        # æœ€å¤šä¼šæœ‰è½»å¾®çš„èµ„æºæµªè´¹ï¼Œä½†é¿å…äº†é”çš„æ€§èƒ½å¼€é”€
        _engine_cache[loop_id] = _create_engine()
        logger.info(
            "db_engine_created_for_event_loop",
            loop_id=loop_id,
            engine_id=id(_engine_cache[loop_id]),
        )
    
    return _engine_cache[loop_id]


def get_engine_sync() -> AsyncEngine:
    """
    åŒæ­¥æ–¹å¼è·å–å¼•æ“ï¼ˆç”¨äºäº‹ä»¶ç›‘å¬å™¨æ³¨å†Œï¼‰
    
    ä»…åœ¨æ¨¡å—å¯¼å…¥æ—¶ä½¿ç”¨ï¼Œä¸åº”åœ¨å¼‚æ­¥ä»£ç ä¸­è°ƒç”¨ã€‚
    """
    loop_id = id(asyncio.get_event_loop())
    if loop_id not in _engine_cache:
        _engine_cache[loop_id] = _create_engine()
    return _engine_cache[loop_id]


# åˆ›å»ºé»˜è®¤å¼•æ“ï¼ˆç”¨äºäº‹ä»¶ç›‘å¬å™¨æ³¨å†Œï¼‰
engine = get_engine_sync()


# ============================================================
# è¿æ¥æ± äº‹ä»¶ç›‘å¬å™¨ï¼ˆè¯Šæ–­ç”¨ï¼‰
# ============================================================

@event.listens_for(engine.sync_engine, "connect")
def on_connect(dbapi_connection, connection_record):
    """æ–°è¿æ¥åˆ›å»ºæ—¶è§¦å‘ï¼ˆç”¨äºè¯Šæ–­ï¼‰"""
    logger.debug(
        "db_pool_new_connection",
        connection_id=id(dbapi_connection),
    )


@event.listens_for(engine.sync_engine, "checkout")
def on_checkout(dbapi_connection, connection_record, connection_proxy):
    """
    ä»è¿æ¥æ± è·å–è¿æ¥æ—¶è§¦å‘
    
    âš ï¸ å…³é”®ä¿®å¤ï¼šåœ¨è¿æ¥å–å‡ºæ—¶æ¸…ç†é¢„ç¼–è¯‘è¯­å¥
    - Supabase pgbouncer äº‹åŠ¡æ¨¡å¼ä¸æ”¯æŒè·¨äº‹åŠ¡çš„é¢„ç¼–è¯‘è¯­å¥
    - å³ä½¿é…ç½®äº† statement_cache_size=0ï¼Œè¿æ¥æ± ä¸­çš„æ—§è¿æ¥ä»å¯èƒ½æºå¸¦é¢„ç¼–è¯‘è¯­å¥
    - å¿…é¡»åœ¨è¿æ¥å–å‡ºæ—¶ä¸»åŠ¨æ¸…ç†ï¼Œè€Œä¸æ˜¯å½’è¿˜æ—¶æ¸…ç†
    """
    connection_record.info["checkout_time"] = time.time()
    
    # ============================================================
    # âš ï¸ å…³é”®ä¿®å¤ï¼šæ¸…ç†é¢„ç¼–è¯‘è¯­å¥ï¼ˆSupabase äº‹åŠ¡æ± åŒ–å¿…éœ€ï¼‰
    # ============================================================
    try:
        # è·å–åº•å±‚çš„ asyncpg è¿æ¥
        if hasattr(dbapi_connection, "_connection"):
            raw_connection = dbapi_connection._connection
            # æ£€æŸ¥æ˜¯å¦æ˜¯ asyncpg è¿æ¥
            if hasattr(raw_connection, "execute"):
                # æ³¨æ„ï¼šè¿™æ˜¯åŒæ­¥äº‹ä»¶å¤„ç†å™¨ï¼Œéœ€è¦ä½¿ç”¨ await_only åŒ…è£…å¼‚æ­¥æ“ä½œ
                from sqlalchemy.util._concurrency_py3k import await_only
                try:
                    await_only(raw_connection.execute("DEALLOCATE ALL"))
                    logger.debug(
                        "db_prepared_statements_cleared_on_checkout",
                        connection_id=id(dbapi_connection),
                    )
                except Exception as e:
                    # æ¸…ç†å¤±è´¥ä¸åº”è¯¥é˜»æ­¢è¿æ¥ä½¿ç”¨
                    logger.debug(
                        "db_prepared_statements_clear_on_checkout_failed",
                        error=str(e),
                        error_type=type(e).__name__,
                    )
    except Exception as e:
        # ä»»ä½•é”™è¯¯éƒ½ä¸åº”è¯¥é˜»æ­¢è¿æ¥ä½¿ç”¨
        logger.debug(
            "db_checkout_cleanup_error",
            error=str(e),
            error_type=type(e).__name__,
        )
    
    # Prometheus æŒ‡æ ‡ï¼šå¢åŠ ä½¿ç”¨ä¸­çš„è¿æ¥æ•°
    if PROMETHEUS_ENABLED:
        db_pool_connections_in_use.inc()
        # æ›´æ–°è¿æ¥æ± å¤§å°
        try:
            pool = engine.pool
            db_pool_size_gauge.set(pool.size())
            
            # âš ï¸ è¿æ¥æ± ä½¿ç”¨ç‡ç›‘æ§ï¼ˆå®æ—¶ï¼‰
            checked_out = pool.checkedout()
            max_connections = pool.size() + pool._max_overflow
            usage_ratio = checked_out / max_connections if max_connections > 0 else 0
            
            # ä½¿ç”¨ç‡è¶…è¿‡ 90% æ—¶å‘å‡ºé”™è¯¯çº§åˆ«è­¦å‘Š
            if usage_ratio > 0.9:
                logger.error(
                    "db_pool_critical_usage",
                    checked_out=checked_out,
                    max_connections=max_connections,
                    usage_ratio=round(usage_ratio * 100, 1),
                    message=f"ğŸš¨ è¿æ¥æ± ä½¿ç”¨ç‡è¿‡é«˜ ({round(usage_ratio * 100, 1)}%)ï¼Œå³å°†è€—å°½",
                )
        except Exception:
            pass


@event.listens_for(engine.sync_engine, "checkin")
def on_checkin(dbapi_connection, connection_record):
    """
    è¿æ¥å½’è¿˜è¿æ¥æ± æ—¶è§¦å‘
    
    âš ï¸ Supabase Transaction Mode å…³é”®ä¿®å¤ï¼š
    åœ¨å½’è¿˜è¿æ¥å‰æ¸…ç†æ‰€æœ‰é¢„ç¼–è¯‘è¯­å¥ï¼Œé¿å… pgbouncer è¿æ¥å¤ç”¨æ—¶å†²çªã€‚
    """
    checkout_time = connection_record.info.get("checkout_time")
    if checkout_time:
        duration = time.time() - checkout_time
        
        # Prometheus æŒ‡æ ‡ï¼šè®°å½•è¿æ¥æŒæœ‰æ—¶é—´
        if PROMETHEUS_ENABLED:
            db_connection_hold_time.observe(duration)
            db_pool_connections_in_use.dec()
        
        # åªè®°å½•é•¿æ—¶é—´æŒæœ‰è¿æ¥çš„æƒ…å†µï¼ˆè¶…è¿‡ 5 ç§’ï¼‰
        if duration > 5:
            logger.warning(
                "db_connection_long_hold",
                duration_seconds=round(duration, 2),
                connection_id=id(dbapi_connection),
            )
        
        # è¶…è¿‡ 10 ç§’çš„è¿æ¥æŒæœ‰è§†ä¸ºå¼‚å¸¸ï¼ˆå¯èƒ½å¯¼è‡´è¿æ¥æ± è€—å°½ï¼‰
        if duration > 10:
            logger.error(
                "db_connection_held_too_long",
                duration_seconds=round(duration, 2),
                threshold_seconds=10,
                connection_id=id(dbapi_connection),
            )
    
    # ğŸ”§ Supabase Transaction Mode ä¿®å¤ï¼šæ¸…ç†é¢„ç¼–è¯‘è¯­å¥
    # åœ¨å½’è¿˜è¿æ¥å‰æ‰§è¡Œ DEALLOCATE ALLï¼Œé˜²æ­¢ pgbouncer åç«¯è¿æ¥å¤ç”¨æ—¶å†²çª
    try:
        # è·å–åº•å±‚çš„ asyncpg è¿æ¥
        if hasattr(dbapi_connection, "_connection"):
            raw_connection = dbapi_connection._connection
            # æ£€æŸ¥æ˜¯å¦æ˜¯ asyncpg è¿æ¥
            if hasattr(raw_connection, "execute"):
                # æ³¨æ„ï¼šè¿™æ˜¯åŒæ­¥äº‹ä»¶å¤„ç†å™¨ï¼Œéœ€è¦ä½¿ç”¨ await_only åŒ…è£…å¼‚æ­¥æ“ä½œ
                from sqlalchemy.util._concurrency_py3k import await_only
                try:
                    await_only(raw_connection.execute("DEALLOCATE ALL"))
                    logger.debug(
                        "db_prepared_statements_cleared",
                        connection_id=id(dbapi_connection),
                    )
                except Exception as e:
                    # æ¸…ç†å¤±è´¥ä¸åº”è¯¥é˜»æ­¢è¿æ¥å½’è¿˜
                    logger.debug(
                        "db_prepared_statements_clear_failed",
                        error=str(e),
                        error_type=type(e).__name__,
                    )
    except Exception as e:
        # ä»»ä½•é”™è¯¯éƒ½ä¸åº”è¯¥é˜»æ­¢è¿æ¥å½’è¿˜
        logger.debug(
            "db_checkin_cleanup_error",
            error=str(e),
            error_type=type(e).__name__,
        )


@event.listens_for(engine.sync_engine, "invalidate")
def on_invalidate(dbapi_connection, connection_record, exception):
    """è¿æ¥è¢«æ ‡è®°ä¸ºæ— æ•ˆæ—¶è§¦å‘ï¼ˆé‡è¦è¯Šæ–­ä¿¡æ¯ï¼‰"""
    logger.warning(
        "db_connection_invalidated",
        connection_id=id(dbapi_connection),
        exception=str(exception) if exception else None,
        exception_type=type(exception).__name__ if exception else None,
    )


# ============================================================
# æ…¢æŸ¥è¯¢è¿½è¸ª
# ============================================================

@event.listens_for(engine.sync_engine, "before_cursor_execute")
def before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    """SQL æ‰§è¡Œå‰è®°å½•æ—¶é—´"""
    conn.info.setdefault("query_start_time", []).append(time.time())
    conn.info.setdefault("query_statement", []).append(statement)


@event.listens_for(engine.sync_engine, "after_cursor_execute")
def after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
    """SQL æ‰§è¡Œåè®¡ç®—è€—æ—¶å¹¶è®°å½•æ…¢æŸ¥è¯¢"""
    try:
        start_time = conn.info.get("query_start_time", [None]).pop() if conn.info.get("query_start_time") else None
        statement_cached = conn.info.get("query_statement", [None]).pop() if conn.info.get("query_statement") else None
        
        if start_time is None:
            return
        
        duration = time.time() - start_time
        
        # æå–æ“ä½œç±»å‹ï¼ˆSELECT, INSERT, UPDATE, DELETEï¼‰
        operation = "UNKNOWN"
        if statement_cached:
            stmt_upper = statement_cached.strip().upper()
            if stmt_upper.startswith("SELECT"):
                operation = "SELECT"
            elif stmt_upper.startswith("INSERT"):
                operation = "INSERT"
            elif stmt_upper.startswith("UPDATE"):
                operation = "UPDATE"
            elif stmt_upper.startswith("DELETE"):
                operation = "DELETE"
            elif stmt_upper.startswith("BEGIN"):
                operation = "BEGIN"
            elif stmt_upper.startswith("COMMIT"):
                operation = "COMMIT"
            elif stmt_upper.startswith("ROLLBACK"):
                operation = "ROLLBACK"
        
        # Prometheus æŒ‡æ ‡ï¼šè®°å½•æŸ¥è¯¢æ‰§è¡Œæ—¶é—´
        if PROMETHEUS_ENABLED:
            db_query_duration.labels(operation=operation).observe(duration)
        
        # æ…¢æŸ¥è¯¢é˜ˆå€¼ï¼š100ms
        SLOW_QUERY_THRESHOLD = 0.1
        
        if duration > SLOW_QUERY_THRESHOLD:
            # è®°å½•æ…¢æŸ¥è¯¢
            logger.warning(
                "slow_query_detected",
                duration_ms=round(duration * 1000, 2),
                duration_seconds=round(duration, 3),
                operation=operation,
                statement=statement_cached[:500] if statement_cached else "N/A",  # åªè®°å½•å‰ 500 ä¸ªå­—ç¬¦
                threshold_ms=round(SLOW_QUERY_THRESHOLD * 1000, 2),
            )
            
            # Prometheus æŒ‡æ ‡ï¼šå¢åŠ æ…¢æŸ¥è¯¢è®¡æ•°
            if PROMETHEUS_ENABLED:
                db_slow_query_count.labels(operation=operation).inc()
    
    except Exception as e:
        # è¿½è¸ªé€»è¾‘ä¸åº”å½±å“æ­£å¸¸æŸ¥è¯¢æ‰§è¡Œ
        logger.debug(
            "query_tracking_error",
            error=str(e),
            error_type=type(e).__name__,
        )

# ============================================================
# ä¼šè¯å·¥å‚ï¼ˆäº‹ä»¶å¾ªç¯æ„ŸçŸ¥ï¼‰
# ============================================================


def get_session_maker() -> async_sessionmaker:
    """
    è·å–å½“å‰äº‹ä»¶å¾ªç¯å¯¹åº”çš„ä¼šè¯å·¥å‚
    
    ç”±äº engine æ˜¯äº‹ä»¶å¾ªç¯æ„ŸçŸ¥çš„ï¼Œä¼šè¯å·¥å‚ä¹Ÿéœ€è¦åŠ¨æ€è·å–ã€‚
    
    Returns:
        async_sessionmaker: ç»‘å®šåˆ°å½“å‰äº‹ä»¶å¾ªç¯ engine çš„ä¼šè¯å·¥å‚
    """
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦åŒæ­¥è·å– engineï¼Œå› ä¸º async_sessionmaker ä¸æ˜¯å¼‚æ­¥å‡½æ•°
    # æˆ‘ä»¬å‡è®¾ engine å·²ç»åœ¨å½“å‰äº‹ä»¶å¾ªç¯ä¸­åˆ›å»ºï¼ˆé€šè¿‡ get_engine()ï¼‰
    loop_id = id(asyncio.get_event_loop())
    current_engine = _engine_cache.get(loop_id)
    
    if current_engine is None:
        # å¦‚æœå½“å‰å¾ªç¯è¿˜æ²¡æœ‰ engineï¼Œåˆ›å»ºä¸€ä¸ª
        current_engine = get_engine_sync()
    
    return async_sessionmaker(
        current_engine,
        class_=AsyncSession,
        expire_on_commit=False,
        autocommit=False,
        autoflush=False,
    )


def AsyncSessionLocal() -> AsyncSession:
    """
    åˆ›å»ºæ•°æ®åº“ä¼šè¯ï¼ˆäº‹ä»¶å¾ªç¯æ„ŸçŸ¥ï¼‰
    
    å…¼å®¹æ—§ä»£ç çš„å‡½æ•°ç­¾åï¼Œä½†å†…éƒ¨ä½¿ç”¨äº‹ä»¶å¾ªç¯æ„ŸçŸ¥çš„å¼•æ“ã€‚
    
    Returns:
        AsyncSession: æ•°æ®åº“ä¼šè¯
    """
    return get_session_maker()()


# ä¿ç•™æ—§çš„å…¨å±€ä¼šè¯å·¥å‚ï¼ˆä»…ç”¨äºå‘åå…¼å®¹ï¼‰
# æ–°ä»£ç åº”è¯¥ä½¿ç”¨ AsyncSessionLocal() å‡½æ•°
_default_session_maker = get_session_maker()


async def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼ˆåˆ›å»ºè¡¨ï¼‰"""
    current_engine = await get_engine()
    async with current_engine.begin() as conn:
        # ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨ Alembic è¿ç§»
        if settings.ENVIRONMENT == "development":
            await conn.run_sync(SQLModel.metadata.create_all)
            logger.info("database_tables_created")


async def get_pool_status() -> dict:
    """
    è·å–è¿æ¥æ± çŠ¶æ€ï¼ˆç”¨äºå¥åº·æ£€æŸ¥å’Œç›‘æ§ï¼‰
    
    Returns:
        åŒ…å«è¿æ¥æ± çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
    """
    current_engine = await get_engine()
    pool = current_engine.pool
    
    checked_out = pool.checkedout()
    pool_size = pool.size()
    max_overflow = pool._max_overflow
    max_connections = pool_size + max_overflow
    
    # è®¡ç®—è¿æ¥ä½¿ç”¨ç‡
    usage_ratio = checked_out / max_connections if max_connections > 0 else 0
    
    # âš ï¸ è¿æ¥æ± å‘Šè­¦ï¼šä½¿ç”¨ç‡è¶…è¿‡ 80% æ—¶è­¦å‘Š
    if usage_ratio > 0.8:
        logger.warning(
            "db_pool_high_usage",
            checked_out=checked_out,
            max_connections=max_connections,
            usage_ratio=round(usage_ratio * 100, 1),
            message=f"âš ï¸ è¿æ¥æ± ä½¿ç”¨ç‡è¿‡é«˜ ({round(usage_ratio * 100, 1)}%)ï¼Œå¯èƒ½å¯¼è‡´è¿æ¥è€—å°½",
        )
    
    # å°è¯•è·å–å¤±æ•ˆè¿æ¥æ•°ï¼ˆæŸäº›æ± ç±»å‹å¯èƒ½ä¸æ”¯æŒï¼‰
    invalid_count = 0
    try:
        if hasattr(pool, 'invalidatedcount'):
            invalid_count = pool.invalidatedcount()
    except Exception:
        pass
    
    return {
        "pool_size": pool_size,  # å½“å‰æ± ä¸­çš„è¿æ¥æ•°
        "checked_out": checked_out,  # æ­£åœ¨ä½¿ç”¨çš„è¿æ¥æ•°
        "overflow": pool.overflow(),  # æº¢å‡ºè¿æ¥æ•°
        "checked_in": pool.checkedin(),  # ç©ºé—²è¿æ¥æ•°
        "invalid": invalid_count,  # å·²å¤±æ•ˆçš„è¿æ¥æ•°
        "max_overflow": max_overflow,  # æœ€å¤§æº¢å‡ºé…ç½®
        "pool_max_size": pool._pool.maxsize if hasattr(pool, "_pool") else None,
        "max_connections": max_connections,  # æœ€å¤§è¿æ¥æ•°
        "usage_ratio": round(usage_ratio * 100, 2),  # ä½¿ç”¨ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰
    }


async def check_db_health() -> dict:
    """
    æ£€æŸ¥æ•°æ®åº“è¿æ¥å¥åº·çŠ¶æ€
    
    æ‰§è¡Œç®€å•æŸ¥è¯¢éªŒè¯è¿æ¥æ˜¯å¦å¯ç”¨ã€‚
    
    Returns:
        å¥åº·çŠ¶æ€ä¿¡æ¯
    """
    start_time = time.time()
    try:
        async with AsyncSessionLocal() as session:
            # æ‰§è¡Œç®€å•æŸ¥è¯¢éªŒè¯è¿æ¥
            result = await session.execute(text("SELECT 1"))
            result.scalar()
        
        latency_ms = round((time.time() - start_time) * 1000, 2)
        pool_status = await get_pool_status()
        
        return {
            "status": "healthy",
            "latency_ms": latency_ms,
            "pool": pool_status,
        }
    except Exception as e:
        latency_ms = round((time.time() - start_time) * 1000, 2)
        logger.error(
            "db_health_check_failed",
            error=str(e),
            error_type=type(e).__name__,
            latency_ms=latency_ms,
        )
        return {
            "status": "unhealthy",
            "error": str(e),
            "error_type": type(e).__name__,
            "latency_ms": latency_ms,
        }


def _is_connection_error(error: Exception) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºæ•°æ®åº“è¿æ¥ç›¸å…³é”™è¯¯
    
    æ”¯æŒçš„é”™è¯¯ç±»å‹ï¼š
    - asyncpg.InterfaceError: è¿æ¥å·²å…³é—­
    - asyncpg.PostgresConnectionError: è¿æ¥é”™è¯¯
    - sqlalchemy.exc.DBAPIError: åº•å±‚é©±åŠ¨é”™è¯¯
    - ä»¥åŠåŒ…å«ç‰¹å®šå…³é”®å­—çš„å…¶ä»–é”™è¯¯
    
    Args:
        error: å¼‚å¸¸å¯¹è±¡
        
    Returns:
        True å¦‚æœæ˜¯è¿æ¥ç›¸å…³é”™è¯¯
    """
    error_type = type(error).__name__
    error_msg = str(error).lower()
    
    # æ£€æŸ¥å¼‚å¸¸ç±»å‹åç§°ï¼ˆé¿å…ç›´æ¥å¯¼å…¥ asyncpgï¼‰
    connection_error_types = {
        "InterfaceError",  # asyncpg: è¿æ¥å·²å…³é—­
        "PostgresConnectionError",  # asyncpg: è¿æ¥é”™è¯¯
        "ConnectionDoesNotExistError",  # asyncpg: è¿æ¥ä¸å­˜åœ¨
        "ConnectionRefusedError",  # è¿æ¥è¢«æ‹’ç»
        "TimeoutError",  # è¶…æ—¶
        "OperationalError",  # SQLAlchemy: æ“ä½œé”™è¯¯ï¼ˆé€šå¸¸æ˜¯è¿æ¥é—®é¢˜ï¼‰
    }
    
    if error_type in connection_error_types:
        return True
    
    # æ£€æŸ¥é”™è¯¯ä¿¡æ¯ä¸­çš„å…³é”®å­—
    connection_keywords = [
        "connection",
        "timeout",
        "closed",
        "does not exist",
        "terminated",
        "connection refused",
        "pool timeout",
        "canceling statement",
        "server closed the connection",
    ]
    
    return any(keyword in error_msg for keyword in connection_keywords)


from contextlib import asynccontextmanager
import asyncio


@asynccontextmanager
async def safe_session_with_retry(
    max_retries: int = 3,
    base_backoff: float = 0.5,
):
    """
    å¸¦é‡è¯•æœºåˆ¶çš„å®‰å…¨ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆä¿®å¤ç‰ˆ - æ­£ç¡®å¤„ç†å¼‚æ­¥ç”Ÿæˆå™¨ï¼‰
    
    âš ï¸ å…³é”®è®¾è®¡åŸåˆ™ï¼š
    @asynccontextmanager è£…é¥°çš„å‡½æ•°åªèƒ½ yield ä¸€æ¬¡ã€‚
    å› æ­¤é‡è¯•é€»è¾‘åªåº”ç”¨äº**è·å–è¿æ¥é˜¶æ®µ**ï¼Œyield åçš„å¼‚å¸¸ç›´æ¥å‘ä¸ŠæŠ›å‡ºã€‚
    
    é‡è¯•ç­–ç•¥ï¼š
    - åªåœ¨åˆ›å»º/è·å–æ•°æ®åº“ä¼šè¯æ—¶é‡è¯•ï¼ˆè¿æ¥æ± è¶…æ—¶ç­‰åœºæ™¯ï¼‰
    - ä¸€æ—¦ yield æˆåŠŸï¼Œåç»­å¼‚å¸¸ä¸å†é‡è¯•ï¼Œç”±è°ƒç”¨æ–¹å¤„ç†
    
    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3 æ¬¡ï¼‰
        base_backoff: åŸºç¡€é€€é¿æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå®é™…ç­‰å¾…æ—¶é—´ = base_backoff * (attempt + 1)
    
    ä½¿ç”¨ç¤ºä¾‹:
        async with safe_session_with_retry() as session:
            result = await session.execute(query)
            await session.commit()
    """
    session = None
    last_error = None
    
    # ============================================================
    # Phase 1: å¸¦é‡è¯•çš„è¿æ¥è·å–ï¼ˆåªæœ‰è¿™ä¸ªé˜¶æ®µå¯ä»¥é‡è¯•ï¼‰
    # ============================================================
    for attempt in range(max_retries):
        try:
            session = AsyncSessionLocal()
            # éªŒè¯è¿æ¥æ˜¯å¦æœ‰æ•ˆï¼ˆè§¦å‘å®é™…çš„è¿æ¥è·å–ï¼‰
            # æ³¨æ„ï¼šAsyncSessionLocal() åªæ˜¯åˆ›å»ºä¼šè¯å¯¹è±¡ï¼Œ
            # å®é™…çš„æ•°æ®åº“è¿æ¥åœ¨ç¬¬ä¸€æ¬¡æ“ä½œæ—¶æ‰ä¼šè·å–
            break  # æˆåŠŸåˆ›å»ºä¼šè¯å¯¹è±¡ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
        except Exception as e:
            last_error = e
            error_msg = str(e).lower()
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯å¯é‡è¯•çš„è¿æ¥é”™è¯¯
            is_pool_timeout = "pool timeout" in error_msg or "timeout" in error_msg
            is_conn_error = _is_connection_error(e)
            
            if (is_pool_timeout or is_conn_error) and attempt < max_retries - 1:
                wait_time = base_backoff * (attempt + 1)
                logger.warning(
                    "db_session_create_retry",
                    attempt=attempt + 1,
                    max_retries=max_retries,
                    wait_seconds=wait_time,
                    error=str(e)[:200],
                    error_type=type(e).__name__,
                )
                await asyncio.sleep(wait_time)
                continue
            else:
                # éè¿æ¥é”™è¯¯æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç›´æ¥æŠ›å‡º
                logger.error(
                    "db_session_create_failed",
                    attempt=attempt + 1,
                    max_retries=max_retries,
                    error=str(e),
                    error_type=type(e).__name__,
                )
                raise
    
    # å¦‚æœå¾ªç¯ç»“æŸä½† session ä»ä¸º Noneï¼ˆç†è®ºä¸Šä¸åº”å‘ç”Ÿï¼‰
    if session is None:
        if last_error:
            raise last_error
        raise RuntimeError("Failed to create database session after retries")
    
    # ============================================================
    # Phase 2: yield ä¼šè¯ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼Œç¬¦åˆ asynccontextmanager è§„èŒƒï¼‰
    # ============================================================
    request_cancelled = False
    
    try:
        yield session
    except asyncio.CancelledError:
        # âš ï¸ è¯·æ±‚è¢«å–æ¶ˆï¼ˆå®¢æˆ·ç«¯æ–­å¼€ã€è¶…æ—¶ç­‰ï¼‰
        request_cancelled = True
        logger.warning(
            "db_session_request_cancelled_with_retry",
            message="å¸¦é‡è¯•çš„ä¼šè¯ï¼šè¯·æ±‚è¢«å–æ¶ˆï¼Œå¼ºåˆ¶æ¸…ç†æ•°æ®åº“ä¼šè¯",
        )
        raise
    except (GeneratorExit, IllegalStateChangeError):
        # SSE æµä¸­æ–­æˆ–å¹¶å‘çŠ¶æ€å†²çªï¼Œé™é»˜å¤„ç†
        pass
    finally:
        # âœ… ã€å…³é”®ä¿®å¤ã€‘ä½¿ç”¨ shield ç¡®ä¿è¿æ¥å½’è¿˜ä¸å¯å–æ¶ˆ
        if session is not None:
            try:
                # ç­‰å¾…æ‰€æœ‰æŒ‚èµ·çš„å¼‚æ­¥æ“ä½œå®Œæˆ
                await asyncio.sleep(0)
                
                # ğŸ›¡ï¸ shield ä¿æŠ¤ï¼šç¡®ä¿ close() ä¸€å®šä¼šå®Œæˆ
                await asyncio.shield(session.close())
                logger.debug("db_session_closed_successfully")
                
                if request_cancelled:
                    logger.info(
                        "db_session_with_retry_closed_after_cancellation",
                        message="å·²æˆåŠŸåœ¨è¯·æ±‚å–æ¶ˆåå…³é—­ä¼šè¯ï¼ˆå¸¦é‡è¯•ï¼‰",
                    )
            except IllegalStateChangeError:
                # å¹¶å‘çŠ¶æ€å†²çªï¼Œé™é»˜å¤„ç†ä½†ä»å°è¯•é‡Šæ”¾
                logger.debug("db_session_close_illegal_state")
                pass
            except asyncio.CancelledError:
                # shield å†…éƒ¨çš„å–æ¶ˆï¼ˆæç«¯æƒ…å†µï¼‰
                logger.error(
                    "db_session_with_retry_close_cancelled_despite_shield",
                    message="âš ï¸ ä¼šè¯å…³é—­åœ¨ shield ä¿æŠ¤ä¸‹ä»è¢«å–æ¶ˆï¼ˆå¸¦é‡è¯•ï¼‰ï¼Œå¯èƒ½å‘ç”Ÿè¿æ¥æ³„æ¼",
                )
            except Exception as e:
                # å¼ºåˆ¶è®°å½•æ‰€æœ‰å…³é—­é”™è¯¯
                logger.warning(
                    "db_session_close_error",
                    error=str(e),
                    error_type=type(e).__name__,
                )
            finally:
                # âœ… é˜²æ­¢æ‚¬æŒ‚å¼•ç”¨
                session = None


@asynccontextmanager
async def safe_session():
    """
    å®‰å…¨çš„æ•°æ®åº“ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆå¢å¼ºç‰ˆ - é˜²æ­¢è¿æ¥æ³„æ¼ï¼‰
    
    ç‰¹åˆ«å¤„ç† SSE æµä¸­æ–­å¯¼è‡´çš„å¹¶å‘çŠ¶æ€å†²çªé—®é¢˜ã€‚
    å½“ session æ­£åœ¨æ‰§è¡Œæ“ä½œæ—¶è¢«å¼ºåˆ¶å…³é—­ï¼Œä¼šè§¦å‘ IllegalStateChangeErrorï¼Œ
    è¿™åœ¨ SSE åœºæ™¯ä¸‹æ˜¯æ­£å¸¸çš„ï¼Œåº”è¯¥è¢«é™é»˜å¤„ç†ã€‚
    
    âœ¨ è¿æ¥æ³„æ¼é˜²æŠ¤ï¼ˆç¬¬ä¸€æ€§åŸç†ä¿®å¤ï¼‰ï¼š
    - ä½¿ç”¨ asyncio.shield() ç¡®ä¿ä¼šè¯å…³é—­ä¸å¯è¢«å–æ¶ˆ
    - åœ¨ä¼šè¯å…³é—­å‰ç­‰å¾…æ‰€æœ‰æŒ‚èµ·çš„å¼‚æ­¥æ“ä½œå®Œæˆ
    - ä½¿ç”¨å¼ºåˆ¶æ¸…ç†æœºåˆ¶ï¼Œé˜²æ­¢è¿æ¥è¢«åƒåœ¾å›æ”¶æ—¶è¿˜æœªå½’è¿˜
    - æ•è· CancelledErrorï¼Œé˜²æ­¢è¯·æ±‚å–æ¶ˆå¯¼è‡´è¿æ¥æ³„æ¼
    
    ä½¿ç”¨ç¤ºä¾‹:
        async with safe_session() as session:
            result = await session.execute(query)
            await session.commit()
    """
    session = None
    request_cancelled = False
    
    try:
        session = AsyncSessionLocal()
        yield session
    except asyncio.CancelledError:
        # âš ï¸ è¯·æ±‚è¢«å–æ¶ˆï¼ˆå®¢æˆ·ç«¯æ–­å¼€ã€è¶…æ—¶ç­‰ï¼‰
        # è¿™æ˜¯è¿æ¥æ³„æ¼çš„ä¸»è¦åŸå› ï¼šå–æ¶ˆæ“ä½œå¯èƒ½å¯¼è‡´ close() æœªæ‰§è¡Œ
        request_cancelled = True
        logger.warning(
            "db_session_request_cancelled",
            message="è¯·æ±‚è¢«å–æ¶ˆï¼Œå¼ºåˆ¶æ¸…ç†æ•°æ®åº“ä¼šè¯ä»¥é˜²æ­¢è¿æ¥æ³„æ¼",
        )
        # é‡æ–°æŠ›å‡ºï¼Œè®©è°ƒç”¨æ–¹çŸ¥é“è¯·æ±‚å·²å–æ¶ˆ
        raise
    except (GeneratorExit, IllegalStateChangeError):
        # SSE æµä¸­æ–­æˆ–å¹¶å‘çŠ¶æ€å†²çªï¼Œé™é»˜å¤„ç†
        pass
    finally:
        # âœ… ã€å…³é”®ä¿®å¤ã€‘ä½¿ç”¨ shield ç¡®ä¿è¿æ¥å½’è¿˜ä¸å¯å–æ¶ˆ
        # å³ä½¿å¤–éƒ¨ä»»åŠ¡è¢«å–æ¶ˆï¼Œä¹Ÿå¿…é¡»å®Œæˆè¿æ¥æ¸…ç†
        if session is not None:
            try:
                # ç­‰å¾…æ‰€æœ‰æŒ‚èµ·çš„å¼‚æ­¥æ“ä½œå®Œæˆ
                await asyncio.sleep(0)
                
                # ğŸ›¡ï¸ shield ä¿æŠ¤ï¼šç¡®ä¿ close() ä¸€å®šä¼šå®Œæˆ
                # å³ä½¿è¯·æ±‚è¢«å–æ¶ˆï¼Œä¹Ÿè¦å½’è¿˜è¿æ¥åˆ°æ± 
                await asyncio.shield(session.close())
                
                if request_cancelled:
                    logger.info(
                        "db_session_closed_after_cancellation",
                        message="å·²æˆåŠŸåœ¨è¯·æ±‚å–æ¶ˆåå…³é—­ä¼šè¯",
                    )
            except IllegalStateChangeError:
                # Session å…³é—­æ—¶å¦ä¸€æ“ä½œæ­£åœ¨è¿›è¡Œï¼Œé™é»˜å¤„ç†
                # è¿™ç§æƒ…å†µä¸‹è¿æ¥æœ€ç»ˆä¼šè¢«è¿æ¥æ± å›æ”¶
                pass
            except asyncio.CancelledError:
                # shield å†…éƒ¨çš„å–æ¶ˆï¼ˆæç«¯æƒ…å†µï¼‰
                # å¼ºåˆ¶è®°å½•ï¼Œè¿™è¡¨ç¤ºè¿æ¥å¯èƒ½æ³„æ¼
                logger.error(
                    "db_session_close_cancelled_despite_shield",
                    message="âš ï¸ ä¼šè¯å…³é—­åœ¨ shield ä¿æŠ¤ä¸‹ä»è¢«å–æ¶ˆï¼Œå¯èƒ½å‘ç”Ÿè¿æ¥æ³„æ¼",
                )
                # ä¸é‡æ–°æŠ›å‡ºï¼Œé¿å…æ©ç›–è¿æ¥æ³„æ¼
            except Exception as e:
                # å…¶ä»–å…³é—­é”™è¯¯ï¼Œè®°å½•ä½†ä¸æŠ›å‡º
                logger.warning(
                    "db_session_close_error",
                    error=str(e),
                    error_type=type(e).__name__,
                )
            finally:
                # âœ… é˜²æ­¢ä¼šè¯è¢«æ„å¤–é‡ç”¨
                session = None


async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """
    FastAPI ä¾èµ–æ³¨å…¥ï¼šè·å–æ•°æ®åº“ä¼šè¯
    
    ä½¿ç”¨ç¤ºä¾‹:
        @app.get("/users")
        async def get_users(db: AsyncSession = Depends(get_db)):
            ...
        
    å¼‚å¸¸å¤„ç†ç­–ç•¥ï¼š
    1. æ­£å¸¸è¯·æ±‚ç»“æŸï¼šè‡ªåŠ¨ commit
    2. è¿æ¥é”™è¯¯ï¼šè®°å½•è­¦å‘Šï¼Œè·³è¿‡ commit/rollbackï¼ˆæ•°æ®åº“ä¼šè‡ªåŠ¨å›æ»šï¼‰
    3. CancelledErrorï¼ˆè¯·æ±‚å–æ¶ˆï¼‰ï¼šå®‰å…¨æ¸…ç†ï¼Œå½’è¿˜è¿æ¥ï¼ˆå·²ç”¨ shield ä¿æŠ¤ï¼‰
    4. GeneratorExitï¼ˆSSE ä¸­æ–­ï¼‰ï¼šé™é»˜å¤„ç†ï¼Œä¸å°è¯• commit/rollback
    5. IllegalStateChangeErrorï¼ˆå¹¶å‘çŠ¶æ€å†²çªï¼‰ï¼šé™é»˜å¤„ç†
    6. å…¶ä»–å¼‚å¸¸ï¼šå°è¯• rollbackï¼Œç„¶åé‡æ–°æŠ›å‡º
    
    è¿æ¥æ³„æ¼é˜²æŠ¤ï¼š
    - safe_session() ä½¿ç”¨ asyncio.shield() ç¡®ä¿è¿æ¥å…³é—­ä¸å¯è¢«å–æ¶ˆ
    - å³ä½¿å®¢æˆ·ç«¯æ–­å¼€è¿æ¥æˆ–è¯·æ±‚è¶…æ—¶ï¼Œè¿æ¥ä¹Ÿä¼šè¢«æ­£ç¡®å½’è¿˜åˆ°æ± ä¸­
    
    è¿æ¥é”™è¯¯è¢«é™é»˜å¤„ç†çš„åŸå› ï¼š
    - æŸ¥è¯¢æ“ä½œé€šå¸¸å·²å®Œæˆï¼Œæ•°æ®å·²è¿”å›
    - å†™æ“ä½œä¼šè¢«æ•°æ®åº“è‡ªåŠ¨å›æ»š
    - æŠ›å‡ºè¿æ¥é”™è¯¯åªä¼šæ©ç›–çœŸæ­£çš„ä¸šåŠ¡é”™è¯¯
    """
    async with safe_session() as session:
        try:
            yield session
            
            # å°è¯• commit
            try:
                await session.commit()
            except IllegalStateChangeError:
                # å¹¶å‘çŠ¶æ€å†²çªï¼Œé™é»˜å¤„ç†
                pass
            except Exception as commit_error:
                if _is_connection_error(commit_error):
                    # è¿æ¥é”™è¯¯ï¼šé™é»˜å¤„ç†
                    logger.warning(
                        "db_session_commit_connection_error",
                        error=str(commit_error),
                        error_type=type(commit_error).__name__,
                    )
                else:
                    # å…¶ä»–é”™è¯¯ï¼šè®°å½•å¹¶é‡æ–°æŠ›å‡º
                    logger.error(
                        "db_session_commit_failed",
                        error=str(commit_error),
                        error_type=type(commit_error).__name__,
                    )
                    raise
        
        except GeneratorExit:
            # SSE æµå¼ä¼ è¾“ä¸­æ–­
            # ä¸å°è¯• commit/rollbackï¼Œç›´æ¥è®©ä¼šè¯å…³é—­
            logger.debug("db_session_generator_exit")
            
        except IllegalStateChangeError:
            # å¹¶å‘çŠ¶æ€å†²çªï¼ˆSSE ä¸­æ–­æ—¶å¸¸è§ï¼‰
            # é™é»˜å¤„ç†ï¼Œæ•°æ®åº“ä¼šè‡ªåŠ¨å¤„ç†æœªå®Œæˆçš„äº‹åŠ¡
            pass
            
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ï¼šå°è¯•å›æ»š
            if _is_connection_error(e):
                # è¿æ¥å·²æ–­å¼€ï¼Œæ— æ³•å›æ»š
                logger.warning(
                    "db_session_error_connection_lost",
                    error=str(e),
                    error_type=type(e).__name__,
                )
            else:
                # å°è¯•å›æ»š
                try:
                    await session.rollback()
                except (IllegalStateChangeError, GeneratorExit):
                    # å¹¶å‘çŠ¶æ€å†²çªæˆ– SSE ä¸­æ–­ï¼Œé™é»˜å¤„ç†
                    pass
                except Exception as rollback_error:
                    logger.error(
                        "db_session_rollback_failed",
                        original_error=str(e),
                        rollback_error=str(rollback_error),
                    )
            
            raise

