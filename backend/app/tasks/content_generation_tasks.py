"""
å†…å®¹ç”Ÿæˆ Celery ä»»åŠ¡

å°†å†…å®¹ç”Ÿæˆä» FastAPI ä¸»è¿›ç¨‹è¿ç§»åˆ°ç‹¬ç«‹çš„ Celery Workerï¼Œ
å®ç°çœŸæ­£çš„è¿›ç¨‹éš”ç¦»ï¼Œé¿å…é˜»å¡ä¸»åº”ç”¨ã€‚

æ¶æ„ä¼˜åŠ¿ï¼š
- FastAPI è¿›ç¨‹ï¼šä¸“æ³¨å¤„ç† HTTP è¯·æ±‚ï¼Œå“åº”é€Ÿåº¦å¿«
- Celery Workerï¼šç‹¬ç«‹è¿›ç¨‹æ‰§è¡Œå†…å®¹ç”Ÿæˆï¼ˆ30+ æ¦‚å¿µå¹¶å‘ï¼Œ90+ LLM è°ƒç”¨ï¼‰
- Redis Queueï¼šè§£è€¦ä¸¤ä¸ªè¿›ç¨‹ï¼Œç¡®ä¿å¯é æ€§

æ¨¡å—æ‹†åˆ†ï¼š
- content_generation_tasks.py: ä¸»ä»»åŠ¡å…¥å£å’Œå¹¶è¡Œç”Ÿæˆé€»è¾‘
- concept_generator.py: å•æ¦‚å¿µå†…å®¹ç”Ÿæˆ
- content_retry_tasks.py: é‡è¯•ä»»åŠ¡
- content_utils.py: å·¥å…·å‡½æ•°
"""
import asyncio
import structlog
from typing import Any

from app.core.celery_app import celery_app
from app.models.domain import RoadmapFramework, LearningPreferences, Concept
from app.db.repository_factory import RepositoryFactory
from app.services.notification_service import notification_service

# ä»å·¥å…·æ¨¡å—å¯¼å…¥
from app.tasks.content_utils import (
    run_async,
    update_framework_with_content_refs,
)

# ä»æ¦‚å¿µç”Ÿæˆå™¨å¯¼å…¥
from app.tasks.concept_generator import generate_single_concept

logger = structlog.get_logger()


@celery_app.task(
    name="app.tasks.content_generation_tasks.generate_roadmap_content",
    queue="content_generation",
    bind=True,
    max_retries=0,
    time_limit=1800,
    soft_time_limit=1500,
    acks_late=True,
)
def generate_roadmap_content(
    self,
    task_id: str,
    roadmap_id: str,
    roadmap_framework_data: dict,
    user_preferences_data: dict,
):
    """
    ä¸ºè·¯çº¿å›¾ç”Ÿæˆæ‰€æœ‰æ¦‚å¿µçš„å†…å®¹ï¼ˆCelery ä»»åŠ¡å…¥å£ï¼‰
    
    è¯¥ä»»åŠ¡åœ¨ç‹¬ç«‹çš„ Celery Worker è¿›ç¨‹ä¸­æ‰§è¡Œï¼Œä¸ä¼šé˜»å¡ FastAPI ä¸»è¿›ç¨‹ã€‚
    
    æ‰§è¡Œæµç¨‹ï¼š
    1. ååºåˆ—åŒ–è¾“å…¥æ•°æ®
    2. æŸ¥è¯¢å·²å®Œæˆçš„ Conceptï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    3. è¿‡æ»¤å‡ºæœªå®Œæˆçš„ Concept
    4. å¹¶è¡Œç”Ÿæˆå†…å®¹
    5. ä¿å­˜ç»“æœåˆ°æ•°æ®åº“
    6. æ¨é€è¿›åº¦é€šçŸ¥
    
    Args:
        task_id: è¿½è¸ª ID
        roadmap_id: è·¯çº¿å›¾ ID
        roadmap_framework_data: è·¯çº¿å›¾æ¡†æ¶æ•°æ®
        user_preferences_data: ç”¨æˆ·åå¥½æ•°æ®
        
    Returns:
        ç”Ÿæˆç»“æœæ‘˜è¦
    """
    logger.info(
        "celery_content_generation_task_started",
        task_id=task_id,
        roadmap_id=roadmap_id,
        celery_task_id=self.request.id,
    )
    
    try:
        result = run_async(
            _async_generate_content(
                task_id=task_id,
                roadmap_id=roadmap_id,
                roadmap_framework_data=roadmap_framework_data,
                user_preferences_data=user_preferences_data,
            )
        )
        
        logger.info(
            "celery_content_generation_task_completed",
            task_id=task_id,
            roadmap_id=roadmap_id,
            tutorial_count=result["tutorial_count"],
            failed_count=result["failed_count"],
        )
        
        return result
        
    except Exception as e:
        logger.error(
            "celery_content_generation_task_failed",
            task_id=task_id,
            roadmap_id=roadmap_id,
            error=str(e),
            error_type=type(e).__name__,
        )
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º failed
        try:
            from app.db.session import safe_session_with_retry
            from app.db.repositories.task_repo import TaskRepository
            
            async def _update_failed_status():
                async with safe_session_with_retry() as session:
                    task_repo = TaskRepository(session)
                    await task_repo.update_task_status(
                        task_id=task_id,
                        status="failed",
                        current_step="content_generation",
                        error_message=str(e)[:500],
                    )
                    await session.commit()
            
            run_async(_update_failed_status())
        except Exception as update_error:
            logger.error("failed_to_update_task_status", task_id=task_id, error=str(update_error))
        
        raise


async def _async_generate_content(
    task_id: str,
    roadmap_id: str,
    roadmap_framework_data: dict,
    user_preferences_data: dict,
) -> dict[str, Any]:
    """
    å†…å®¹ç”Ÿæˆæ ¸å¿ƒé€»è¾‘ï¼ˆå¼‚æ­¥ï¼‰
    
    Args:
        task_id: ä»»åŠ¡ ID
        roadmap_id: è·¯çº¿å›¾ ID
        roadmap_framework_data: è·¯çº¿å›¾æ¡†æ¶æ•°æ®
        user_preferences_data: ç”¨æˆ·åå¥½æ•°æ®
        
    Returns:
        ç”Ÿæˆç»“æœæ‘˜è¦
    """
    from app.agents.factory import get_agent_factory
    from app.core.orchestrator.base import WorkflowConfig
    from app.services.execution_logger import execution_logger
    
    logger.info(
        "async_content_generation_started",
        task_id=task_id,
        roadmap_id=roadmap_id,
    )
    
    # 1. ååºåˆ—åŒ–æ•°æ®
    framework = RoadmapFramework.model_validate(roadmap_framework_data)
    preferences = LearningPreferences.model_validate(user_preferences_data)
    
    # 2. æå–æ‰€æœ‰æ¦‚å¿µ
    all_concepts: list[Concept] = []
    concept_map: dict[str, Concept] = {}
    for stage in framework.stages:
        for module in stage.modules:
            for concept in module.concepts:
                all_concepts.append(concept)
                concept_map[concept.concept_id] = concept
    
    total_concepts = len(all_concepts)
    logger.info(
        "concepts_extracted",
        task_id=task_id,
        roadmap_id=roadmap_id,
        total_concepts=total_concepts,
    )
    
    # 3. æ–­ç‚¹ç»­ä¼ ï¼šæŸ¥è¯¢å·²å®Œæˆçš„ Concept
    from app.db.session import safe_session_with_retry
    from app.db.repositories.roadmap_repo import RoadmapRepository
    
    completed_concept_ids = set()
    async with safe_session_with_retry() as session:
        repo = RoadmapRepository(session)
        completed_tutorials = await repo.get_tutorials_by_roadmap(
            roadmap_id=roadmap_id,
            latest_only=True,
        )
        completed_concept_ids = {
            tutorial.concept_id 
            for tutorial in completed_tutorials 
            if tutorial.content_status == "completed"
        }
    
    # 4. è¿‡æ»¤ï¼šåªç”Ÿæˆæœªå®Œæˆçš„ Concept
    pending_concepts = [
        concept 
        for concept in all_concepts 
        if concept.concept_id not in completed_concept_ids
    ]
    
    skipped_count = len(all_concepts) - len(pending_concepts)
    logger.info(
        "concepts_filtered_by_completion",
        task_id=task_id,
        roadmap_id=roadmap_id,
        total_concepts=len(all_concepts),
        completed_concepts=len(completed_concept_ids),
        pending_concepts=len(pending_concepts),
    )
    
    # å¦‚æœæ‰€æœ‰æ¦‚å¿µéƒ½å·²å®Œæˆï¼Œç›´æ¥è¿”å›
    if not pending_concepts:
        logger.info("all_concepts_already_completed", task_id=task_id, roadmap_id=roadmap_id)
        
        await notification_service.publish_completed(
            task_id=task_id,
            roadmap_id=roadmap_id,
            tutorials_count=len(completed_concept_ids),
            failed_count=0,
        )
        
        return {
            "tutorial_count": len(completed_concept_ids),
            "resource_count": len(completed_concept_ids),
            "quiz_count": len(completed_concept_ids),
            "failed_count": 0,
            "failure_rate": 0,
            "skipped_count": skipped_count,
        }
    
    # 5. åˆ›å»ºæœåŠ¡å’Œå·¥å…·
    repo_factory = RepositoryFactory()
    agent_factory = get_agent_factory()
    config = WorkflowConfig()
    
    # 6. å¹¶è¡Œç”Ÿæˆå†…å®¹
    tutorial_refs, resource_refs, quiz_refs, failed_concepts = await _generate_content_parallel(
        task_id=task_id,
        roadmap_id=roadmap_id,
        concepts=pending_concepts,
        concept_map=concept_map,
        preferences=preferences,
        agent_factory=agent_factory,
    )
    
    # 7. æ£€æŸ¥å¤±è´¥ç‡
    failed_count = len(failed_concepts)
    attempted_concepts = len(pending_concepts)
    success_count = attempted_concepts - failed_count
    failure_rate = failed_count / attempted_concepts if attempted_concepts > 0 else 0
    
    FAILURE_THRESHOLD = 0.5
    
    if failure_rate >= FAILURE_THRESHOLD or failed_count == attempted_concepts:
        error_message = (
            f"Content generation failed: {failed_count}/{attempted_concepts} concepts failed "
            f"(failure rate: {failure_rate:.1%}). Threshold: {FAILURE_THRESHOLD:.1%}"
        )
        
        await execution_logger.error(
            task_id=task_id,
            category="workflow",
            step="content_generation",
            roadmap_id=roadmap_id,
            message=f"âŒ Content generation aborted: failure rate too high ({failure_rate:.1%})",
            details={
                "log_type": "content_generation_aborted",
                "total_concepts": len(all_concepts),
                "attempted_concepts": attempted_concepts,
                "failed_concepts": failed_count,
                "failure_rate": failure_rate,
                "failed_concept_ids": failed_concepts,
            },
        )
        
        raise RuntimeError(error_message)
    
    # 8. ä¿å­˜ç»“æœåˆ°æ•°æ®åº“
    await _save_content_results(
        task_id=task_id,
        roadmap_id=roadmap_id,
        tutorial_refs=tutorial_refs,
        resource_refs=resource_refs,
        quiz_refs=quiz_refs,
        failed_concepts=failed_concepts,
        repo_factory=repo_factory,
    )
    
    # 9. å‘å¸ƒå®Œæˆé€šçŸ¥
    await notification_service.publish_completed(
        task_id=task_id,
        roadmap_id=roadmap_id,
        tutorials_count=len(tutorial_refs),
        failed_count=failed_count,
    )
    
    logger.info(
        "async_content_generation_completed",
        task_id=task_id,
        roadmap_id=roadmap_id,
        tutorial_count=len(tutorial_refs),
        failed_count=failed_count,
    )
    
    return {
        "tutorial_count": len(tutorial_refs),
        "resource_count": len(resource_refs),
        "quiz_count": len(quiz_refs),
        "failed_count": failed_count,
        "failure_rate": failure_rate,
        "skipped_count": skipped_count,
        "attempted_count": attempted_concepts,
    }


async def _generate_content_parallel(
    task_id: str,
    roadmap_id: str,
    concepts: list[Concept],
    concept_map: dict[str, Concept],
    preferences: LearningPreferences,
    agent_factory: Any,
) -> tuple[dict[str, Any], dict[str, Any], dict[str, Any], list[str]]:
    """
    å¹¶è¡Œç”Ÿæˆæ‰€æœ‰æ¦‚å¿µçš„å†…å®¹ï¼ˆå¸¦æ•°æ®åº“è¿æ¥é™åˆ¶ï¼‰
    
    æ¯ä¸ªæ¦‚å¿µç‹¬ç«‹ç”Ÿæˆï¼ˆTutorial â†’ Resource â†’ Quizï¼‰ï¼Œå®Œæˆåç«‹å³å†™å…¥æ•°æ®åº“ã€‚
    
    ğŸ”§ è¿æ¥æ± ä¿æŠ¤ï¼š
    - ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°æ®åº“æ“ä½œæ•°é‡
    - é»˜è®¤æœ€å¤š 8 ä¸ª Concept åŒæ—¶å†™å…¥æ•°æ®åº“
    - é˜²æ­¢è¿æ¥æ± è€—å°½ï¼ˆpool_size=10 + max_overflow=5ï¼‰
    
    Args:
        task_id: ä»»åŠ¡ ID
        roadmap_id: è·¯çº¿å›¾ ID
        concepts: æ¦‚å¿µåˆ—è¡¨
        concept_map: æ¦‚å¿µæ˜ å°„
        preferences: ç”¨æˆ·åå¥½
        agent_factory: Agent å·¥å‚
        
    Returns:
        (tutorial_refs, resource_refs, quiz_refs, failed_concepts)
    """
    total_concepts = len(concepts)
    progress_counter = {"current": 0}
    progress_lock = asyncio.Lock()
    
    tutorial_refs: dict[str, Any] = {}
    resource_refs: dict[str, Any] = {}
    quiz_refs: dict[str, Any] = {}
    failed_concepts: list[str] = []
    results_lock = asyncio.Lock()
    
    # ğŸ”§ æ•°æ®åº“è¿æ¥é™åˆ¶ï¼šæœ€å¤š 3 ä¸ªå¹¶å‘æ•°æ®åº“æ“ä½œ
    # 
    # âš ï¸ å…³é”®çº¦æŸï¼š
    # - æ¯ä¸ªè¿›ç¨‹çš„è¿æ¥æ± åªæœ‰ 4 ä¸ªè¿æ¥ï¼ˆpool_size=2 + max_overflow=2ï¼‰
    # - å¿…é¡»ä¸ºå…¶ä»–æ“ä½œï¼ˆçŠ¶æ€æ›´æ–°ã€æ—¥å¿—ç­‰ï¼‰é¢„ç•™è¿æ¥
    # - MAX_DB_CONCURRENT å¿…é¡» < æ¯è¿›ç¨‹è¿æ¥æ± å¤§å°
    #
    # å…¬å¼ï¼šMAX_DB_CONCURRENT = pool_sizeï¼ˆç•™ 50% ç»™å…¶ä»–æ“ä½œï¼‰
    MAX_DB_CONCURRENT = 3
    db_semaphore = asyncio.Semaphore(MAX_DB_CONCURRENT)
    
    logger.info(
        "content_generation_parallel_config",
        task_id=task_id,
        total_concepts=total_concepts,
        max_db_concurrent=MAX_DB_CONCURRENT,
        message=f"é™åˆ¶æœ€å¤š {MAX_DB_CONCURRENT} ä¸ª Concept åŒæ—¶å†™å…¥æ•°æ®åº“ï¼ˆè¿›ç¨‹æ± è¿æ¥æ•°æœ‰é™ï¼‰",
    )
    
    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æ¦‚å¿µçš„å†…å®¹ç”Ÿæˆ
    tasks = [
        generate_single_concept(
            task_id=task_id,
            roadmap_id=roadmap_id,
            concept=concept,
            concept_map=concept_map,
            preferences=preferences,
            agent_factory=agent_factory,
            total_concepts=total_concepts,
            progress_counter=progress_counter,
            progress_lock=progress_lock,
            tutorial_refs=tutorial_refs,
            resource_refs=resource_refs,
            quiz_refs=quiz_refs,
            failed_concepts=failed_concepts,
            results_lock=results_lock,
            db_semaphore=db_semaphore,  # ä¼ é€’ä¿¡å·é‡
        )
        for concept in concepts
    ]
    
    await asyncio.gather(*tasks, return_exceptions=True)
    
    logger.info(
        "content_generation_parallel_completed",
        task_id=task_id,
        roadmap_id=roadmap_id,
        tutorial_count=len(tutorial_refs),
        resource_count=len(resource_refs),
        quiz_count=len(quiz_refs),
        failed_count=len(failed_concepts),
    )
    
    return tutorial_refs, resource_refs, quiz_refs, failed_concepts


async def _save_content_results(
    task_id: str,
    roadmap_id: str,
    tutorial_refs: dict,
    resource_refs: dict,
    quiz_refs: dict,
    failed_concepts: list,
    repo_factory: Any,
):
    """
    ä¿å­˜å†…å®¹ç”Ÿæˆç»“æœï¼ˆåˆ†æ‰¹äº‹åŠ¡æ“ä½œï¼Œå¸¦å®¹é”™æœºåˆ¶ï¼‰
    
    æ”¹è¿›ï¼š
    - æ•è·æ•°æ®åº“é”™è¯¯ï¼Œå°†å¤±è´¥çš„æ‰¹æ¬¡è®°å½•åˆ° failed_concepts
    - å³ä½¿éƒ¨åˆ†æ‰¹æ¬¡å¤±è´¥ï¼Œä¹Ÿä¿å­˜æˆåŠŸçš„éƒ¨åˆ†
    - ç¡®ä¿ framework_data å’Œ task çŠ¶æ€å§‹ç»ˆè¢«æ›´æ–°
    
    Args:
        task_id: ä»»åŠ¡ ID
        roadmap_id: è·¯çº¿å›¾ ID
        tutorial_refs: æ•™ç¨‹å¼•ç”¨å­—å…¸
        resource_refs: èµ„æºå¼•ç”¨å­—å…¸
        quiz_refs: æµ‹éªŒå¼•ç”¨å­—å…¸
        failed_concepts: å¤±è´¥çš„æ¦‚å¿µ ID åˆ—è¡¨ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
        repo_factory: Repository å·¥å‚
    """
    from app.db.session import safe_session_with_retry
    from app.db.repositories.roadmap_repo import RoadmapRepository
    from sqlalchemy.exc import IntegrityError, DBAPIError
    
    logger.info(
        "save_content_results_started",
        task_id=task_id,
        roadmap_id=roadmap_id,
        tutorial_count=len(tutorial_refs),
        failed_count=len(failed_concepts),
    )
    
    BATCH_SIZE = 3
    
    # ç”¨äºè·Ÿè¸ªä¿å­˜å¤±è´¥çš„ concept_id
    save_failed_concepts = []
    
    # Phase 1: åˆ†æ‰¹ä¿å­˜å…ƒæ•°æ®ï¼ˆå¸¦å®¹é”™æœºåˆ¶ï¼‰
    if tutorial_refs:
        tutorial_items = list(tutorial_refs.items())
        for i in range(0, len(tutorial_items), BATCH_SIZE):
            batch = dict(tutorial_items[i:i + BATCH_SIZE])
            try:
                async with safe_session_with_retry() as session:
                    repo = RoadmapRepository(session)
                    await repo.save_tutorials_batch(batch, roadmap_id)
                    await session.commit()
            except (IntegrityError, DBAPIError) as e:
                logger.error(
                    "tutorial_batch_save_failed",
                    task_id=task_id,
                    roadmap_id=roadmap_id,
                    batch_index=i // BATCH_SIZE,
                    concept_ids=list(batch.keys()),
                    error=str(e)[:500],
                    error_type=type(e).__name__,
                )
                # å°†å¤±è´¥çš„æ¦‚å¿µæ·»åŠ åˆ° failed_concepts
                for concept_id in batch.keys():
                    if concept_id not in failed_concepts and concept_id not in save_failed_concepts:
                        save_failed_concepts.append(concept_id)
                        failed_concepts.append(concept_id)
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹
                continue
    
    if resource_refs:
        resource_items = list(resource_refs.items())
        for i in range(0, len(resource_items), BATCH_SIZE):
            batch = dict(resource_items[i:i + BATCH_SIZE])
            try:
                async with safe_session_with_retry() as session:
                    repo = RoadmapRepository(session)
                    await repo.save_resources_batch(batch, roadmap_id)
                    await session.commit()
            except (IntegrityError, DBAPIError) as e:
                logger.error(
                    "resource_batch_save_failed",
                    task_id=task_id,
                    roadmap_id=roadmap_id,
                    batch_index=i // BATCH_SIZE,
                    concept_ids=list(batch.keys()),
                    error=str(e)[:500],
                    error_type=type(e).__name__,
                )
                # å°†å¤±è´¥çš„æ¦‚å¿µæ·»åŠ åˆ° failed_concepts
                for concept_id in batch.keys():
                    if concept_id not in failed_concepts and concept_id not in save_failed_concepts:
                        save_failed_concepts.append(concept_id)
                        failed_concepts.append(concept_id)
                continue
    
    if quiz_refs:
        quiz_items = list(quiz_refs.items())
        for i in range(0, len(quiz_items), BATCH_SIZE):
            batch = dict(quiz_items[i:i + BATCH_SIZE])
            try:
                async with safe_session_with_retry() as session:
                    repo = RoadmapRepository(session)
                    await repo.save_quizzes_batch(batch, roadmap_id)
                    await session.commit()
            except (IntegrityError, DBAPIError) as e:
                logger.error(
                    "quiz_batch_save_failed",
                    task_id=task_id,
                    roadmap_id=roadmap_id,
                    batch_index=i // BATCH_SIZE,
                    concept_ids=list(batch.keys()),
                    error=str(e)[:500],
                    error_type=type(e).__name__,
                )
                # å°†å¤±è´¥çš„æ¦‚å¿µæ·»åŠ åˆ° failed_concepts
                for concept_id in batch.keys():
                    if concept_id not in failed_concepts and concept_id not in save_failed_concepts:
                        save_failed_concepts.append(concept_id)
                        failed_concepts.append(concept_id)
                continue
    
    # è®°å½•ä¿å­˜å¤±è´¥çš„ç»Ÿè®¡
    if save_failed_concepts:
        logger.warning(
            "some_concepts_failed_to_save",
            task_id=task_id,
            roadmap_id=roadmap_id,
            save_failed_count=len(save_failed_concepts),
            save_failed_concepts=save_failed_concepts[:10],  # åªè®°å½•å‰ 10 ä¸ª
        )
    
    # Phase 2: æ›´æ–° framework_dataï¼ˆå¿…é¡»æ‰§è¡Œï¼Œå³ä½¿ Phase 1 æœ‰å¤±è´¥ï¼‰
    try:
        async with safe_session_with_retry() as session:
            repo = RoadmapRepository(session)
            roadmap_metadata = await repo.get_roadmap_metadata(roadmap_id)
            
            if roadmap_metadata and roadmap_metadata.framework_data:
                updated_framework = update_framework_with_content_refs(
                    framework_data=roadmap_metadata.framework_data,
                    tutorial_refs=tutorial_refs,
                    resource_refs=resource_refs,
                    quiz_refs=quiz_refs,
                    failed_concepts=failed_concepts,
                )
                
                framework_obj = RoadmapFramework.model_validate(updated_framework)
                await repo.save_roadmap_metadata(
                    roadmap_id=roadmap_id,
                    user_id=roadmap_metadata.user_id,
                    framework=framework_obj,
                )
                await session.commit()
                
                logger.info(
                    "framework_data_updated",
                    task_id=task_id,
                    roadmap_id=roadmap_id,
                    tutorial_count=len(tutorial_refs),
                    failed_count=len(failed_concepts),
                )
            else:
                logger.warning(
                    "framework_data_not_found",
                    task_id=task_id,
                    roadmap_id=roadmap_id,
                )
    except Exception as e:
        logger.error(
            "framework_data_update_failed",
            task_id=task_id,
            roadmap_id=roadmap_id,
            error=str(e)[:500],
            error_type=type(e).__name__,
        )
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­æ‰§è¡Œ Phase 3
    
    # Phase 3: æ›´æ–° task æœ€ç»ˆçŠ¶æ€ï¼ˆå¿…é¡»æ‰§è¡Œï¼‰
    final_status = "partial_failure" if failed_concepts else "completed"
    final_step = "content_generation" if failed_concepts else "completed"
    
    try:
        async with safe_session_with_retry() as session:
            repo = RoadmapRepository(session)
            await repo.update_task_status(
                task_id=task_id,
                status=final_status,
                current_step=final_step,
                failed_concepts={
                    "count": len(failed_concepts),
                    "concept_ids": failed_concepts,
                } if failed_concepts else None,
                execution_summary={
                    "tutorial_count": len(tutorial_refs),
                    "resource_count": len(resource_refs),
                    "quiz_count": len(quiz_refs),
                    "failed_count": len(failed_concepts),
                    "save_failed_count": len(save_failed_concepts),
                },
            )
            await session.commit()
            
            logger.info(
                "task_status_updated",
                task_id=task_id,
                final_status=final_status,
                failed_count=len(failed_concepts),
            )
    except Exception as e:
        logger.error(
            "task_status_update_failed",
            task_id=task_id,
            error=str(e)[:500],
            error_type=type(e).__name__,
        )
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“æ•´ä½“æµç¨‹
    
    logger.info(
        "save_content_results_completed",
        task_id=task_id,
        roadmap_id=roadmap_id,
        final_status=final_status,
        tutorial_saved=len(tutorial_refs) - len([c for c in save_failed_concepts if c in tutorial_refs]),
        tutorial_failed=len([c for c in save_failed_concepts if c in tutorial_refs]),
        total_failed=len(failed_concepts),
    )


@celery_app.task(
    name="app.tasks.content_generation_tasks.retry_failed_content_task",
    queue="content_generation",
    bind=True,
    max_retries=0,
    time_limit=1800,
    soft_time_limit=1500,
    acks_late=True,
)
def retry_failed_content_task(
    self,
    roadmap_id: str,
    task_id: str,
    user_id: str,
    preferences: dict,
    content_types: list[str],
    items_to_retry: dict | None = None,
):
    """
    é‡è¯•å¤±è´¥å†…å®¹çš„ç”Ÿæˆï¼ˆCelery ä»»åŠ¡å…¥å£ï¼‰
    
    è¯¥ä»»åŠ¡åœ¨ç‹¬ç«‹çš„ Celery Worker è¿›ç¨‹ä¸­æ‰§è¡Œï¼Œä¸ä¼šé˜»å¡ FastAPI ä¸»è¿›ç¨‹ã€‚
    
    Args:
        roadmap_id: è·¯çº¿å›¾ ID
        task_id: ä»»åŠ¡ IDï¼ˆç”¨äº WebSocket é€šçŸ¥ï¼‰
        user_id: ç”¨æˆ· ID
        preferences: ç”¨æˆ·åå¥½ï¼ˆå­—å…¸æ ¼å¼ï¼‰
        content_types: è¦é‡è¯•çš„å†…å®¹ç±»å‹åˆ—è¡¨ï¼ˆ["tutorial", "resources", "quiz"]ï¼‰
        items_to_retry: è¦é‡è¯•çš„å…·ä½“é¡¹ç›®åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ç›´æ¥ä½¿ç”¨ï¼Œé¿å…é‡å¤æŸ¥è¯¢ï¼‰
        
    Returns:
        é‡è¯•ç»“æœæ‘˜è¦
    """
    from app.services.retry_service import execute_retry_failed_task
    from app.api.v1.endpoints.utils import get_failed_content_items
    from app.db.repository_factory import RepositoryFactory
    
    logger.info(
        "celery_retry_task_started",
        task_id=task_id,
        roadmap_id=roadmap_id,
        celery_task_id=self.request.id,
        items_provided=items_to_retry is not None,
    )
    
    try:
        # ååºåˆ—åŒ–ç”¨æˆ·åå¥½
        user_preferences = LearningPreferences.model_validate(preferences)
        
        # å¦‚æœæ²¡æœ‰æä¾›items_to_retryï¼Œåˆ™æŸ¥è¯¢å¤±è´¥çš„å†…å®¹é¡¹ç›®
        if items_to_retry is None:
            async def _get_failed_items():
                async with RepositoryFactory().create_session() as session:
                    from app.db.repositories.roadmap_repo import RoadmapRepository
                    repo = RoadmapRepository(session)
                    roadmap_metadata = await repo.get_roadmap_metadata(roadmap_id)
                    
                    if not roadmap_metadata:
                        raise RuntimeError(f"è·¯çº¿å›¾ {roadmap_id} ä¸å­˜åœ¨")
                    
                    # è·å–å¤±è´¥çš„å†…å®¹é¡¹ç›®
                    failed_items = get_failed_content_items(roadmap_metadata.framework_data)
                    
                    # ç­›é€‰è¦é‡è¯•çš„ç±»å‹
                    items_to_retry = {}
                    for content_type in content_types:
                        if content_type in failed_items and failed_items[content_type]:
                            items_to_retry[content_type] = failed_items[content_type]
                    
                    return items_to_retry
            
            items_to_retry = run_async(_get_failed_items())
        else:
            # ä½¿ç”¨æä¾›çš„items_to_retryï¼Œä½†ä»éœ€è¦ç­›é€‰content_types
            filtered_items = {}
            for content_type in content_types:
                if content_type in items_to_retry and items_to_retry[content_type]:
                    filtered_items[content_type] = items_to_retry[content_type]
            items_to_retry = filtered_items
        
        if not items_to_retry:
            logger.warning(
                "no_failed_items_to_retry",
                task_id=task_id,
                roadmap_id=roadmap_id,
            )
            return {
                "success": True,
                "retried_count": 0,
                "message": "æ²¡æœ‰éœ€è¦é‡è¯•çš„å¤±è´¥é¡¹ç›®",
            }
        
        # æ‰§è¡Œé‡è¯•
        run_async(
            execute_retry_failed_task(
                retry_task_id=task_id,
                roadmap_id=roadmap_id,
                items_to_retry=items_to_retry,
                user_preferences=user_preferences,
                user_id=user_id,
            )
        )
        
        logger.info(
            "celery_retry_task_completed",
            task_id=task_id,
            roadmap_id=roadmap_id,
        )
        
        return {
            "success": True,
            "retried_count": sum(len(items) for items in items_to_retry.values()),
        }
        
    except Exception as e:
        logger.error(
            "celery_retry_task_failed",
            task_id=task_id,
            roadmap_id=roadmap_id,
            error=str(e),
            error_type=type(e).__name__,
        )
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸º failed
        try:
            from app.db.session import safe_session_with_retry
            from app.db.repositories.task_repo import TaskRepository
            
            async def _update_failed_status():
                async with safe_session_with_retry() as session:
                    task_repo = TaskRepository(session)
                    await task_repo.update_task_status(
                        task_id=task_id,
                        status="failed",
                        current_step="content_retry",
                        error_message=str(e)[:500],
                    )
                    await session.commit()
            
            run_async(_update_failed_status())
        except Exception as update_error:
            logger.error("failed_to_update_task_status", task_id=task_id, error=str(update_error))
        
        raise
